# 20251110-20251116

## 2025-11-12

**cs.DC total: 21**

- **[arXiv251112] HyProv: Hybrid Provenance Management for Scientific Workflows**
  - **tags:** [mlsys], [cluster infrastructure], [hybrid provenance management, centralized component, federated querying, workflow-aware queries, Airflow, Kubernetes]
  - **authors:** Vasilis Bountris, Lauritz Thamsen, Ulf Leser
  - **institution:** Humboldt-Universität zu Berlin, University of Glasgow
  - **link:** https://arxiv.org/pdf/2511.07574
  - **Simple LLM Summary:** HyProv introduces a hybrid provenance management system that combines centralized and federated approaches to handle workflow provenance data. The system uses a centralized component for workflow-specific provenance and federated querying for large-scale execution logs. Experiments show that HyProv scales to large workflows, provides sub-second query latencies, and adds minimal overhead to cluster resources.

- **[arXiv251112] Network and Systems Performance Characterization of MCP-Enabled LLM Agents**
  - **tags:** [mlsys], [llm inference], [Model Context Protocol, token efficiency, parallel tool calls, task abort mechanisms, performance characterization]
  - **authors:** Zihao Ding, Mufeng Zhu, Yao Liu
  - **institution:** Rutgers University
  - **link:** https://arxiv.org/pdf/2511.07426
  - **Simple LLM Summary:** This paper conducts a measurement-based analysis of MCP-enabled LLM interactions, examining how different models and configurations affect token usage, costs, and performance. The study reveals significant trade-offs between capability enhancement and increased computational overhead in MCP workflows. The findings suggest optimizations like parallel tool calls to develop more efficient and cost-effective agent systems.

- **[arXiv251112] Enhancing reliability in AI inference services: An empirical study on real production incidents**
  - **tags:** [mlsys], [llm inference], [incident taxonomy, traffic routing, GPU capacity-aware routing, connection liveness, endpoint isolation, auto-detection, hotfix]
  - **authors:** Bhala Ranganathan, Mickey Zhang, Kai Wu
  - **institution:** Microsoft
  - **link:** https://arxiv.org/pdf/2511.07424
  - **Simple LLM Summary:** This paper presents an empirical study of 156 high-severity production incidents in large language model inference services, developing a taxonomy and methodology grounded in operational experience. The research identifies dominant failure modes and mitigation strategies, showing that systematic analysis can drive more reliable and cost-efficient LLM serving at scale. The study also provides a practitioner-oriented adoption checklist to help others replicate their approach.

- **[arXiv251112] DynaKV: Enabling Accurate and Efficient Long-Sequence LLM Decoding on Smartphones**
  - **tags:** [mlsys], [llm inference], [KVCache management, cluster adaptation, flash management, memory virtualization, retrieval-based methods]
  - **authors:** Tuowei Wang, Minxing Huang, Fengzu Li, Ligeng Chen, Jinrui Zhang, Ju Ren
  - **institution:** Tsinghua University, Honor Device Co., Ltd.
  - **link:** https://arxiv.org/pdf/2511.07427
  - **Simple LLM Summary:** DynaKV is an adaptive KVCache management system for smartphones that uses migration-free cluster adaptation, continuity-centric flash management, and memory-efficient cache design to handle long-sequence LLM decoding. It improves retrieval accuracy by 1.38× and reduces latency by 1.47× compared to state-of-the-art solutions while addressing smartphone-specific memory and bandwidth constraints.

- **[arXiv251112] An Evaluation of LLMs Inference on Popular Single-board Computers**
  - **tags:** [mlsys], [llm inference], [quantization, on-device inference, edge computing, benchmarking, single-board computers]
  - **authors:** Tung, Nguyen, Tuyen Nguyen
  - **institution:** BillulloNex, University of Technology Sydney
  - **link:** https://arxiv.org/pdf/2511.07425
  - **Simple LLM Summary:** This paper benchmarks the performance of 25 quantized LLMs across three single-board computers using Ollama and Llamafile runtimes. The study evaluates generation throughput, memory usage, and power consumption under realistic workloads. Results show SBCs can reliably support models up to 1.5B parameters, with Llamafile achieving 4x higher throughput and 30-40% lower power usage than Ollama.

- **[arXiv251112] From Attention to Disaggregation: Tracing the Evolution of LLM Inference**
  - **tags:** [mlsys], [llm inference], [disaggregated inference, distributed systems, service decomposition, resource disaggregation, workload partitioning, prefill phase, decode phase]
  - **authors:** Madabattula Rajesh Kumar, Srinivasa Rao Aravilli, Mustafa Saify, Shashank Srivastava
  - **institution:** Capital One
  - **link:** https://arxiv.org/pdf/2511.07422
  - **Simple LLM Summary:** This paper proposes disaggregated inference as an architectural shift for LLM deployment, separating compute-intensive prefill from memory-intensive decode phases into independently scalable components. This approach addresses the multi-objective optimization challenge of minimizing latency while maximizing throughput and reducing costs. The main conclusion is that disaggregation mitigates resource contention and enables independent optimization of key inference metrics like Time to First Token and Inter Token Latency.

- **[arXiv251112] SemanticForge: Repository-Level Code Generation through Semantic Knowledge Graphs and Constraint Satisfaction**
  - **tags:** [mlsys], [llm inference], [semantic knowledge graphs, constraint satisfaction, SMT solving, beam search, dual static-dynamic graphs]
  - **authors:** Wuyang Zhang, Chenkai Zhang, Zhen Luo, Jianming Ma, Wangming Yuan, Chuqiao Gu, Chenwei Feng
  - **institution:** University of Massachusetts Amherst, Northeastern University, George Mason University, Carnegie Mellon University, Auckland University of Technology
  - **link:** https://arxiv.org/pdf/2511.07584
  - **Simple LLM Summary:** SemanticForge introduces a repository-level code generation system that combines semantic knowledge graphs with constraint satisfaction to address LLM hallucinations. The system uses dual static-dynamic knowledge graphs and integrated SMT solving during beam search to ensure semantic correctness. Evaluation shows 49.8% Pass@1 performance with significant reductions in logical and schematic hallucinations while maintaining sub-3s latency.

- **[arXiv251112] Towards Affordable, Adaptive and Automatic GNN Training on CPU-GPU Heterogeneous Platforms**
  - **tags:** [mlsys], [others], [locality-aware sampling, fine-grained parallelism scheduling, reinforcement learning, CPU-GPU heterogeneous platforms]
  - **authors:** Tong Qiao, Ao Zhou, Yingjie Qi, Yiou Wang, Han Wan, Jianlei Yang, Chunming Hu
  - **institution:** Beihang University
  - **link:** https://arxiv.org/pdf/2511.07421
  - **Simple LLM Summary:** This paper introduces A3GNN, a framework that optimizes GNN training on CPU-GPU platforms through locality-aware sampling and fine-grained parallelism scheduling, using reinforcement learning to achieve optimal trade-offs. The system enables affordable GNN training by efficiently utilizing resource-constrained hardware. Experiments show it can outperform high-end GPUs, with seven 2080Ti GPUs achieving up to 1.8× higher throughput than two A100 GPUs with minimal accuracy loss.

- **[arXiv251112] Synera: Synergistic LLM Serving across Device and Cloud at Scale**
  - **tags:** [mlsys], [llm inference], [device-cloud synergy, selective offloading, parallel inference, scalable batching, SLM-LLM synergy]
  - **authors:** Genglin Wang, Liekang Zeng, Bufang Yang, Kaiwei Liu, Guoliang Xing, Chumin Sun, Li Zhou, Jie Sun, Zhenyu Yan
  - **institution:** The Chinese University of Hong Kong, Huawei Technologies Co. Ltd.
  - **link:** https://arxiv.org/pdf/2511.07423
  - **Simple LLM Summary:** Synera is a device-cloud synergistic LLM serving system that uses an efficient SLM-LLM synergistic mechanism with communication-efficient selective offloading, stall-free parallel inference, and scalable cloud batching. The system achieves 1.20-5.47× better generation quality compared to baselines while maintaining similar latency, and reduces cloud serving costs by 8.2-16.5% compared to existing cloud serving approaches.

- **[arXiv251112] Parallel Sampling via Autospeculation**
  - **tags:** [mlsys], [diffusion inference], [speculative rejection sampling, autospeculation, parallel sampling]
  - **authors:** Nima Anari, Carlo Baronio, CJ Chen, Alireza Haqi, Frederic Koehler, Anqi Li, Thuy-Duong Vuong
  - **institution:** Stanford University, University of Arizona, University of Chicago, UC Berkeley
  - **link:** https://arxiv.org/pdf/2511.07869
  - **Simple LLM Summary:** The paper introduces speculative rejection sampling, a novel technique that uses autospeculation to accelerate sampling from autoregressive and diffusion models. By building speculative distributions from the same oracle that defines the target distribution and making sequence-level speculations, the method achieves parallel sampling. This reduces expected sampling time from O(n) to O(n^\{1/2\}), improving previous bounds and providing the first parallel speedup for diffusion models in high-accuracy regimes.

- **[arXiv251112] BIPPO: Budget-Aware Independent PPO for Energy-Efficient Federated Learning Services**
  - **tags:** [mlsys], [others], [federated learning, reinforcement learning, proximal policy optimization, client selection, energy efficiency, multi-agent RL]
  - **authors:** Anna Lackinger, Andrea Morichetta, Pantelis A. Frangoudis, Schahram Dustdar
  - **institution:** TU Wien
  - **link:** https://arxiv.org/pdf/2511.08142
  - **Simple LLM Summary:** The paper proposes BIPPO, a budget-aware independent proximal policy optimization method for energy-efficient client selection in federated learning. This multi-agent reinforcement learning approach improves performance while consuming minimal budget in resource-constrained IoT environments. Experimental results show BIPPO achieves higher accuracy than traditional methods while maintaining scalability and sustainability.

- **[arXiv251112] UniFormer: Unified and Efficient Transformer for Reasoning Across General and Custom Computing**
  - **tags:** [mlsys], [llm inference], [transformer architecture, parallelism, compute-storage fusion, FPGA optimization, GPU acceleration]
  - **authors:** Zhuoheng Ran, Chong Wu, Renjie Xu, Maolin Che, Hong Yan
  - **institution:** City University of Hong Kong, Guizhou University
  - **link:** https://arxiv.org/pdf/2511.08135
  - **Simple LLM Summary:** This paper introduces UniFormer, a unified Transformer architecture designed for both general-purpose and custom computing platforms. It achieves higher parallelism and compute-storage fusion to optimize performance across different hardware. The method demonstrates state-of-the-art accuracy and latency on GPUs while maintaining strong adaptability on FPGAs.

- **[arXiv251112] Intelligence per Watt: Measuring Intelligence Efficiency of Local AI**
  - **tags:** [mlsys], [llm inference], [intelligence per watt, local inference, power efficiency, model-accelerator pairs, empirical benchmarking]
  - **authors:** Jon Saad-Falcon, Avanika Narayan, Hakki Orhun Akengin, J. Wes Griffin, Herumb Shandilya, Adrian Gamarra Lafuente, Medhya Goel, Rebecca Joseph, Shlok Natarajan, Etash Kumar Guha, Shang Zhu, Ben Athiwaratkun, John Hennessy, Azalia Mirhoseini, Christopher Ré
  - **institution:** Stanford University, Together AI
  - **link:** https://arxiv.org/pdf/2511.07885
  - **Simple LLM Summary:** This paper proposes Intelligence Per Watt (IPW) as a metric to evaluate the efficiency of local AI inference across model-accelerator pairs. Through large-scale empirical analysis of local language models and hardware accelerators, the study demonstrates that local inference can accurately handle most single-turn queries and meaningfully redistribute demand from centralized cloud infrastructure. The findings show significant improvements in IPW over time and reveal optimization opportunities for local accelerators.

- **[arXiv251112] Generic Algorithm for Universal TDM Communication Over Inter Satellite Links**
  - **tags:** [mlsys], [others], [TDM communication, federated learning, inter satellite links, time division multiplexing, peer data exchange, satellite constellations]
  - **authors:** Miroslav Popovic, Marko Popovic, Pavle Vasiljevic, Ilija Basicevic
  - **institution:** University of Novi Sad, RT-RK Institute for Computer Based Systems
  - **link:** https://arxiv.org/pdf/2511.08034
  - **Simple LLM Summary:** This paper presents a new generic algorithm for universal TDM communication that extends beyond pairwise node communication, allowing nodes to communicate with multiple peers simultaneously. The algorithm was developed within a federated learning framework and specifically addresses communication needs for satellite constellations with multiple antennas. The main advantage is enabling real-world TDM communications over inter satellite links for applications like orbit determination and time synchronization.

- **[arXiv251112] ProbSelect: Stochastic Client Selection for GPU-Accelerated Compute Devices in the 3D Continuum**
  - **tags:** [mlsys], [cluster infrastructure], [probabilistic forecasting, analytical modeling, GPU-accelerated training, federated learning, client selection]
  - **authors:** Andrija Stanisic, Stefan Nastic
  - **institution:** TU Wien
  - **link:** https://arxiv.org/pdf/2511.08147
  - **Simple LLM Summary:** This paper introduces ProbSelect, a novel client selection approach for federated learning that uses analytical modeling and probabilistic forecasting to select GPU-accelerated devices in the 3D compute continuum. The method operates without requiring historical data or continuous monitoring and models client selection within user-defined SLOs. Evaluation shows ProbSelect improves SLO compliance by 13.77% on average while reducing computational waste by 72.5% compared to baseline approaches.

- **[arXiv251112] ACGraph: An Efficient Asynchronous Out-of-Core Graph Processing Framework**
  - **tags:** [sys], [graph processing systems], [asynchronous execution, out-of-core processing, block-centric scheduling, hybrid storage format, SSD optimization]
  - **authors:** Dechuang Chen, Sibo Wang, Qintian Guo
  - **institution:** The Chinese University of Hong Kong, The Hong Kong University of Science and Technology
  - **link:** https://arxiv.org/pdf/2511.07886
  - **Simple LLM Summary:** ACGraph introduces an asynchronous out-of-core graph processing framework that uses dynamic block-centric scheduling and pipelined I/O-computation execution to overcome limitations of synchronous systems. It employs an online asynchronous worklist and hybrid storage format to minimize redundant disk accesses and optimize memory usage. Experimental results show ACGraph significantly outperforms state-of-the-art out-of-core graph processing systems in both runtime and I/O efficiency.

- **[arXiv251112] Forgetting Alternation and Blossoms: A New Framework for Fast Matching Augmentation and Its Applications to Sequential/Distributed/Streaming Computation**
  - **tags:** [ai], [graph algorithms], [alternating base trees, maximum cardinality matching, shortest alternating paths, matching augmentation]
  - **authors:** Taisuke Izumi, Naoki Kitamura, Yutaro Yamaguchi
  - **institution:** Osaka University
  - **link:** https://arxiv.org/pdf/2511.08210
  - **Simple LLM Summary:** The paper proposes a new framework for maximum matching that simplifies the complex structure of shortest alternating paths by "forgetting alternation" and using alternating base trees. This approach yields a more implementable algorithm that is easier to verify than the classical Micali-Vazirani algorithm. The framework also enables improved deterministic approximation algorithms for distributed and streaming settings with substantially better time bounds.

- **[arXiv251112] Foam Segmentation in Wastewater Treatment Plants: A Federated Learning Approach with Segment Anything Model 2**
  - **tags:** [mlsys], [multi-modal training], [Federated Learning, Segment Anything Model 2, Image Segmentation, Flower framework, Fog computing]
  - **authors:** Mehmet Batuhan Duman, Alejandro Carnero, Cristian Martín, Daniel Garrido, Manuel Díaz
  - **institution:** ITIS Software, University of Malaga
  - **link:** https://arxiv.org/pdf/2511.08130
  - **Simple LLM Summary:** This paper proposes a framework combining Federated Learning with Segment Anything Model 2 (SAM2) for foam segmentation in wastewater treatment plants. The approach enables privacy-preserving collaborative training across multiple plants without sharing sensitive data while leveraging SAM2's pre-trained weights for improved performance. The research demonstrates that integrating large-scale foundational models with federated learning provides a practical solution for industrial applications with distributed and sensitive data.

- **[arXiv251112] Gathering in Vertex- and Edge-Transitive Graphs without Multiplicity Detection under Round Robin**
  - **tags:** [sys], [distributed robotics algorithms], [round-robin scheduling, vertex-transitive graphs, edge-transitive graphs, OBLOT model, multiplicity detection]
  - **authors:** Serafino Cicerone, Alessia Di Fonso, Gabriele Di Stefano, Alfredo Navarra
  - **institution:** Università degli Studi dell'Aquila, Università degli Studi di Perugia
  - **link:** https://arxiv.org/pdf/2511.08222
  - **Simple LLM Summary:** This paper proposes distributed algorithms for solving the Gathering problem in swarm robotics on vertex- and edge-transitive graphs under hostile conditions where robots cannot detect multiplicities. The algorithms specifically target infinite grids and hypercubes, exploiting their topological properties to achieve time-optimal performance. The authors conclude that no general algorithm likely exists for all solvable cases due to the heavy reliance on specific graph properties.

- **[arXiv251112] \uline{LO}w-c\uline{O}st yet High-\uline{P}erformant \uline{S}parse Matrix-Matrix Multiplication on Arm SME Architectures**
  - **tags:** [mlsys], [GPU kernels], [SME, NEON, CSR, BCSR, two-level parallelization, performance modeling]
  - **authors:** Kelun Lei, Hailong Yang, Kaige Zhang, Kejie Ma, Yiqing Wang, Xin You, Yufan Xu, Enrique S. Quintana-Orti, Zhongzhi Luan, Yi Liu, Depei Qian
  - **institution:** Beihang University
  - **link:** https://arxiv.org/pdf/2511.08158
  - **Simple LLM Summary:** The paper proposes LOOPS, a hybrid execution framework that combines row-wise CSR and vector-wise BCSR layouts to cooperatively utilize both NEON vector instructions and Arm SME matrix extensions for sparse matrix multiplication. Experimental results show LOOPS achieves significant speedups over CPU baselines and GPU methods while delivering better energy efficiency on Apple M4Pro CPUs compared to NVIDIA A100 GPU implementations.

- **[arXiv251112] Priority Matters: Optimising Kubernetes Clusters Usage with Constraint-Based Pod Packing**
  - **tags:** [mlsys], [cluster infrastructure], [constraint programming, pod packing, OR-Tools, Kubernetes scheduler, resource optimization]
  - **authors:** Henrik Daniel Christensen, Saverio Giallorenzo, Jacopo Mauro
  - **institution:** University of Southern Denmark, University of Bologna
  - **link:** https://arxiv.org/pdf/2511.08373
  - **Simple LLM Summary:** This paper proposes using constraint programming with OR-Tools to optimize Kubernetes pod scheduling, implemented as a fallback plugin when the default scheduler fails. The method improves pod placement by finding optimal allocations that satisfy priorities and resource requirements. Experimental results show the approach places more high-priority pods in over 44% of problematic scenarios within 1 second, and over 73% within 10 seconds, while certifying default scheduler optimality in 19% of cases.


**cs.AI/cs.LG contains "reinforcement learning" total: 31**
- [arXiv251112] A Negotiation-Based Multi-Agent Reinforcement Learning Approach for Dynamic Scheduling of Reconfigurable Manufacturing Systems [link](https://arxiv.org/pdf/2511.07707)
- [arXiv251112] Think Before You Retrieve: Learning Test-Time Adaptive Search with Small Language Models [link](https://arxiv.org/pdf/2511.07581)
- [arXiv251112] Diffusion Guided Adversarial State Perturbations in Reinforcement Learning [link](https://arxiv.org/pdf/2511.07701)
- [arXiv251112] Partial Action Replacement: Tackling Distribution Shift in Offline MARL [link](https://arxiv.org/pdf/2511.07629)
- [arXiv251112] The Polite Liar: Epistemic Pathology in Language Models [link](https://arxiv.org/pdf/2511.07477)
- [arXiv251112] RELEAP: Reinforcement-Enhanced Label-Efficient Active Phenotyping for Electronic Health Records [link](https://arxiv.org/pdf/2511.07473)
- [arXiv251112] MURPHY: Multi-Turn GRPO for Self Correcting Code Generation [link](https://arxiv.org/pdf/2511.07833)
- [arXiv251112] From Exploration to Exploitation: A Two-Stage Entropy RLVR Approach for Noise-Tolerant MLLM Training [link](https://arxiv.org/pdf/2511.07738)
- [arXiv251112] Beyond Correctness: Confidence-Aware Reward Modeling for Enhancing Large Language Model Reasoning [link](https://arxiv.org/pdf/2511.07483)
- [arXiv251112] Intelligent Optimization of Multi-Parameter Micromixers Using a Scientific Machine Learning Framework [link](https://arxiv.org/pdf/2511.07702)
- [arXiv251112] ZeroSim: Zero-Shot Analog Circuit Evaluation with Unified Transformer Embeddings [link](https://arxiv.org/pdf/2511.07658)
- [arXiv251112] Statistically Assuring Safety of Control Systems using Ensembles of Safety Filters and Conformal Prediction [link](https://arxiv.org/pdf/2511.07899)
- [arXiv251112] Test-driven Reinforcement Learning [link](https://arxiv.org/pdf/2511.07904)
- [arXiv251112] Feedback Descent: Open-Ended Text Optimization via Pairwise Comparison [link](https://arxiv.org/pdf/2511.07919)
- [arXiv251112] SERL: Self-Examining Reinforcement Learning on Open-Domain [link](https://arxiv.org/pdf/2511.07922)
- [arXiv251112] SpeechJudge: Towards Human-Level Judgment for Speech Naturalness [link](https://arxiv.org/pdf/2511.07931)
- [arXiv251112] Thinker: Training LLMs in Hierarchical Thinking for Deep Search via Multi-Turn Interaction [link](https://arxiv.org/pdf/2511.07943)
- [arXiv251112] Knowledge-Augmented Long-CoT Generation for Complex Biomolecular Reasoning [link](https://arxiv.org/pdf/2511.08024)
- [arXiv251112] Dynamic Sparsity: Challenging Common Sparsity Assumptions for Learning World Models in Robotic Reinforcement Learning Benchmarks [link](https://arxiv.org/pdf/2511.08086)
- [arXiv251112] An Efficient Training Pipeline for Reasoning Graphical User Interface Agents [link](https://arxiv.org/pdf/2511.08172)
- [arXiv251112] Beyond Distributions: Geometric Action Control for Continuous Reinforcement Learning [link](https://arxiv.org/pdf/2511.08234)
- [arXiv251112] PrefPoE: Advantage-Guided Preference Fusion for Learning Where to Explore [link](https://arxiv.org/pdf/2511.08241)
- [arXiv251112] Where and What Matters: Sensitivity-Aware Task Vectors for Many-Shot Multimodal In-Context Learning [link](https://arxiv.org/pdf/2511.08246)
- [arXiv251112] AgentPRM: Process Reward Models for LLM Agents via Step-Wise Promise and Progress [link](https://arxiv.org/pdf/2511.08325)
- [arXiv251112] LPPG-RL: Lexicographically Projected Policy Gradient Reinforcement Learning with Subproblem Exploration [link](https://arxiv.org/pdf/2511.08339)
- [arXiv251112] ARAC: Adaptive Regularized Multi-Agent Soft Actor-Critic in Graph-Structured Adversarial Games [link](https://arxiv.org/pdf/2511.08412)
- [arXiv251112] Understanding Electro-communication and Electro-sensing in Weakly Electric Fish using Multi-Agent Deep Reinforcement Learning [link](https://arxiv.org/pdf/2511.08436)
- [arXiv251112] The Path Not Taken: RLVR Provably Learns Off the Principals [link](https://arxiv.org/pdf/2511.08567)
- [arXiv251112] DeepProofLog: Efficient Proving in Deep Stochastic Logic Programs [link](https://arxiv.org/pdf/2511.08581)
- [arXiv251112] Shocks Under Control: Taming Transonic Compressible Flow over an RAE2822 Airfoil with Deep Reinforcement Learning [link](https://arxiv.org/pdf/2511.07564)
- [arXiv251112] Distributionally Robust Online Markov Game with Linear Function Approximation [link](https://arxiv.org/pdf/2511.07831)

**cs.AI/cs.LG contains "accelerate" total: 16**
- [arXiv251112] TurboSAT: Gradient-Guided Boolean Satisfiability Accelerated on GPU-CPU Hybrid System [link](https://arxiv.org/pdf/2511.07737)
- [arXiv251112] A Negotiation-Based Multi-Agent Reinforcement Learning Approach for Dynamic Scheduling of Reconfigurable Manufacturing Systems [link](https://arxiv.org/pdf/2511.07707)
- [arXiv251112] Operational machine learning for remote spectroscopic detection of CH$_{4}$ point sources [link](https://arxiv.org/pdf/2511.07719)
- [arXiv251112] FractalCloud: A Fractal-Inspired Architecture for Efficient Large-Scale Point Cloud Processing [link](https://arxiv.org/pdf/2511.07665)
- [arXiv251112] Hyperellipsoid Density Sampling: Exploitative Sequences to Accelerate High-Dimensional Optimization [link](https://arxiv.org/pdf/2511.07836)
- [arXiv251112] A Self-Improving Architecture for Dynamic Safety in Large Language Models [link](https://arxiv.org/pdf/2511.07645)
- [arXiv251112] Streaming Tensor Program: A streaming abstraction for dynamic parallelism [link](https://arxiv.org/pdf/2511.07776)
- [arXiv251112] Sharp Eyes and Memory for VideoLLMs: Information-Aware Visual Token Pruning for Efficient and Reliable VideoLLM Reasoning [link](https://arxiv.org/pdf/2511.08003)
- [arXiv251112] Improving Long-Range Interactions in Graph Neural Simulators via Hamiltonian Dynamics [link](https://arxiv.org/pdf/2511.08185)
- [arXiv251112] Dual-Kernel Graph Community Contrastive Learning [link](https://arxiv.org/pdf/2511.08287)
- [arXiv251112] LPPG-RL: Lexicographically Projected Policy Gradient Reinforcement Learning with Subproblem Exploration [link](https://arxiv.org/pdf/2511.08339)
- [arXiv251112] NeuCLIP: Efficient Large-Scale CLIP Training with Neural Normalizer Optimization [link](https://arxiv.org/pdf/2511.08417)
- [arXiv251112] Benchmarking Simulacra AI's Quantum Accurate Synthetic Data Generation for Chemical Sciences [link](https://arxiv.org/pdf/2511.07433)
- [arXiv251112] Emulating Radiative Transfer in Astrophysical Environments [link](https://arxiv.org/pdf/2511.08219)
- [arXiv251112] Generative AI Meets 6G and Beyond: Diffusion Models for Semantic Communications [link](https://arxiv.org/pdf/2511.08416)
- [arXiv251112] Galactification: painting galaxies onto dark matter only simulations using a transformer-based model [link](https://arxiv.org/pdf/2511.08438)
