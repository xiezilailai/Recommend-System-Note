# 20251110-20251116

## 2025-11-12

**cs.DC total: 21**

- **[arXiv251112] HyProv: Hybrid Provenance Management for Scientific Workflows**
  - **tags:** [mlsys], [cluster infrastructure], [hybrid provenance management, centralized component, federated querying, workflow-aware queries, Airflow, Kubernetes]
  - **authors:** Vasilis Bountris, Lauritz Thamsen, Ulf Leser
  - **institution:** Humboldt-Universität zu Berlin, University of Glasgow
  - **link:** https://arxiv.org/pdf/2511.07574
  - **Simple LLM Summary:** HyProv introduces a hybrid provenance management system that combines centralized and federated approaches to handle workflow provenance data. The system uses a centralized component for workflow-specific provenance and federated querying for large-scale execution logs. Experiments show that HyProv scales to large workflows, provides sub-second query latencies, and adds minimal overhead to cluster resources.

- **[arXiv251112] Network and Systems Performance Characterization of MCP-Enabled LLM Agents**
  - **tags:** [mlsys], [llm inference], [Model Context Protocol, token efficiency, parallel tool calls, task abort mechanisms, performance characterization]
  - **authors:** Zihao Ding, Mufeng Zhu, Yao Liu
  - **institution:** Rutgers University
  - **link:** https://arxiv.org/pdf/2511.07426
  - **Simple LLM Summary:** This paper conducts a measurement-based analysis of MCP-enabled LLM interactions, examining how different models and configurations affect token usage, costs, and performance. The study reveals significant trade-offs between capability enhancement and increased computational overhead in MCP workflows. The findings suggest optimizations like parallel tool calls to develop more efficient and cost-effective agent systems.

- **[arXiv251112] Enhancing reliability in AI inference services: An empirical study on real production incidents**
  - **tags:** [mlsys], [llm inference], [incident taxonomy, traffic routing, GPU capacity-aware routing, connection liveness, endpoint isolation, auto-detection, hotfix]
  - **authors:** Bhala Ranganathan, Mickey Zhang, Kai Wu
  - **institution:** Microsoft
  - **link:** https://arxiv.org/pdf/2511.07424
  - **Simple LLM Summary:** This paper presents an empirical study of 156 high-severity production incidents in large language model inference services, developing a taxonomy and methodology grounded in operational experience. The research identifies dominant failure modes and mitigation strategies, showing that systematic analysis can drive more reliable and cost-efficient LLM serving at scale. The study also provides a practitioner-oriented adoption checklist to help others replicate their approach.

- **[arXiv251112] DynaKV: Enabling Accurate and Efficient Long-Sequence LLM Decoding on Smartphones**
  - **tags:** [mlsys], [llm inference], [KVCache management, cluster adaptation, flash management, memory virtualization, retrieval-based methods]
  - **authors:** Tuowei Wang, Minxing Huang, Fengzu Li, Ligeng Chen, Jinrui Zhang, Ju Ren
  - **institution:** Tsinghua University, Honor Device Co., Ltd.
  - **link:** https://arxiv.org/pdf/2511.07427
  - **Simple LLM Summary:** DynaKV is an adaptive KVCache management system for smartphones that uses migration-free cluster adaptation, continuity-centric flash management, and memory-efficient cache design to handle long-sequence LLM decoding. It improves retrieval accuracy by 1.38× and reduces latency by 1.47× compared to state-of-the-art solutions while addressing smartphone-specific memory and bandwidth constraints.

- **[arXiv251112] An Evaluation of LLMs Inference on Popular Single-board Computers**
  - **tags:** [mlsys], [llm inference], [quantization, on-device inference, edge computing, benchmarking, single-board computers]
  - **authors:** Tung, Nguyen, Tuyen Nguyen
  - **institution:** BillulloNex, University of Technology Sydney
  - **link:** https://arxiv.org/pdf/2511.07425
  - **Simple LLM Summary:** This paper benchmarks the performance of 25 quantized LLMs across three single-board computers using Ollama and Llamafile runtimes. The study evaluates generation throughput, memory usage, and power consumption under realistic workloads. Results show SBCs can reliably support models up to 1.5B parameters, with Llamafile achieving 4x higher throughput and 30-40% lower power usage than Ollama.

- **[arXiv251112] From Attention to Disaggregation: Tracing the Evolution of LLM Inference**
  - **tags:** [mlsys], [llm inference], [disaggregated inference, distributed systems, service decomposition, resource disaggregation, workload partitioning, prefill phase, decode phase]
  - **authors:** Madabattula Rajesh Kumar, Srinivasa Rao Aravilli, Mustafa Saify, Shashank Srivastava
  - **institution:** Capital One
  - **link:** https://arxiv.org/pdf/2511.07422
  - **Simple LLM Summary:** This paper proposes disaggregated inference as an architectural shift for LLM deployment, separating compute-intensive prefill from memory-intensive decode phases into independently scalable components. This approach addresses the multi-objective optimization challenge of minimizing latency while maximizing throughput and reducing costs. The main conclusion is that disaggregation mitigates resource contention and enables independent optimization of key inference metrics like Time to First Token and Inter Token Latency.

- **[arXiv251112] SemanticForge: Repository-Level Code Generation through Semantic Knowledge Graphs and Constraint Satisfaction**
  - **tags:** [mlsys], [llm inference], [semantic knowledge graphs, constraint satisfaction, SMT solving, beam search, dual static-dynamic graphs]
  - **authors:** Wuyang Zhang, Chenkai Zhang, Zhen Luo, Jianming Ma, Wangming Yuan, Chuqiao Gu, Chenwei Feng
  - **institution:** University of Massachusetts Amherst, Northeastern University, George Mason University, Carnegie Mellon University, Auckland University of Technology
  - **link:** https://arxiv.org/pdf/2511.07584
  - **Simple LLM Summary:** SemanticForge introduces a repository-level code generation system that combines semantic knowledge graphs with constraint satisfaction to address LLM hallucinations. The system uses dual static-dynamic knowledge graphs and integrated SMT solving during beam search to ensure semantic correctness. Evaluation shows 49.8% Pass@1 performance with significant reductions in logical and schematic hallucinations while maintaining sub-3s latency.

- **[arXiv251112] Towards Affordable, Adaptive and Automatic GNN Training on CPU-GPU Heterogeneous Platforms**
  - **tags:** [mlsys], [others], [locality-aware sampling, fine-grained parallelism scheduling, reinforcement learning, CPU-GPU heterogeneous platforms]
  - **authors:** Tong Qiao, Ao Zhou, Yingjie Qi, Yiou Wang, Han Wan, Jianlei Yang, Chunming Hu
  - **institution:** Beihang University
  - **link:** https://arxiv.org/pdf/2511.07421
  - **Simple LLM Summary:** This paper introduces A3GNN, a framework that optimizes GNN training on CPU-GPU platforms through locality-aware sampling and fine-grained parallelism scheduling, using reinforcement learning to achieve optimal trade-offs. The system enables affordable GNN training by efficiently utilizing resource-constrained hardware. Experiments show it can outperform high-end GPUs, with seven 2080Ti GPUs achieving up to 1.8× higher throughput than two A100 GPUs with minimal accuracy loss.

- **[arXiv251112] Synera: Synergistic LLM Serving across Device and Cloud at Scale**
  - **tags:** [mlsys], [llm inference], [device-cloud synergy, selective offloading, parallel inference, scalable batching, SLM-LLM synergy]
  - **authors:** Genglin Wang, Liekang Zeng, Bufang Yang, Kaiwei Liu, Guoliang Xing, Chumin Sun, Li Zhou, Jie Sun, Zhenyu Yan
  - **institution:** The Chinese University of Hong Kong, Huawei Technologies Co. Ltd.
  - **link:** https://arxiv.org/pdf/2511.07423
  - **Simple LLM Summary:** Synera is a device-cloud synergistic LLM serving system that uses an efficient SLM-LLM synergistic mechanism with communication-efficient selective offloading, stall-free parallel inference, and scalable cloud batching. The system achieves 1.20-5.47× better generation quality compared to baselines while maintaining similar latency, and reduces cloud serving costs by 8.2-16.5% compared to existing cloud serving approaches.

- **[arXiv251112] Parallel Sampling via Autospeculation**
  - **tags:** [mlsys], [diffusion inference], [speculative rejection sampling, autospeculation, parallel sampling]
  - **authors:** Nima Anari, Carlo Baronio, CJ Chen, Alireza Haqi, Frederic Koehler, Anqi Li, Thuy-Duong Vuong
  - **institution:** Stanford University, University of Arizona, University of Chicago, UC Berkeley
  - **link:** https://arxiv.org/pdf/2511.07869
  - **Simple LLM Summary:** The paper introduces speculative rejection sampling, a novel technique that uses autospeculation to accelerate sampling from autoregressive and diffusion models. By building speculative distributions from the same oracle that defines the target distribution and making sequence-level speculations, the method achieves parallel sampling. This reduces expected sampling time from O(n) to O(n^\{1/2\}), improving previous bounds and providing the first parallel speedup for diffusion models in high-accuracy regimes.

- **[arXiv251112] BIPPO: Budget-Aware Independent PPO for Energy-Efficient Federated Learning Services**
  - **tags:** [mlsys], [others], [federated learning, reinforcement learning, proximal policy optimization, client selection, energy efficiency, multi-agent RL]
  - **authors:** Anna Lackinger, Andrea Morichetta, Pantelis A. Frangoudis, Schahram Dustdar
  - **institution:** TU Wien
  - **link:** https://arxiv.org/pdf/2511.08142
  - **Simple LLM Summary:** The paper proposes BIPPO, a budget-aware independent proximal policy optimization method for energy-efficient client selection in federated learning. This multi-agent reinforcement learning approach improves performance while consuming minimal budget in resource-constrained IoT environments. Experimental results show BIPPO achieves higher accuracy than traditional methods while maintaining scalability and sustainability.

- **[arXiv251112] UniFormer: Unified and Efficient Transformer for Reasoning Across General and Custom Computing**
  - **tags:** [mlsys], [llm inference], [transformer architecture, parallelism, compute-storage fusion, FPGA optimization, GPU acceleration]
  - **authors:** Zhuoheng Ran, Chong Wu, Renjie Xu, Maolin Che, Hong Yan
  - **institution:** City University of Hong Kong, Guizhou University
  - **link:** https://arxiv.org/pdf/2511.08135
  - **Simple LLM Summary:** This paper introduces UniFormer, a unified Transformer architecture designed for both general-purpose and custom computing platforms. It achieves higher parallelism and compute-storage fusion to optimize performance across different hardware. The method demonstrates state-of-the-art accuracy and latency on GPUs while maintaining strong adaptability on FPGAs.

- **[arXiv251112] Intelligence per Watt: Measuring Intelligence Efficiency of Local AI**
  - **tags:** [mlsys], [llm inference], [intelligence per watt, local inference, power efficiency, model-accelerator pairs, empirical benchmarking]
  - **authors:** Jon Saad-Falcon, Avanika Narayan, Hakki Orhun Akengin, J. Wes Griffin, Herumb Shandilya, Adrian Gamarra Lafuente, Medhya Goel, Rebecca Joseph, Shlok Natarajan, Etash Kumar Guha, Shang Zhu, Ben Athiwaratkun, John Hennessy, Azalia Mirhoseini, Christopher Ré
  - **institution:** Stanford University, Together AI
  - **link:** https://arxiv.org/pdf/2511.07885
  - **Simple LLM Summary:** This paper proposes Intelligence Per Watt (IPW) as a metric to evaluate the efficiency of local AI inference across model-accelerator pairs. Through large-scale empirical analysis of local language models and hardware accelerators, the study demonstrates that local inference can accurately handle most single-turn queries and meaningfully redistribute demand from centralized cloud infrastructure. The findings show significant improvements in IPW over time and reveal optimization opportunities for local accelerators.

- **[arXiv251112] Generic Algorithm for Universal TDM Communication Over Inter Satellite Links**
  - **tags:** [mlsys], [others], [TDM communication, federated learning, inter satellite links, time division multiplexing, peer data exchange, satellite constellations]
  - **authors:** Miroslav Popovic, Marko Popovic, Pavle Vasiljevic, Ilija Basicevic
  - **institution:** University of Novi Sad, RT-RK Institute for Computer Based Systems
  - **link:** https://arxiv.org/pdf/2511.08034
  - **Simple LLM Summary:** This paper presents a new generic algorithm for universal TDM communication that extends beyond pairwise node communication, allowing nodes to communicate with multiple peers simultaneously. The algorithm was developed within a federated learning framework and specifically addresses communication needs for satellite constellations with multiple antennas. The main advantage is enabling real-world TDM communications over inter satellite links for applications like orbit determination and time synchronization.

- **[arXiv251112] ProbSelect: Stochastic Client Selection for GPU-Accelerated Compute Devices in the 3D Continuum**
  - **tags:** [mlsys], [cluster infrastructure], [probabilistic forecasting, analytical modeling, GPU-accelerated training, federated learning, client selection]
  - **authors:** Andrija Stanisic, Stefan Nastic
  - **institution:** TU Wien
  - **link:** https://arxiv.org/pdf/2511.08147
  - **Simple LLM Summary:** This paper introduces ProbSelect, a novel client selection approach for federated learning that uses analytical modeling and probabilistic forecasting to select GPU-accelerated devices in the 3D compute continuum. The method operates without requiring historical data or continuous monitoring and models client selection within user-defined SLOs. Evaluation shows ProbSelect improves SLO compliance by 13.77% on average while reducing computational waste by 72.5% compared to baseline approaches.

- **[arXiv251112] ACGraph: An Efficient Asynchronous Out-of-Core Graph Processing Framework**
  - **tags:** [sys], [graph processing systems], [asynchronous execution, out-of-core processing, block-centric scheduling, hybrid storage format, SSD optimization]
  - **authors:** Dechuang Chen, Sibo Wang, Qintian Guo
  - **institution:** The Chinese University of Hong Kong, The Hong Kong University of Science and Technology
  - **link:** https://arxiv.org/pdf/2511.07886
  - **Simple LLM Summary:** ACGraph introduces an asynchronous out-of-core graph processing framework that uses dynamic block-centric scheduling and pipelined I/O-computation execution to overcome limitations of synchronous systems. It employs an online asynchronous worklist and hybrid storage format to minimize redundant disk accesses and optimize memory usage. Experimental results show ACGraph significantly outperforms state-of-the-art out-of-core graph processing systems in both runtime and I/O efficiency.

- **[arXiv251112] Forgetting Alternation and Blossoms: A New Framework for Fast Matching Augmentation and Its Applications to Sequential/Distributed/Streaming Computation**
  - **tags:** [ai], [graph algorithms], [alternating base trees, maximum cardinality matching, shortest alternating paths, matching augmentation]
  - **authors:** Taisuke Izumi, Naoki Kitamura, Yutaro Yamaguchi
  - **institution:** Osaka University
  - **link:** https://arxiv.org/pdf/2511.08210
  - **Simple LLM Summary:** The paper proposes a new framework for maximum matching that simplifies the complex structure of shortest alternating paths by "forgetting alternation" and using alternating base trees. This approach yields a more implementable algorithm that is easier to verify than the classical Micali-Vazirani algorithm. The framework also enables improved deterministic approximation algorithms for distributed and streaming settings with substantially better time bounds.

- **[arXiv251112] Foam Segmentation in Wastewater Treatment Plants: A Federated Learning Approach with Segment Anything Model 2**
  - **tags:** [mlsys], [multi-modal training], [Federated Learning, Segment Anything Model 2, Image Segmentation, Flower framework, Fog computing]
  - **authors:** Mehmet Batuhan Duman, Alejandro Carnero, Cristian Martín, Daniel Garrido, Manuel Díaz
  - **institution:** ITIS Software, University of Malaga
  - **link:** https://arxiv.org/pdf/2511.08130
  - **Simple LLM Summary:** This paper proposes a framework combining Federated Learning with Segment Anything Model 2 (SAM2) for foam segmentation in wastewater treatment plants. The approach enables privacy-preserving collaborative training across multiple plants without sharing sensitive data while leveraging SAM2's pre-trained weights for improved performance. The research demonstrates that integrating large-scale foundational models with federated learning provides a practical solution for industrial applications with distributed and sensitive data.

- **[arXiv251112] Gathering in Vertex- and Edge-Transitive Graphs without Multiplicity Detection under Round Robin**
  - **tags:** [sys], [distributed robotics algorithms], [round-robin scheduling, vertex-transitive graphs, edge-transitive graphs, OBLOT model, multiplicity detection]
  - **authors:** Serafino Cicerone, Alessia Di Fonso, Gabriele Di Stefano, Alfredo Navarra
  - **institution:** Università degli Studi dell'Aquila, Università degli Studi di Perugia
  - **link:** https://arxiv.org/pdf/2511.08222
  - **Simple LLM Summary:** This paper proposes distributed algorithms for solving the Gathering problem in swarm robotics on vertex- and edge-transitive graphs under hostile conditions where robots cannot detect multiplicities. The algorithms specifically target infinite grids and hypercubes, exploiting their topological properties to achieve time-optimal performance. The authors conclude that no general algorithm likely exists for all solvable cases due to the heavy reliance on specific graph properties.

- **[arXiv251112] \uline{LO}w-c\uline{O}st yet High-\uline{P}erformant \uline{S}parse Matrix-Matrix Multiplication on Arm SME Architectures**
  - **tags:** [mlsys], [GPU kernels], [SME, NEON, CSR, BCSR, two-level parallelization, performance modeling]
  - **authors:** Kelun Lei, Hailong Yang, Kaige Zhang, Kejie Ma, Yiqing Wang, Xin You, Yufan Xu, Enrique S. Quintana-Orti, Zhongzhi Luan, Yi Liu, Depei Qian
  - **institution:** Beihang University
  - **link:** https://arxiv.org/pdf/2511.08158
  - **Simple LLM Summary:** The paper proposes LOOPS, a hybrid execution framework that combines row-wise CSR and vector-wise BCSR layouts to cooperatively utilize both NEON vector instructions and Arm SME matrix extensions for sparse matrix multiplication. Experimental results show LOOPS achieves significant speedups over CPU baselines and GPU methods while delivering better energy efficiency on Apple M4Pro CPUs compared to NVIDIA A100 GPU implementations.

- **[arXiv251112] Priority Matters: Optimising Kubernetes Clusters Usage with Constraint-Based Pod Packing**
  - **tags:** [mlsys], [cluster infrastructure], [constraint programming, pod packing, OR-Tools, Kubernetes scheduler, resource optimization]
  - **authors:** Henrik Daniel Christensen, Saverio Giallorenzo, Jacopo Mauro
  - **institution:** University of Southern Denmark, University of Bologna
  - **link:** https://arxiv.org/pdf/2511.08373
  - **Simple LLM Summary:** This paper proposes using constraint programming with OR-Tools to optimize Kubernetes pod scheduling, implemented as a fallback plugin when the default scheduler fails. The method improves pod placement by finding optimal allocations that satisfy priorities and resource requirements. Experimental results show the approach places more high-priority pods in over 44% of problematic scenarios within 1 second, and over 73% within 10 seconds, while certifying default scheduler optimality in 19% of cases.


**cs.AI/cs.LG contains "reinforcement learning" total: 31**
- [arXiv251112] A Negotiation-Based Multi-Agent Reinforcement Learning Approach for Dynamic Scheduling of Reconfigurable Manufacturing Systems [link](https://arxiv.org/pdf/2511.07707)
- [arXiv251112] Think Before You Retrieve: Learning Test-Time Adaptive Search with Small Language Models [link](https://arxiv.org/pdf/2511.07581)
- [arXiv251112] Diffusion Guided Adversarial State Perturbations in Reinforcement Learning [link](https://arxiv.org/pdf/2511.07701)
- [arXiv251112] Partial Action Replacement: Tackling Distribution Shift in Offline MARL [link](https://arxiv.org/pdf/2511.07629)
- [arXiv251112] The Polite Liar: Epistemic Pathology in Language Models [link](https://arxiv.org/pdf/2511.07477)
- [arXiv251112] RELEAP: Reinforcement-Enhanced Label-Efficient Active Phenotyping for Electronic Health Records [link](https://arxiv.org/pdf/2511.07473)
- [arXiv251112] MURPHY: Multi-Turn GRPO for Self Correcting Code Generation [link](https://arxiv.org/pdf/2511.07833)
- [arXiv251112] From Exploration to Exploitation: A Two-Stage Entropy RLVR Approach for Noise-Tolerant MLLM Training [link](https://arxiv.org/pdf/2511.07738)
- [arXiv251112] Beyond Correctness: Confidence-Aware Reward Modeling for Enhancing Large Language Model Reasoning [link](https://arxiv.org/pdf/2511.07483)
- [arXiv251112] Intelligent Optimization of Multi-Parameter Micromixers Using a Scientific Machine Learning Framework [link](https://arxiv.org/pdf/2511.07702)
- [arXiv251112] ZeroSim: Zero-Shot Analog Circuit Evaluation with Unified Transformer Embeddings [link](https://arxiv.org/pdf/2511.07658)
- [arXiv251112] Statistically Assuring Safety of Control Systems using Ensembles of Safety Filters and Conformal Prediction [link](https://arxiv.org/pdf/2511.07899)
- [arXiv251112] Test-driven Reinforcement Learning [link](https://arxiv.org/pdf/2511.07904)
- [arXiv251112] Feedback Descent: Open-Ended Text Optimization via Pairwise Comparison [link](https://arxiv.org/pdf/2511.07919)
- [arXiv251112] SERL: Self-Examining Reinforcement Learning on Open-Domain [link](https://arxiv.org/pdf/2511.07922)
- [arXiv251112] SpeechJudge: Towards Human-Level Judgment for Speech Naturalness [link](https://arxiv.org/pdf/2511.07931)
- [arXiv251112] Thinker: Training LLMs in Hierarchical Thinking for Deep Search via Multi-Turn Interaction [link](https://arxiv.org/pdf/2511.07943)
- [arXiv251112] Knowledge-Augmented Long-CoT Generation for Complex Biomolecular Reasoning [link](https://arxiv.org/pdf/2511.08024)
- [arXiv251112] Dynamic Sparsity: Challenging Common Sparsity Assumptions for Learning World Models in Robotic Reinforcement Learning Benchmarks [link](https://arxiv.org/pdf/2511.08086)
- [arXiv251112] An Efficient Training Pipeline for Reasoning Graphical User Interface Agents [link](https://arxiv.org/pdf/2511.08172)
- [arXiv251112] Beyond Distributions: Geometric Action Control for Continuous Reinforcement Learning [link](https://arxiv.org/pdf/2511.08234)
- [arXiv251112] PrefPoE: Advantage-Guided Preference Fusion for Learning Where to Explore [link](https://arxiv.org/pdf/2511.08241)
- [arXiv251112] Where and What Matters: Sensitivity-Aware Task Vectors for Many-Shot Multimodal In-Context Learning [link](https://arxiv.org/pdf/2511.08246)
- [arXiv251112] AgentPRM: Process Reward Models for LLM Agents via Step-Wise Promise and Progress [link](https://arxiv.org/pdf/2511.08325)
- [arXiv251112] LPPG-RL: Lexicographically Projected Policy Gradient Reinforcement Learning with Subproblem Exploration [link](https://arxiv.org/pdf/2511.08339)
- [arXiv251112] ARAC: Adaptive Regularized Multi-Agent Soft Actor-Critic in Graph-Structured Adversarial Games [link](https://arxiv.org/pdf/2511.08412)
- [arXiv251112] Understanding Electro-communication and Electro-sensing in Weakly Electric Fish using Multi-Agent Deep Reinforcement Learning [link](https://arxiv.org/pdf/2511.08436)
- [arXiv251112] The Path Not Taken: RLVR Provably Learns Off the Principals [link](https://arxiv.org/pdf/2511.08567)
- [arXiv251112] DeepProofLog: Efficient Proving in Deep Stochastic Logic Programs [link](https://arxiv.org/pdf/2511.08581)
- [arXiv251112] Shocks Under Control: Taming Transonic Compressible Flow over an RAE2822 Airfoil with Deep Reinforcement Learning [link](https://arxiv.org/pdf/2511.07564)
- [arXiv251112] Distributionally Robust Online Markov Game with Linear Function Approximation [link](https://arxiv.org/pdf/2511.07831)

**cs.AI/cs.LG contains "accelerate" total: 16**
- [arXiv251112] TurboSAT: Gradient-Guided Boolean Satisfiability Accelerated on GPU-CPU Hybrid System [link](https://arxiv.org/pdf/2511.07737)
- [arXiv251112] A Negotiation-Based Multi-Agent Reinforcement Learning Approach for Dynamic Scheduling of Reconfigurable Manufacturing Systems [link](https://arxiv.org/pdf/2511.07707)
- [arXiv251112] Operational machine learning for remote spectroscopic detection of CH$_{4}$ point sources [link](https://arxiv.org/pdf/2511.07719)
- [arXiv251112] FractalCloud: A Fractal-Inspired Architecture for Efficient Large-Scale Point Cloud Processing [link](https://arxiv.org/pdf/2511.07665)
- [arXiv251112] Hyperellipsoid Density Sampling: Exploitative Sequences to Accelerate High-Dimensional Optimization [link](https://arxiv.org/pdf/2511.07836)
- [arXiv251112] A Self-Improving Architecture for Dynamic Safety in Large Language Models [link](https://arxiv.org/pdf/2511.07645)
- [arXiv251112] Streaming Tensor Program: A streaming abstraction for dynamic parallelism [link](https://arxiv.org/pdf/2511.07776)
- [arXiv251112] Sharp Eyes and Memory for VideoLLMs: Information-Aware Visual Token Pruning for Efficient and Reliable VideoLLM Reasoning [link](https://arxiv.org/pdf/2511.08003)
- [arXiv251112] Improving Long-Range Interactions in Graph Neural Simulators via Hamiltonian Dynamics [link](https://arxiv.org/pdf/2511.08185)
- [arXiv251112] Dual-Kernel Graph Community Contrastive Learning [link](https://arxiv.org/pdf/2511.08287)
- [arXiv251112] LPPG-RL: Lexicographically Projected Policy Gradient Reinforcement Learning with Subproblem Exploration [link](https://arxiv.org/pdf/2511.08339)
- [arXiv251112] NeuCLIP: Efficient Large-Scale CLIP Training with Neural Normalizer Optimization [link](https://arxiv.org/pdf/2511.08417)
- [arXiv251112] Benchmarking Simulacra AI's Quantum Accurate Synthetic Data Generation for Chemical Sciences [link](https://arxiv.org/pdf/2511.07433)
- [arXiv251112] Emulating Radiative Transfer in Astrophysical Environments [link](https://arxiv.org/pdf/2511.08219)
- [arXiv251112] Generative AI Meets 6G and Beyond: Diffusion Models for Semantic Communications [link](https://arxiv.org/pdf/2511.08416)
- [arXiv251112] Galactification: painting galaxies onto dark matter only simulations using a transformer-based model [link](https://arxiv.org/pdf/2511.08438)

## 2025-11-13

**cs.DC total: 13**

- **[arXiv251113] FedPM: Federated Learning Using Second-order Optimization with Preconditioned Mixing of Local Parameters**
  - **tags:** [mlsys], [others], [federated learning, second-order optimization, preconditioned mixing, local parameter updates, convergence analysis]
  - **authors:** Hiro Ishii, Kenta Niwa, Hiroshi Sawada, Akinori Fujino, Noboru Harada, Rio Yokota
  - **institution:** Institute of Science Tokyo, NTT Communication Science Laboratories
  - **link:** https://arxiv.org/pdf/2511.09100
  - **Simple LLM Summary:** FedPM introduces a novel federated learning method that uses second-order optimization with preconditioned mixing of local parameters to address drift issues in local preconditioners. The approach decomposes ideal second-order updates into server-side parameter mixing and client-side local updates. Experimental results show significant improvements in test accuracy compared to conventional methods with simple mixing.

- **[arXiv251113] Attack-Centric by Design: A Program-Structure Taxonomy of Smart Contract Vulnerabilities**
  - **tags:** [sys], [blockchain security], [vulnerability taxonomy, static analysis, dynamic analysis, learning-based tools, root-cause analysis, program structure]
  - **authors:** Parsa Hedayatnia, Tina Tavakkoli, Hadi Amini, Mohammad Allahbakhsh, Haleh Amintoosi
  - **institution:** Ferdowsi University of Mashhad
  - **link:** https://arxiv.org/pdf/2511.09051
  - **Simple LLM Summary:** This paper introduces an attack-centric program-structure taxonomy that organizes smart contract vulnerabilities into eight root-cause families. The taxonomy provides a unified framework for vulnerability detection, audit reproducibility, and security education. It reveals coverage gaps in existing datasets and enables more interpretable security analysis through structural classification.

- **[arXiv251113] Minimize Your Critical Path with Combine-and-Exchange Locks**
  - **tags:** [sys], [concurrency and synchronization], [Combine-and-Exchange Scheduling, coroutines, userspace scheduling, cooperative multitasking, critical sections]
  - **authors:** Simon König, Lukas Epple, Christian Becker
  - **institution:** University of Stuttgart
  - **link:** https://arxiv.org/pdf/2511.09194
  - **Simple LLM Summary:** This paper introduces Combine-and-Exchange Scheduling (CES), a novel scheduling approach for userspace tasks like coroutines that keeps contended critical sections on the same thread while distributing parallelizable work across other threads. The method addresses limitations in existing userspace synchronization primitives that introduce unnecessary delays. The approach achieves 3-fold performance improvements in application benchmarks and 8-fold improvements in microbenchmarks.

- **[arXiv251113] An MLIR pipeline for offloading Fortran to FPGAs via OpenMP**
  - **tags:** [sys], [compiler systems], [MLIR, OpenMP, FPGA offloading, High-Level Synthesis, Flang]
  - **authors:** Gabriel Rodriguez-Canal, David Katz, Nick Brown
  - **institution:** EPCC, The University of Edinburgh
  - **link:** https://arxiv.org/pdf/2511.08713
  - **Simple LLM Summary:** This paper presents an MLIR-based compilation pipeline that enables Fortran code offloading to FPGAs using OpenMP target directives. The approach combines MLIR's OpenMP dialect with a High-Level Synthesis dialect to create a portable FPGA compilation flow. The work demonstrates that building upon existing MLIR components significantly reduces development effort and provides a flexible path for directive-based FPGA acceleration within the MLIR ecosystem.

- **[arXiv251113] CheetahGIS: Architecting a Scalable and Efficient Streaming Spatial Query Processing System**
  - **tags:** [sys], [spatial data processing], [Apache Flink Stateful Functions, grid-based indexing, load balancing, streaming spatial queries]
  - **authors:** Jiaping Cao, Ting Sun, Man Lung Yiu, Xiao Yan, Bo Tang
  - **institution:** Hong Kong Polytechnic University, Southern University of Science and Technology, Wuhan University
  - **link:** https://arxiv.org/pdf/2511.09262
  - **Simple LLM Summary:** CheetahGIS is a scalable streaming spatial query processing system built on Apache Flink Stateful Functions with optimizations including lightweight grid indexing and load balancing. The system efficiently handles massive moving objects and real-time spatial queries through its modular architecture. Experimental results demonstrate its excellent scalability and performance for various streaming spatial query types.

- **[arXiv251113] Evaluating HPC-Style CPU Performance and Cost in Virtualized Cloud Infrastructures**
  - **tags:** [sys], [cloud computing performance evaluation], [SPEC ACCEL, OpenMP workloads, virtualized cloud infrastructure, CPU performance benchmarking]
  - **authors:** Jay Tharwani, Shobhit Aggarwal, Arnab A Purkayastha
  - **institution:** University of North Carolina at Charlotte, The Citadel, Western New England University
  - **link:** https://arxiv.org/pdf/2511.08948
  - **Simple LLM Summary:** This paper evaluates HPC-style CPU performance and cost across four major cloud providers using SPEC ACCEL OpenMP workloads on Intel, AMD, and ARM instances. The study found that AWS delivers the fastest performance but at a premium cost, while OCI emerges as the most economical option despite slower runtimes. The research demonstrates that instance selection and provider choice significantly impact both runtime and pricing, suggesting workload priorities should guide deployment decisions.

- **[arXiv251113] No Cords Attached: Coordination-Free Concurrent Lock-Free Queues**
  - **tags:** [sys], [concurrent data structures], [Cyclic Memory Protection, lock-free queues, coordination-free, linearizability, bounded reclamation]
  - **authors:** Yusuf Motiwala
  - **institution:** mesibo, PatANN
  - **link:** https://arxiv.org/pdf/2511.09410
  - **Simple LLM Summary:** This paper introduces Cyclic Memory Protection (CMP), a coordination-free concurrent lock-free queue that uses bounded protection windows to provide practical reclamation guarantees. The method preserves strict FIFO ordering, unbounded capacity, and lock-free progress while significantly outperforming state-of-the-art queues by up to 4x under high contention. The work demonstrates that highly concurrent queues can maintain fundamental simplicity without compromising queue semantics.

- **[arXiv251113] Flex-MIG: Enabling Distributed Execution on MIG**
  - **tags:** [mlsys], [cluster infrastructure], [GPU sharing, MIG, fragmentation reduction, host-shared-memory collectives, one-to-many allocation]
  - **authors:** Myungsu Kim, Ikjun Yeom, Younghoon Kim
  - **institution:** SungKyunKwan University, Ajou University
  - **link:** https://arxiv.org/pdf/2511.09143
  - **Simple LLM Summary:** Flex-MIG is a software framework that replaces the conventional one-to-one allocation model with a one-to-many model for NVIDIA MIG GPUs, enabling distributed execution across MIG instances using host-shared-memory collectives. This approach eliminates drain-required reconfigurations and reduces fragmentation without hardware modifications. The system improves cluster efficiency by up to 17% in makespan across diverse workload traces.

- **[arXiv251113] Distribution and Management of Datacenter Load Decoupling**
  - **tags:** [sys], [datacenter energy management], [load adaptation, energy resources, datacenter-grid cooperation, power capacity decoupling]
  - **authors:** Liuzixuan Lin, Andrew A. Chien
  - **institution:** University of Chicago, Argonne National Laboratory
  - **link:** https://arxiv.org/pdf/2511.08936
  - **Simple LLM Summary:** This paper proposes datacenter load decoupling using energy resources to separate power capacity from grid load, enabling datacenter flexibility without compromising capacity. The study shows optimized distribution achieves 98% grid carbon reduction with 70% decoupling needs, and DC-grid cooperation provides 1.4x greater carbon reduction. Economic analysis suggests decoupling is viable on average but may require grid intervention due to site variations.

- **[arXiv251113] Experiences Building Enterprise-Level Privacy-Preserving Federated Learning to Power AI for Science**
  - **tags:** [mlsys], [cluster infrastructure], [federated learning, differential privacy, secure aggregation, confidential computing, hybrid cloud-HPC architecture]
  - **authors:** Zilinghan Li, Aditya Sinha, Yijiang Li, Kyle Chard, Kibaek Kim, Ravi Madduri
  - **institution:** Argonne National Laboratory, University of Illinois at Urbana-Champaign, University of Chicago
  - **link:** https://arxiv.org/pdf/2511.08998
  - **Simple LLM Summary:** The paper presents the Advanced Privacy-Preserving Federated Learning (APPFL) framework designed to enable collaborative AI model training without centralized data sharing. It focuses on building an enterprise-level system that bridges local prototyping with distributed deployment across heterogeneous infrastructures while ensuring privacy through techniques like differential privacy and secure aggregation. The framework aims to provide scalable, reliable, and privacy-preserving AI for scientific applications by addressing challenges in distributed execution across diverse computing environments.

- **[arXiv251113] Formal Verification of a Generic Algorithm for TDM Communication Over Inter Satellite Links**
  - **tags:** [mlsys], [fault-tolerance], [formal verification, CSP process algebra, model checking, deadlock freeness, successful termination]
  - **authors:** Miroslav Popovic, Marko Popovic, Pavle Vasiljevic, Miodrag Djukic
  - **institution:** University of Novi Sad, RT-RK Institute for Computer Based Systems
  - **link:** https://arxiv.org/pdf/2511.09485
  - **Simple LLM Summary:** This paper formally verifies a TDM communication algorithm for satellite constellations using CSP process algebra and the PAT model checker. The verification process involves constructing a CSP model from Python code and proving deadlock freeness and successful termination properties. The main conclusion is that the algorithm's correctness was automatically verified, ensuring its reliability for safety-critical edge systems.

- **[arXiv251113] SPADA: A Spatial Dataflow Architecture Programming Language**
  - **tags:** [mlsys], [others], [spatial dataflow architectures, programming language, dataflow semantics, network-on-chip, compiler design, stencil DSL]
  - **authors:** Lukas Gianinazzi, Tal Ben-Nun, Torsten Hoefler
  - **institution:** ETH Zurich, Lawrence Livermore National Laboratory
  - **link:** https://arxiv.org/pdf/2511.09447
  - **Simple LLM Summary:** SPADA is a programming language that provides precise control over data placement, dataflow patterns, and asynchronous operations for spatial dataflow architectures while abstracting low-level details. It enables developers to express complex parallel patterns in 6-8x less code than existing approaches while achieving near-ideal weak scaling. The language serves as both a high-level programming interface and intermediate representation for domain-specific languages, advancing both theoretical foundations and practical usability of spatial dataflow architectures.

- **[arXiv251113] LLM Inference Beyond a Single Node: From Bottlenecks to Mitigations with Fast All-Reduce Communication**
  - **tags:** [mlsys], [llm inference], [all-reduce, tensor parallelism, NVSHMEM, model parallelism, distributed inference]
  - **authors:** Prajwal Singhania, Siddharth Singh, Lannie Dalton Hough, Akarsh Srivastava, Harshitha Menon, Charles Fredrick Jekel, Abhinav Bhatele
  - **institution:** University of Maryland, Lawrence Livermore National Laboratory
  - **link:** https://arxiv.org/pdf/2511.09557
  - **Simple LLM Summary:** This paper introduces NVRAR, a hierarchical all-reduce algorithm using NVSHMEM to optimize communication bottlenecks in multi-node LLM inference. The method achieves up to 3.6x lower latency than NCCL and reduces end-to-end batch latency by 1.72x for large models like Llama 3.1 405B. The research demonstrates that optimized collective communication significantly improves performance in distributed inference workloads.


**cs.AI/cs.LG contains "reinforcement learning" total: 21**
- [arXiv251113] TIGER-MARL: Enhancing Multi-Agent Reinforcement Learning with Temporal Information through Graph-based Embeddings and Representations [link](https://arxiv.org/pdf/2511.08832)
- [arXiv251113] Planning in Branch-and-Bound: Model-Based Reinforcement Learning for Exact Combinatorial Optimization [link](https://arxiv.org/pdf/2511.09219)
- [arXiv251113] A Distributed Training Architecture For Combinatorial Optimization [link](https://arxiv.org/pdf/2511.09261)
- [arXiv251113] Interpretable by Design: Query-Specific Neural Modules for Explainable Reinforcement Learning [link](https://arxiv.org/pdf/2511.08749)
- [arXiv251113] Efficient Reasoning via Reward Model [link](https://arxiv.org/pdf/2511.09158)
- [arXiv251113] Iterated Population Based Training with Task-Agnostic Restarts [link](https://arxiv.org/pdf/2511.09190)
- [arXiv251113] Structured Uncertainty guided Clarification for LLM Agents [link](https://arxiv.org/pdf/2511.08798)
- [arXiv251113] Achieving Equilibrium under Utility Heterogeneity: An Agent-Attention Framework for Multi-Agent Multi-Objective Reinforcement Learning [link](https://arxiv.org/pdf/2511.08926)
- [arXiv251113] Potent but Stealthy: Rethink Profile Pollution against Sequential Recommendation via Bi-level Constrained Reinforcement Paradigm [link](https://arxiv.org/pdf/2511.09392)
- [arXiv251113] Diffusion Policies with Value-Conditional Optimization for Offline Reinforcement Learning [link](https://arxiv.org/pdf/2511.08922)
- [arXiv251113] Thinking Forward and Backward: Multi-Objective Reinforcement Learning for Retrieval-Augmented Reasoning [link](https://arxiv.org/pdf/2511.09109)
- [arXiv251113] Advancing Autonomous Emergency Response Systems: A Generative AI Perspective [link](https://arxiv.org/pdf/2511.09044)
- [arXiv251113] Towards a Generalisable Cyber Defence Agent for Real-World Computer Networks [link](https://arxiv.org/pdf/2511.09114)
- [arXiv251113] History-Aware Reasoning for GUI Agents [link](https://arxiv.org/pdf/2511.09127)
- [arXiv251113] UCO: A Multi-Turn Interactive Reinforcement Learning Method for Adaptive Teaching with Large Language Models [link](https://arxiv.org/pdf/2511.08873)
- [arXiv251113] AdaCuRL: Adaptive Curriculum Reinforcement Learning with Invalid Sample Mitigation and Historical Revisiting [link](https://arxiv.org/pdf/2511.09478)
- [arXiv251113] Quasi-Newton Compatible Actor-Critic for Deterministic Policies [link](https://arxiv.org/pdf/2511.09509)
- [arXiv251113] WMPO: World Model-based Policy Optimization for Vision-Language-Action Models [link](https://arxiv.org/pdf/2511.09515)
- [arXiv251113] Optimal Control of the Future via Prospective Foraging [link](https://arxiv.org/pdf/2511.08717)
- [arXiv251113] Practical considerations when designing an online learning algorithm for an app-based mHealth intervention [link](https://arxiv.org/pdf/2511.08719)
- [arXiv251113] DRL-Based Beam Positioning for LEO Satellite Constellations with Weighted Least Squares [link](https://arxiv.org/pdf/2511.08852)

**cs.AI/cs.LG contains "accelerate" total: 9**
- [arXiv251113] Data reuse enables cost-efficient randomized trials of medical AI models [link](https://arxiv.org/pdf/2511.08986)
- [arXiv251113] Leveraging Large Language Models for Use Case Model Generation from Software Requirements [link](https://arxiv.org/pdf/2511.09231)
- [arXiv251113] CoCo-MILP: Inter-Variable Contrastive and Intra-Constraint Competitive MILP Solution Prediction [link](https://arxiv.org/pdf/2511.09209)
- [arXiv251113] FSampler: Training Free Acceleration of Diffusion Sampling via Epsilon Extrapolation [link](https://arxiv.org/pdf/2511.09180)
- [arXiv251113] Enabling Agents to Communicate Entirely in Latent Space [link](https://arxiv.org/pdf/2511.09149)
- [arXiv251113] Tele-LLM-Hub: Building Context-Aware Multi-Agent LLM Systems for Telecom Networks [link](https://arxiv.org/pdf/2511.09087)
- [arXiv251113] Enhancing Explainability in Solar Energetic Particle Event Prediction: A Global Feature Mapping Approach [link](https://arxiv.org/pdf/2511.09475)
- [arXiv251113] Fluence Map Prediction with Deep Learning: A Transformer-based Approach [link](https://arxiv.org/pdf/2511.08645)
- [arXiv251113] Bio AI Agent: A Multi-Agent Artificial Intelligence System for Autonomous CAR-T Cell Therapy Development with Integrated Target Discovery, Toxicity Prediction, and Rational Molecular Design [link](https://arxiv.org/pdf/2511.08649)
