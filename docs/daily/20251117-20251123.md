# 20251117-20251123

## 2025-11-17

**cs.DC total: 9**

- **[arXiv251117] SMART: A Surrogate Model for Predicting Application Runtime in Dragonfly Systems**
  - **tags:** [mlsys], [others], [graph neural networks, large language models, parallel discrete event simulation, hybrid simulation, surrogate modeling]
  - **authors:** Xin Wang, Pietro Lodi Rizzini, Sourav Medya, Zhiling Lan
  - **institution:** University of Illinois Chicago, Argonne National Laboratory
  - **link:** https://arxiv.org/pdf/2511.11111
  - **Simple LLM Summary:** The paper presents SMART, a surrogate model that combines graph neural networks and large language models to predict application runtime in Dragonfly networks. The model captures both spatial and temporal patterns from router data to address workload interference challenges. SMART outperforms existing baselines and enables efficient hybrid simulation of Dragonfly network systems.

- **[arXiv251117] Beyond Exascale: Dataflow Domain Translation on a Cerebras Cluster**
  - **tags:** [sys], [high performance computing], [Domain Translation algorithm, shallow-water equations, finite difference methods, stencil computations, cluster computing]
  - **authors:** Tomas Oppelstrup, Nicholas Giamblanco, Delyan Z. Kalchev, Ilya Sharapov, Mark Taylor, Dirk Van Essendelft, Sivasankaran Rajamanickam, Michael James
  - **institution:** Cerebras Systems, Sandia National Laboratories, National Energy Technology Laboratory
  - **link:** https://arxiv.org/pdf/2511.11542
  - **Simple LLM Summary:** This paper introduces a novel Domain Translation algorithm that overcomes limitations of traditional domain decomposition methods for physical simulations. The method achieves 1.6 million time steps per second and 84 PFLOP/s performance on a 64-node Cerebras CS-3 cluster, demonstrating 90% of peak performance for planetary-scale tsunami modeling using shallow-water equations.

- **[arXiv251117] FengHuang: Next-Generation Memory Orchestration for AI Inferencing**
  - **tags:** [mlsys], [llm inference], [memory disaggregation, multi-tier shared-memory, active tensor paging, near-memory compute]
  - **authors:** Jiamin Li, Lei Qu, Tao Zhang, Grigory Chirkov, Shuotao Xu, Peng Cheng, Lidong Zhou
  - **institution:** Microsoft Research
  - **link:** https://arxiv.org/pdf/2511.10753
  - **Simple LLM Summary:** The paper proposes FengHuang, a disaggregated AI infrastructure platform that uses multi-tier shared-memory architecture with active tensor paging and near-memory compute to overcome memory and communication bottlenecks. Simulation results show the system achieves significant memory capacity reduction, GPU compute savings, and faster inter-GPU communication while maintaining performance for large language model inference workloads.

- **[arXiv251117] Cascading Bandits With Feedback**
  - **tags:** [mlsys], [llm inference], [cascade bandits, explore-then-commit, action elimination, lower confidence bound, thompson sampling]
  - **authors:** R Sri Prakash, Nikhil Karamchandani, Sharayu Moharir
  - **institution:** IIITDM Kancheepuram, IIT Bombay
  - **link:** https://arxiv.org/pdf/2511.10938
  - **Simple LLM Summary:** This paper analyzes four decision-making policies for cascade bandits in edge inference systems. The study shows that LCB and Thompson Sampling achieve constant regret by continuously adapting based on feedback, while Explore-then-Commit and Action Elimination incur suboptimal regret due to fixed ordering commitments. Adaptive policies are crucial for efficient edge inference under uncertainty.

- **[arXiv251117] SemanticNN: Compressive and Error-Resilient Semantic Offloading for Extremely Weak Devices**
  - **tags:** [mlsys], [others], [semantic codec, bit error rate-aware decoder, soft quantization, feature-augmentation learning, XAI-based asymmetry compensation]
  - **authors:** Jiaming Huang, Yi Gao, Fuchang Pan, Renjie Li, Wei Dong
  - **institution:** Zhejiang University
  - **link:** https://arxiv.org/pdf/2511.11038
  - **Simple LLM Summary:** SemanticNN is a semantic codec system that tolerates bit-level transmission errors while maintaining semantic-level correctness for device-edge collaborative inference. It uses BER-aware decoders, soft quantization encoders, and novel training strategies to handle asymmetric resources. Experimental results show it reduces feature transmission volume by 56.82-344.83x while maintaining superior inference accuracy under varying error rates.

- **[arXiv251117] HPCAgentTester: A Multi-Agent LLM Approach for Enhanced HPC Unit Test Generation**
  - **tags:** [mlsys], [others], [multi-agent LLM, OpenMP, MPI, unit test generation, parallel computing, critique loop]
  - **authors:** Rabimba Karanjai, Lei Xu, Weidong Shi
  - **institution:** University of Houston, Kent State University
  - **link:** https://arxiv.org/pdf/2511.10860
  - **Simple LLM Summary:** This paper introduces HPCAgentTester, a multi-agent LLM framework that uses specialized agents (Recipe Agent and Test Agent) working collaboratively through a critique loop to generate unit tests for HPC software. The system produces compilable and functionally correct tests targeting parallel execution constructs in OpenMP and MPI. Evaluation shows it significantly improves test compilation rates and correctness compared to standalone LLMs, effectively identifying subtle bugs in parallel software systems.

- **[arXiv251117] A Unified Convergence Analysis for Semi-Decentralized Learning: Sampled-to-Sampled vs. Sampled-to-All Communication**
  - **tags:** [mlsys], [others], [federated learning, semi-decentralized learning, local SGD, device-to-device communication, model aggregation, convergence analysis]
  - **authors:** Angelo Rodio, Giovanni Neglia, Zheng Chen, Erik G. Larsson
  - **institution:** Linköping University, Inria
  - **link:** https://arxiv.org/pdf/2511.11560
  - **Simple LLM Summary:** This paper analyzes two communication strategies (sampled-to-sampled vs sampled-to-all) in semi-decentralized federated learning where devices primarily use device-to-device communication with periodic server interactions. The authors develop a unified convergence framework that accounts for sampling rate, server aggregation frequency, and network connectivity. Their analysis reveals that the optimal strategy depends primarily on data heterogeneity across devices, providing practical design guidelines for semi-decentralized FL deployments.

- **[arXiv251117] UFO$^3$: Weaving the Digital Agent Galaxy**
  - **tags:** [mlsys], [cluster infrastructure], [TaskConstellation, distributed DAG, asynchronous execution, adaptive recovery, dynamic optimization, Agent Interaction Protocol]
  - **authors:** Chaoyun Zhang, Liqun Li, He Huang, Chiming Ni, Bo Qiao, Si Qin, Yu Kang, Minghua Ma, Qingwei Lin, Saravan Rajmohan, Dongmei Zhang
  - **institution:** Microsoft, ZJU-UIUC Institute
  - **link:** https://arxiv.org/pdf/2511.11332
  - **Simple LLM Summary:** UFO³ introduces a system that models user requests as mutable TaskConstellations - distributed DAGs of atomic subtasks executed across heterogeneous devices. The system enables asynchronous execution, adaptive recovery, and dynamic optimization through its Constellation Orchestrator and Agent Interaction Protocol. Evaluation shows it achieves 70.9% task success rate, exposes parallelism, and reduces latency by 31% while providing resilient orchestration across diverse computing devices.

- **[arXiv251117] EarthSight: A Distributed Framework for Low-Latency Satellite Intelligence**
  - **tags:** [mlsys], [multi-modal inference], [distributed runtime framework, multi-task inference, shared backbones, ground-station query scheduler, dynamic filter ordering, resource-aware adaptive decisions]
  - **authors:** Ansel Kaplan Erol, Seungjun Lee, Divya Mahajan
  - **institution:** Georgia Institute of Technology, KAIST
  - **link:** https://arxiv.org/pdf/2511.10834
  - **Simple LLM Summary:** EarthSight introduces a distributed framework that coordinates satellite constellations and ground stations to perform onboard multi-task inference using shared backbones, intelligent query scheduling, and dynamic filter ordering. This approach enables satellites to prioritize and analyze imagery in orbit while conserving bandwidth and power resources. The system reduces average compute time by 1.9x and cuts 90th percentile latency from 51 to 21 minutes compared to state-of-the-art baselines.


**cs.AI/cs.LG contains "reinforcement learning" total: 18**
- [arXiv251117] Aligning Machiavellian Agents: Behavior Steering via Test-Time Policy Shaping [link](https://arxiv.org/pdf/2511.11551)
- [arXiv251117] Incorporating Spatial Information into Goal-Conditioned Hierarchical Reinforcement Learning via Graph Representations [link](https://arxiv.org/pdf/2511.10872)
- [arXiv251117] Honesty over Accuracy: Trustworthy Language Models through Reinforced Hesitation [link](https://arxiv.org/pdf/2511.11500)
- [arXiv251117] Context-aware Adaptive Visualizations for Critical Decision Making [link](https://arxiv.org/pdf/2511.11476)
- [arXiv251117] VIDEOP2R: Video Understanding from Perception to Reasoning [link](https://arxiv.org/pdf/2511.11113)
- [arXiv251117] LoRaCompass: Robust Reinforcement Learning to Efficiently Search for a LoRa Tag [link](https://arxiv.org/pdf/2511.11190)
- [arXiv251117] ARCTraj: A Dataset and Benchmark of Human Reasoning Trajectories for Abstract Problem Solving [link](https://arxiv.org/pdf/2511.11079)
- [arXiv251117] When Data is the Algorithm: A Systematic Study and Curation of Preference Optimization Datasets [link](https://arxiv.org/pdf/2511.10985)
- [arXiv251117] From Efficiency to Adaptivity: A Deeper Look at Adaptive Reasoning in Large Language Models [link](https://arxiv.org/pdf/2511.10788)
- [arXiv251117] Multi-Phase Spacecraft Trajectory Optimization via Transformer-Based Reinforcement Learning [link](https://arxiv.org/pdf/2511.11402)
- [arXiv251117] STaR: Towards Cognitive Table Reasoning via Slow-Thinking Large Language Models [link](https://arxiv.org/pdf/2511.11233)
- [arXiv251117] Scalable Population Training for Zero-Shot Coordination [link](https://arxiv.org/pdf/2511.11083)
- [arXiv251117] Data Poisoning Vulnerabilities Across Healthcare AI Architectures: A Security Threat Analysis [link](https://arxiv.org/pdf/2511.11020)
- [arXiv251117] Robust and Efficient Communication in Multi-Agent Reinforcement Learning [link](https://arxiv.org/pdf/2511.11393)
- [arXiv251117] RLSLM: A Hybrid Reinforcement Learning Framework Aligning Rule-Based Social Locomotion Model with Human Social Norms [link](https://arxiv.org/pdf/2511.11323)
- [arXiv251117] Understanding the Nature of Depth-1 Equivariant Quantum Circuit [link](https://arxiv.org/pdf/2511.10756)
- [arXiv251117] Behaviour Policy Optimization: Provably Lower Variance Return Estimates for Off-Policy Reinforcement Learning [link](https://arxiv.org/pdf/2511.10843)
- [arXiv251117] MarsRL: Advancing Multi-Agent Reasoning System via Reinforcement Learning with Agentic Pipeline Parallelism [link](https://arxiv.org/pdf/2511.11373)

**cs.AI/cs.LG contains "accelerate" total: 9**
- [arXiv251117] MMA-Sim: Bit-Accurate Reference Model of Tensor Cores and Matrix Cores [link](https://arxiv.org/pdf/2511.10909)
- [arXiv251117] FarSkip-Collective: Unhobbling Blocking Communication in Mixture of Experts Models [link](https://arxiv.org/pdf/2511.11505)
- [arXiv251117] LiteAttention: A Temporal Sparse Attention for Diffusion Transformers [link](https://arxiv.org/pdf/2511.11062)
- [arXiv251117] Benchmarking Quantum Kernels Across Diverse and Complex Data [link](https://arxiv.org/pdf/2511.10831)
- [arXiv251117] Improving Continual Learning of Knowledge Graph Embeddings via Informed Initialization [link](https://arxiv.org/pdf/2511.11118)
- [arXiv251117] AIonopedia: an LLM agent orchestrating multimodal learning for ionic liquid discovery [link](https://arxiv.org/pdf/2511.11257)
- [arXiv251117] Virtual Width Networks [link](https://arxiv.org/pdf/2511.11238)
- [arXiv251117] Human-AI collaborative autonomous synthesis with pulsed laser deposition for remote epitaxy [link](https://arxiv.org/pdf/2511.11558)
- [arXiv251117] LAD-BNet: Lag-Aware Dual-Branch Networks for Real-Time Energy Forecasting on Edge Devices [link](https://arxiv.org/pdf/2511.10680)

## 2025-11-18

**cs.DC total: 53**

- **[arXiv251118] Machine learning-based cloud resource allocation algorithms: a comprehensive comparative review**
  - **tags:** [mlsys], [cluster infrastructure], [deep reinforcement learning, neural networks, multi-agent systems, hybrid architectures, edge computing]
  - **authors:** Deep Bodra, Sushil Khairnar
  - **institution:** Harrisburg University of Science and Technology, Virginia Tech
  - **link:** https://arxiv.org/pdf/2511.11603
  - **Simple LLM Summary:** This paper compares machine learning algorithms for cloud resource allocation, including deep reinforcement learning, neural networks, and multi-agent systems. The analysis shows that hybrid AI/ML architectures consistently outperform single-method approaches, with edge computing environments demonstrating the highest deployment readiness for these resource allocation strategies.

- **[arXiv251118] The Anatomy of a Triton Attention Kernel**
  - **tags:** [mlsys], [llm inference], [triton, paged attention, auto-tuning, just-in-time compilation, cross-platform kernels]
  - **authors:** Burkhard Ringlein, Jan van Lunteren, Radu Stoica, Thomas Parnell
  - **institution:** IBM Research
  - **link:** https://arxiv.org/pdf/2511.11581
  - **Simple LLM Summary:** This paper develops a portable paged attention kernel using Triton's domain-specific language that achieves cross-platform state-of-the-art performance on both NVIDIA and AMD GPUs. The kernel eliminates the need for low-level hand-tuning through parameter auto-tuning and system-level optimizations. The results demonstrate that open-source domain-specific languages can enable efficient LLM inference across different hardware vendors while maintaining performance portability.

- **[arXiv251118] ACE-GNN: Adaptive GNN Co-Inference with System-Aware Scheduling in Dynamic Edge Environments**
  - **tags:** [mlsys], [others], [device-edge co-inference, pipeline parallelism, data parallelism, adaptive scheduling, batch inference, system-aware optimization]
  - **authors:** Ao Zhou, Jianlei Yang, Tong Qiao, Yingjie Qi, Xinming Wei, Cenlin Duan, Weisheng Zhao, Chunming Hu
  - **institution:** Beihang University
  - **link:** https://arxiv.org/pdf/2511.11586
  - **Simple LLM Summary:** ACE-GNN introduces an adaptive GNN co-inference framework that dynamically schedules between pipeline and data parallelism to optimize performance in dynamic edge environments. The system uses runtime scheme optimization with performance prediction and specialized communication middleware to maintain stable inference. Experiments show significant improvements with up to 12.7× speedup and 82.3% energy savings compared to existing methods.

- **[arXiv251118] Evaluating Large Language Models for Workload Mapping and Scheduling in Heterogeneous HPC Systems**
  - **tags:** [mlsys], [llm inference], [constraint-based optimization, workload mapping, scheduling, makespan optimization, natural language reasoning]
  - **authors:** Aasish Kumar Sharma, Julian Kunkel
  - **institution:** Georg-August-Universität Göttingen
  - **link:** https://arxiv.org/pdf/2511.11612
  - **Simple LLM Summary:** This study evaluates 21 large language models on their ability to perform HPC workload mapping and scheduling from natural language descriptions. The models were tested on assigning tasks to nodes while computing makespan and explaining reasoning under given constraints. Results show that while some LLMs can reconstruct optimal schedules, most struggle with precise timing and dependency enforcement, positioning them better as explainable co-pilots rather than autonomous optimization solvers.

- **[arXiv251118] Distributed Q-learning-based Shortest-Path Tree Construction in IoT Sensor Networks**
  - **tags:** [mlsys], [others], [Q-learning, distributed algorithms, shortest-path tree, IoT sensor networks, reinforcement learning]
  - **authors:** Van-Vi Vo, Tien-Dung Nguyen, Duc-Tai Le, Hyunseung Choo
  - **institution:** Sungkyunkwan University, Hanoi University of Science and Technology
  - **link:** https://arxiv.org/pdf/2511.11598
  - **Simple LLM Summary:** This paper proposes a distributed Q-learning framework for constructing shortest-path trees in IoT sensor networks, where nodes independently learn optimal routing decisions using local information. The method achieves near-optimal routing accuracy (over 99% for large networks) while reducing communication overhead and adapting to topology changes. The approach demonstrates superior scalability and energy efficiency compared to traditional centralized and flooding-based routing protocols.

- **[arXiv251118] PACE Solver Description: twin_width_fmi**
  - **tags:** [ai], [graph-algorithms], [greedy-heuristic, simulated-annealing, iterative-greedy, local-search, graph-reductions]
  - **authors:** David Balaban, Adrian Miclăuş
  - **institution:** International Computer High School of Bucharest, University of Bucharest
  - **link:** https://arxiv.org/pdf/2511.11605
  - **Simple LLM Summary:** The paper presents hedom5, an iterative-greedy heuristic for the Minimum Dominating Set problem that combines greedy construction, backward pruning, and local improvement steps. This approach outperformed both a standard greedy baseline and a simulated annealing variant on PACE 2025 benchmark instances. The authors selected hedom5 as their final submission due to its superior performance in finding smaller dominating sets.

- **[arXiv251118] Why Should the Server Do It All?: A Scalable, Versatile, and Model-Agnostic Framework for Server-Light DNN Inference over Massively Distributed Clients via Training-Free Intermediate Feature Compression**
  - **tags:** [mlsys], [llm inference], [intermediate feature compression, asymmetric top-K filtering, magnitude-splitting, adaptive bit quantization, split computing]
  - **authors:** Mingyu Sung, Suhwan Im, Daeho Bang, Il-Min Kim, Sangseok Yun, Jae-Mo Kang
  - **institution:** Kyungpook National University, Queen's University, Pukyong National University
  - **link:** https://arxiv.org/pdf/2511.11608
  - **Simple LLM Summary:** The paper introduces SLICER, a training-free framework that compresses intermediate features in split computing using sparsification and quantization techniques. This approach reduces communication volume by up to 10x and server GPU time by up to 4.4x while maintaining task quality. The method works with off-the-shelf models without retraining, enabling scalable distributed inference.

- **[arXiv251118] Mind the Gap: Revealing Inconsistencies Across Heterogeneous AI Accelerators**
  - **tags:** [mlsys], [others], [differential testing, automated pipeline, model synthesis, operator implementations, numerical discrepancies, compilation failures]
  - **authors:** Elliott Wen, Sean Ma, Ewan Tempero, Jens Dietrich, Daniel Luo, Jiaxing Shen, Kaiqi Zhao, Bruce Sham, Yousong Song, Jiayi Hua, Jia Hong
  - **institution:** The University of Auckland, Hong Kong Polytechnic University, Victoria University of Wellington, Harbin Institute of Technology, Lingnan University
  - **link:** https://arxiv.org/pdf/2511.11601
  - **Simple LLM Summary:** This paper presents an empirical study using differential testing with an automated pipeline that synthesizes over 100,000 variant models from real-world examples. The study reveals significant inconsistencies across heterogeneous AI accelerators, finding that newer platforms from Mac and Huawei support fewer operators and exhibit higher output discrepancy rates. These results highlight challenges in achieving consistent machine learning behavior across diverse hardware ecosystems.

- **[arXiv251118] Beyond the GPU: The Strategic Role of FPGAs in the Next Wave of AI**
  - **tags:** [mlsys], [others], [FPGA, hardware reconfiguration, parallel pipelines, deterministic timing, energy efficiency, SoC integration, partial reconfiguration]
  - **authors:** Arturo Urías Jiménez
  - **institution:** Instituto Tecnológico y de Estudios Superiores de Monterrey
  - **link:** https://arxiv.org/pdf/2511.11614
  - **Simple LLM Summary:** This paper proposes using Field-Programmable Gate Arrays (FPGAs) as reconfigurable hardware platforms that can directly map AI algorithms into device logic. The method enables parallel processing pipelines with deterministic timing and reduced power consumption through hardware-algorithm co-design. The main conclusion is that FPGAs offer strategic advantages over GPUs for AI workloads requiring predictable performance, deep customization, and edge deployment near sensors.

- **[arXiv251118] Parameter-Efficient and Personalized Federated Training of Generative Models at the Edge**
  - **tags:** [mlsys], [llm training], [federated learning, LoRA, parameter-efficient fine-tuning, FedAvg, client adapters]
  - **authors:** Kabir Khan, Manju Sarkar, Anita Kar, Suresh Ghosh
  - **institution:** San Francisco State University, University of Lakhimpur, Manipur University, Lakshadweep University
  - **link:** https://arxiv.org/pdf/2511.11585
  - **Simple LLM Summary:** The paper proposes FedGen-Edge, a federated learning framework that uses Low-Rank Adaptation (LoRA) to train lightweight client adapters while keeping a pre-trained global backbone frozen. This approach reduces communication costs by over 99%, stabilizes training with non-IID data, and enables personalization through local adapter tuning. Experiments show improved performance and faster convergence on language modeling and image generation tasks compared to full-model federated averaging.

- **[arXiv251118] AnchorTP: Resilient LLM Inference with State-Preserving Elastic Tensor Parallelism**
  - **tags:** [mlsys], [llm inference], [elastic tensor parallelism, state preservation, continuous minimal migration, KV cache preservation, bandwidth-aware planning]
  - **authors:** Wendong Xu, Chujie Chen, He Xiao, Kuan Li, Jing Xiong, Chen Zhang, Wenyong Zhou, Chaofan Tao, Yang Bai, Bei Yu, Ngai Wong
  - **institution:** The University of Hong Kong, Institute of Computing Technology Chinese Academy of Sciences, Hong Kong University of Science and Technology, Chinese University of Hong Kong
  - **link:** https://arxiv.org/pdf/2511.11617
  - **Simple LLM Summary:** AnchorTP introduces a state-preserving elastic tensor parallelism framework that maintains model parameters and KV caches during GPU failures. It uses a bandwidth-aware planner with Continuous Minimal Migration algorithm and execution scheduler to minimize data movement during recovery. The system reduces Time to First Success by up to 11x and Time to Peak by up to 59% compared to restart-and-reload approaches.

- **[arXiv251118] AIvailable: A Software-Defined Architecture for LLM-as-a-Service on Heterogeneous and Legacy GPUs**
  - **tags:** [mlsys], [llm inference], [software-defined architecture, VRAM-aware allocation, heterogeneous GPU support, load balancing, dynamic reallocation]
  - **authors:** Pedro Antunes, Ana Rita Ortigoso, Gabriel Vieira, Daniel Fuentes, Luís Frazão, Nuno Costa, António Pereira
  - **institution:** Polytechnic University of Leiria
  - **link:** https://arxiv.org/pdf/2511.11621
  - **Simple LLM Summary:** AIvailable introduces a software-defined architecture for LLM-as-a-Service that enables efficient inference across heterogeneous and legacy GPU nodes through dynamic VRAM-aware allocation. The system provides a unified client interface and fully GPU-accelerated inference without CPU fallbacks. This approach allows resource-constrained organizations to repurpose legacy GPUs for running diverse open LLMs, democratizing access to generative AI.

- **[arXiv251118] Exploring Parallelism in FPGA-Based Accelerators for Machine Learning Applications**
  - **tags:** [mlsys], [others], [speculative backpropagation, FPGA acceleration, OpenMP parallelization, MNIST dataset]
  - **authors:** Sed Centeno, Christopher Sprague, Arnab A Purkayastha, Ray Simar, Neeraj Magotra
  - **institution:** Western New England University, Rice University
  - **link:** https://arxiv.org/pdf/2511.11640
  - **Simple LLM Summary:** This paper implements speculative backpropagation using OpenMP to overlap forward and backward passes in neural network training. The method achieved up to 24% overall speedup and 35% step-level speedup on MNIST while maintaining accuracy within 3-4% of baseline. The work demonstrates the potential for hardware acceleration through planned FPGA synthesis.

- **[arXiv251118] Range Asymmetric Numeral Systems-Based Lightweight Intermediate Feature Compression for Split Computing of Deep Neural Networks**
  - **tags:** [mlsys], [others], [rANS encoding, asymmetric integer quantization, sparse tensor representation, split computing, intermediate feature compression]
  - **authors:** Mingyu Sung, Suhwan Im, Vikas Palakonda, Jae-Mo Kang
  - **institution:** Kyungpook National University
  - **link:** https://arxiv.org/pdf/2511.11664
  - **Simple LLM Summary:** This paper proposes a lightweight compression framework using Range Asymmetric Numeral Systems encoding with asymmetric integer quantization and sparse tensor representation to reduce transmission overhead in split computing. The method maintains near-baseline accuracy across various neural architectures and benchmarks while achieving sub-millisecond encoding/decoding latency. It effectively addresses communication bottlenecks in bandwidth-constrained environments without requiring network modifications.

- **[arXiv251118] HeteroSTA: A CPU-GPU Heterogeneous Static Timing Analysis Engine with Holistic Industrial Design Support**
  - **tags:** [mlsys], [GPU kernels], [CPU-GPU heterogeneous computing, static timing analysis, delay calculation models, graph propagation, path search, SDC constraints, API integration]
  - **authors:** Zizheng Guo, Haichuan Liu, Xizhe Shi, Shenglu Hua, Zuodong Zhang, Chunyuan Zhao, Runsheng Wang, Yibo Lin
  - **institution:** Peking University
  - **link:** https://arxiv.org/pdf/2511.11660
  - **Simple LLM Summary:** HeteroSTA is a CPU-GPU heterogeneous static timing analysis engine that provides end-to-end GPU acceleration for both graph-based and path-based timing queries. It supports industry-standard formats and offers versatile delay calculation models without relying on external tools. The system demonstrates remarkable runtime speed-up while maintaining comparable quality in various EDA applications.

- **[arXiv251118] Characterizing and Understanding Energy Footprint and Efficiency of Small Language Model on Edges**
  - **tags:** [mlsys], [llm inference], [edge computing, GPU acceleration, memory bandwidth, model architecture optimization, power efficiency benchmarking]
  - **authors:** Md Romyull Islam, Bobin Deng, Nobel Dhar, Tu N. Nguyen, Selena He, Yong Shi, Kun Suo
  - **institution:** Kennesaw State University
  - **link:** https://arxiv.org/pdf/2511.11624
  - **Simple LLM Summary:** This paper evaluates the energy efficiency of five small language models (SLMs) deployed on edge devices including Raspberry Pi 5 and Jetson platforms. The study found that Jetson Orin Nano with GPU acceleration achieves the highest energy-to-performance ratio, while Llama 3.2 provides the best balance of accuracy and power efficiency. Key factors influencing energy efficiency include GPU acceleration, memory bandwidth, and model architecture.

- **[arXiv251118] Mixture-of-Schedulers: An Adaptive Scheduling Agent as a Learned Router for Expert Policies**
  - **tags:** [mlsys], [others], [adaptive scheduling, machine learning model, time-weighted probability voting, sched_ext framework, workload pattern recognition]
  - **authors:** Xinbo Wang, Shian Jia, Ziyang Huang, Jing Cao, Mingli Song
  - **institution:** Zhejiang University, HangZhou City University
  - **link:** https://arxiv.org/pdf/2511.11628
  - **Simple LLM Summary:** The paper proposes an Adaptive Scheduling Agent (ASA) that uses a machine learning model to dynamically select optimal scheduling policies from a portfolio of expert schedulers at runtime. This approach combines offline training of a hardware-agnostic workload recognition model with online decision-making using time-weighted probability voting. Evaluation shows ASA outperforms the default Linux scheduler in 86.4% of test scenarios and achieves near-optimal performance in most cases.

- **[arXiv251118] OSGym: Super-Scalable Distributed Data Engine for Generalizable Computer Agents**
  - **tags:** [mlsys], [cluster infrastructure], [distributed data engine, OS replicas, parallelization, supervised fine-tuning, reinforcement learning]
  - **authors:** Zengyi Qin, Jinyuan Chen, Yunze Man, Shengcao Cao, Ziqi Pang, Zhuoyuan Wang, Xin Sun, Gen Lin, Han Fang, Ling Zhu, Zixin Xie, Zibu Wei, Tianshu Ran, Haoran Geng, Xander Wu, Zachary Bright, Qizhen Sun, Rui Wang, Yuyang Cai, Song Wang, Jiace Zhao, Han Cao, Yeyang Zhou, Tianrui Liu, Ray Pan, Chongye Yang, Xiang Ren, Bo Zhang, Yutong Ban, Jitendra Malik, Brian Anthony, Pieter Abbeel
  - **institution:** MIT, UIUC, CMU, USC, UVA, UC Berkeley
  - **link:** https://arxiv.org/pdf/2511.11672
  - **Simple LLM Summary:** OSGym is a super-scalable distributed data engine that can parallelize over a thousand OS replicas for training computer agents across diverse tasks. It enables efficient data collection, supervised fine-tuning, and reinforcement learning pipelines at low cost. Models trained with OSGym outperform state-of-the-art baselines, demonstrating its potential to advance agent research scalability and universality.

- **[arXiv251118] DIAP: A Decentralized Agent Identity Protocol with Zero-Knowledge Proofs and a Hybrid P2P Stack**
  - **tags:** [mlsys], [cluster infrastructure], [zero-knowledge proofs, IPFS, Libp2p GossipSub, Iroh, QUIC, DID-Key, Noir]
  - **authors:** Yuanjie Liu, Wenpeng Xing, Ye Zhou, Gaowei Chang, Changting Lin, Meng Han
  - **institution:** Zhejiang University, Binjiang Institute of Zhejiang University, GenTel.io, ANP Open Source Community
  - **link:** https://arxiv.org/pdf/2511.11619
  - **Simple LLM Summary:** DIAP proposes a decentralized agent identity protocol that binds agent identities to IPFS content identifiers and uses zero-knowledge proofs for ownership verification. The framework combines a hybrid P2P stack with Libp2p for discovery and Iroh for data exchange, eliminating the need for centralized intermediaries. This establishes a practical foundation for trustless, privacy-preserving autonomous agent ecosystems and A2A economies.

- **[arXiv251118] A Structure-Agnostic Co-Tuning Framework for LLMs and SLMs in Cloud-Edge Systems**
  - **tags:** [mlsys], [llm training], [co-tuning, structure-agnostic mutual learning, distilled proxy models, cloud-edge systems, knowledge exchange]
  - **authors:** Yuze Liu, Yunhan Wang, Tiehua Zhang, Zhishu Shen, Cheng Peng, Libing Wu, Feng Xia, Jiong Jin
  - **institution:** Swinburne University of Technology, Tongji University, Wuhan University of Technology, INFLY TECH, Wuhan University, RMIT University
  - **link:** https://arxiv.org/pdf/2511.11678
  - **Simple LLM Summary:** This paper proposes Co-PLMs, a structure-agnostic co-tuning framework that enables collaborative training between large language models on cloud servers and small language models on edge devices using distilled proxy models as bridges. The framework facilitates knowledge exchange between heterogeneous models while preserving domain-specific insights. Experimental results show Co-PLMs outperforms state-of-the-art methods with average improvements of 5.38% in Rouge-L and 4.88% in EM scores.

- **[arXiv251118] A Meta-Heuristic Load Balancer for Cloud Computing Systems**
  - **tags:** [sys], [cloud resource management], [genetic algorithm, meta-heuristic, load balancing, service migration, resource utilization]
  - **authors:** Leszek Sliwko, Vladimir Getov
  - **institution:** University of Westminster
  - **link:** https://arxiv.org/pdf/2511.11721
  - **Simple LLM Summary:** This paper proposes a meta-heuristic load balancing strategy using a novel genetic algorithm seeded with outputs from other meta-heuristics for cloud computing systems. The approach aims to allocate services without overloading nodes while maintaining system stability with minimum cost. Experimental results demonstrate the effectiveness of the proposed method in managing cloud resources efficiently.

- **[arXiv251118] Federated Learning for Pediatric Pneumonia Detection: Enabling Collaborative Diagnosis Without Sharing Patient Data**
  - **tags:** [mlsys], [others], [federated learning, chest x-ray classification, non-IID data, privacy-preserving training]
  - **authors:** Daniel M. Jimenez-Gutierrez, Enrique Zuazua, Joaquin Del Rio, Oleksii Sliusarenko, Xabi Uribe-Etxebarria
  - **institution:** Sherpa.ai
  - **link:** https://arxiv.org/pdf/2511.11714
  - **Simple LLM Summary:** This paper uses federated learning to enable multiple hospitals to collaboratively train a pneumonia detection model from chest X-rays without sharing patient data. The method achieved significant performance improvements (47.5% accuracy gain and 50.0% ROC-AUC gain) over single-hospital models while maintaining data privacy. The results demonstrate that federated learning enables secure, high-performing medical diagnosis across healthcare networks while keeping data local.

- **[arXiv251118] ECCENTRIC: Edge-Cloud Collaboration Framework for Distributed Inference Using Knowledge Adaptation**
  - **tags:** [mlsys], [others], [knowledge adaptation, edge-cloud collaboration, distributed inference, Pareto optimization, model compression]
  - **authors:** Mohammad Mahdi Kamani, Zhongwei Cheng, Lin Chen
  - **institution:** Wyze Labs, Inc.
  - **link:** https://arxiv.org/pdf/2511.11719
  - **Simple LLM Summary:** The paper proposes ECCENTRIC, a framework that uses knowledge adaptation between edge and cloud models to achieve optimal trade-offs between computation, communication, and performance in distributed inference systems. This approach reduces both computation and communication costs while maintaining high performance. Empirical results on classification and object detection tasks demonstrate the framework's effectiveness.

- **[arXiv251118] How Machine Learning-Data Driven Replication Strategies Enhance Fault Tolerance in Large-Scale Distributed Systems**
  - **tags:** [mlsys], [fault-tolerance], [machine learning, predictive analytics, reinforcement learning, data replication, adaptive mechanisms]
  - **authors:** Almond Kiruthu Murimi
  - **institution:** Kabarak University, Carnegie Mellon University
  - **link:** https://arxiv.org/pdf/2511.11749
  - **Simple LLM Summary:** This paper proposes using machine learning techniques, specifically predictive analytics and reinforcement learning, to create adaptive data replication strategies that forecast failures and optimize data placement in real-time. It concludes that ML-driven approaches significantly enhance fault tolerance in distributed systems compared to traditional static methods, though implementation challenges remain for real-world deployment.

- **[arXiv251118] Harli: Harvest Underutilized Resources in LLM Serving with Finetuning Tasks**
  - **tags:** [mlsys], [llm inference], [parameter-efficient finetuning, memory allocator, latency predictor, QoS scheduler, resource co-location]
  - **authors:** Ao Xu, Han Zhao, Weihao Cui, Quan Chen, Yukang Chen, Shulai Zhang, Shuang Chen, Jiemin Jiang, Zhibin Yu, Minyi Guo
  - **institution:** Shanghai Jiao Tong University, Zhejiang University, Chinese Academy of Science
  - **link:** https://arxiv.org/pdf/2511.11729
  - **Simple LLM Summary:** Harli improves GPU utilization in LLM serving by co-locating parameter-efficient finetuning tasks with decode instances. The system addresses memory and interference challenges through a unified memory allocator, latency predictor, and QoS-aware scheduler. Experimental results show Harli achieves 46.2% average finetuning throughput improvement while maintaining strict QoS guarantees for inference.

- **[arXiv251118] Speculative Decoding in Decentralized LLM Inference: Turning Communication Latency into Computation Throughput**
  - **tags:** [mlsys], [llm inference], [speculative decoding, decentralized inference, adaptive verification, communication optimization]
  - **authors:** Jingwei Song, Wanyi Chen, Xinyuan Song, Chris Tong, Gufeng Chen, Tianyi Zhao, Eric Yang, Bill Shi, Lynn Ai
  - **institution:** Gradient Network, The University of Hong Kong, Soochow University, Emory University
  - **link:** https://arxiv.org/pdf/2511.11733
  - **Simple LLM Summary:** This paper introduces Decentralized Speculative Decoding (DSD), a framework that converts network latency into computation throughput by verifying multiple candidate tokens in parallel across distributed nodes. The method includes an adaptive verification strategy that adjusts acceptance thresholds based on token-level semantic importance. DSD achieves up to 2.6× speedup on benchmarks while preserving accuracy, enabling faster distributed LLM inference without model retraining.

- **[arXiv251118] Flash-Fusion: Enabling Expressive, Low-Latency Queries on IoT Sensor Streams with LLMs**
  - **tags:** [mlsys], [llm inference], [edge-based statistical summarization, query planning, context-rich prompts, sensor fusion, prompt engineering]
  - **authors:** Kausar Patherya, Ashutosh Dhekne, Francisco Romero
  - **institution:** Georgia Institute of Technology
  - **link:** https://arxiv.org/pdf/2511.11885
  - **Simple LLM Summary:** Flash-Fusion is an edge-cloud system that reduces IoT data volume through edge-based statistical summarization and improves data interpretation via cloud-based query planning with context-rich prompts. The system achieves 95% latency reduction and 98% decrease in token usage while maintaining high-quality LLM responses, enabling efficient natural language queries on IoT sensor streams without manual preprocessing.

- **[arXiv251118] Noise-Aware Optimization in Nominally Identical Manufacturing and Measuring Systems for High-Throughput Parallel Workflows**
  - **tags:** [mlsys], [others], [Bayesian optimization, distributional analysis, pairwise divergence metrics, clustering, noise-aware decision-making]
  - **authors:** Christina Schenk, Miguel Hernández-del-Valle, Luis Calero-Lumbreras, Marcus Noack, Maciej Haranczyk
  - **institution:** IMDEA Materials Institute, Universidad Carlos III de Madrid, Lawrence Berkeley National Laboratory
  - **link:** https://arxiv.org/pdf/2511.11739
  - **Simple LLM Summary:** This paper presents a noise-aware optimization framework that uses distributional analysis and clustering to select between single-device and robust multi-device Bayesian optimization strategies. The method explicitly models device-specific noise profiles to manage variability in automated manufacturing systems. Experimental results with nominally identical 3D printers show reduced redundancy, lower resource usage, and improved reliability compared to conventional approaches.

- **[arXiv251118] TD-Orch: Scalable Load-Balancing for Distributed Systems with Applications to Graph Processing**
  - **tags:** [sys], [distributed systems], [task-data orchestration, distributed push-pull, load balancing]
  - **authors:** Yiwei Zhao, Qiushi Lin, Hongbo Kang, Guy E. Blelloch, Laxman Dhulipala, Charles McGuffey, Phillip B. Gibbons
  - **institution:** Carnegie Mellon University, Tsinghua University, University of Maryland, Reed College
  - **link:** https://arxiv.org/pdf/2511.11843
  - **Simple LLM Summary:** TD-Orch is a distributed orchestration framework that uses a push-pull technique to co-locate tasks with their required data while achieving scalable load balancing. The system demonstrates significant performance improvements, achieving up to 2.7x speedup over existing distributed scheduling baselines and enabling a graph processing system (TDO-GP) that outperforms prior systems by 4.1x on average.

- **[arXiv251118] Advancing Annotat3D with Harpia: A CUDA-Accelerated Library For Large-Scale Volumetric Data Segmentation**
  - **tags:** [mlsys], [GPU kernels], [CUDA acceleration, memory control, chunked execution, GPU-accelerated filtering, volumetric data segmentation]
  - **authors:** Camila Machado de Araujo, Egon P. B. S. Borges, Ricardo Marcelo Canteiro Grangeiro, Allan Pinto
  - **institution:** Brazilian Synchrotron Light Laboratory (LNLS), Brazilian Center for Research in Energy and Materials (CNPEM)
  - **link:** https://arxiv.org/pdf/2511.11890
  - **Simple LLM Summary:** This paper introduces Harpia, a CUDA-accelerated library that enables large-scale volumetric data segmentation through strict memory control, native chunked execution, and GPU-accelerated tools. The system demonstrates significant improvements in processing speed, memory efficiency, and scalability compared to existing frameworks like NVIDIA cuCIM and scikit-image. The combination of interactive interfaces and efficient GPU management makes it suitable for collaborative scientific workflows in HPC environments.

- **[arXiv251118] KVSwap: Disk-aware KV Cache Offloading for Long-Context On-device Inference**
  - **tags:** [mlsys], [llm inference], [KV cache offloading, disk-aware optimization, preloading prediction, hardware-aware disk access]
  - **authors:** Huawei Zhang, Chunwei Xia, Zheng Wang
  - **institution:** University of Leeds
  - **link:** https://arxiv.org/pdf/2511.11907
  - **Simple LLM Summary:** KVSwap is a software framework that offloads key-value cache to disk storage for long-context on-device inference. It uses compact metadata to predict critical cache entries for preloading and orchestrates disk access patterns to match storage characteristics. The system achieves higher throughput under tight memory constraints while maintaining generation quality compared to existing offloading schemes.

- **[arXiv251118] Modular GPU Programming with Typed Perspectives**
  - **tags:** [mlsys], [GPU kernels], [typed perspectives, collective operations, Bundl calculus, modular programming, thread coordination]
  - **authors:** Manya Bansal, Daniel Sainati, Joseph W. Cutler, Saman Amarasinghe, Jonathan Ragan-Kelley
  - **institution:** Massachusetts Institute of Technology, University of Pennsylvania
  - **link:** https://arxiv.org/pdf/2511.11939
  - **Simple LLM Summary:** This paper introduces Prism, a new GPU programming language that uses typed perspectives to materialize thread granularity at the type level. The approach enables modular programming while maintaining low-level control over collective operations needed for high-performance GPU kernels. The authors demonstrate that Prism provides safety guarantees for writing modular code without sacrificing performance.

- **[arXiv251118] A Quick and Exact Method for Distributed Quantile Computation**
  - **tags:** [sys], [distributed computing], [Greenwald-Khanna Sketch, GK Select, tree-reduce, exact quantiles, Spark]
  - **authors:** Ivan Cao, Jaromir J. Saloni, David A. G. Harrison
  - **institution:** University of Mississippi
  - **link:** https://arxiv.org/pdf/2511.12025
  - **Simple LLM Summary:** The paper introduces GK Select, a distributed algorithm that computes exact quantiles by using GK Sketch to identify a pivot, extracting candidate values within error bounds, and tree-reducing the results. This method avoids expensive global sorting while maintaining exactness. Empirical results show it achieves sketch-level latency and outperforms Spark's full sort by approximately 10.5x on large datasets.

- **[arXiv251118] Distributed Seasonal Temporal Pattern Mining**
  - **tags:** [mlsys], [cluster infrastructure], [distributed hierarchical lookup hash structures, seasonal temporal patterns, time series mining]
  - **authors:** Van Ho-Long, Nguyen Ho, Anh-Vu Dinh-Duc, Ha Manh Tran, Ky Trung Nguyen, Tran Dung Pham, Quoc Viet Hung Nguyen
  - **institution:** International University, Vietnam National University, Loyola University Maryland, Griffith University
  - **link:** https://arxiv.org/pdf/2511.12216
  - **Simple LLM Summary:** The paper introduces DSTPM, a distributed framework that uses hierarchical lookup hash structures to mine seasonal temporal patterns from time series data. It significantly outperforms sequential methods in runtime and memory usage while scaling effectively to large datasets.

- **[arXiv251118] High-Performance N-Queens Solver on GPU: Iterative DFS with Zero Bank Conflicts**
  - **tags:** [sys], [parallel computing], [iterative DFS, GPU shared memory, bank conflict avoidance, parallel backtracking]
  - **authors:** Guangchao Yao, Yali Li
  - **institution:** XiaoPeng Motors
  - **link:** https://arxiv.org/pdf/2511.12009
  - **Simple LLM Summary:** The paper proposes an iterative depth-first search algorithm optimized for GPU parallel computing to solve the N-Queens problem, featuring shared memory mapping and bank conflict avoidance techniques. This approach verified the 27-Queens solution in 28.4 days using eight RTX 5090 GPUs, confirming previous results and achieving over 10x speedup compared to state-of-the-art methods. The method also reduces projected solving time for the 28-Queens problem to approximately 11 months, making it computationally feasible.

- **[arXiv251118] PipeDiT: Accelerating Diffusion Transformers in Video Generation with Task Pipelining and Model Decoupling**
  - **tags:** [mlsys], [diffusion inference], [task pipelining, model decoupling, sequence parallelism, attention co-processing]
  - **authors:** Sijie Wang, Qiang Wang, Shaohuai Shi
  - **institution:** Harbin Institute of Technology, Shenzhen
  - **link:** https://arxiv.org/pdf/2511.12056
  - **Simple LLM Summary:** PipeDiT introduces a pipelining framework that accelerates video generation through three innovations: pipelined sequence parallelism, decoupling of diffusion and VAE modules, and attention co-processing. The method achieves 1.06x to 4.02x speedups over existing frameworks while maintaining video quality through system-level optimizations rather than algorithmic changes.

- **[arXiv251118] Striking the Right Balance between Compute and Copy: Improving LLM Inferencing Under Speculative Decoding**
  - **tags:** [mlsys], [llm inference], [speculative decoding, KV cache optimization, memory-compute tradeoff, in-place updates, redundant computation]
  - **authors:** Arun Ramachandran, Ramaswamy Govindarajan, Murali Annavaram, Prakash Raghavendra, Hossein Entezari Zarch, Lei Gao, Chaoyi Jiang
  - **institution:** Advanced Micro Devices, Indian Institute of Science, University of Southern California
  - **link:** https://arxiv.org/pdf/2511.12031
  - **Simple LLM Summary:** The paper proposes BMC, a KV cache allocation mechanism that balances memory and compute by allocating redundant rows periodically to enable in-place updates without copy overhead. This approach reduces memory management costs while leveraging redundant computation for speculative decoding. BMC achieves significant throughput improvements over baseline methods and state-of-the-art inference servers on both CPUs and GPUs.

- **[arXiv251118] Combining Serverless and High-Performance Computing Paradigms to support ML Data-Intensive Applications**
  - **tags:** [mlsys], [cluster infrastructure], [serverless computing, high-performance computing, distributed data frames, AWS Lambda, NAT Traversal TCP Hole Punching, Cylon]
  - **authors:** Mills Staylor, Arup Kumar Sarker, Gregor von Laszewski, Geoffrey Fox, Yue Cheng, Judy Fox
  - **institution:** University of Virginia
  - **link:** https://arxiv.org/pdf/2511.12185
  - **Simple LLM Summary:** The paper introduces Cylon, a high-performance distributed data frame solution that combines serverless and HPC paradigms using a serverless communicator with NAT Traversal TCP Hole Punching. The research demonstrates that AWS Lambda performs below 1% of strong scaling experiments compared to serverful AWS EC2 and traditional HPC systems due to communication bottlenecks in serverless architectures.

- **[arXiv251118] SEE++: Evolving Snowpark Execution Environment for Modern Workloads**
  - **tags:** [mlsys], [cluster infrastructure], [gVisor, sandboxing, syscall filtering, virtual warehouse, Python execution]
  - **authors:** Gaurav Jain, Brandon Baker, Joe Yin, Chenwei Xie, Zihao Ye, Sidh Kulkarni, Sara Abdelrahman, Nova Qi, Urjeet Shrestha, Mike Halcrow, Dave Bailey, Yuxiong He
  - **institution:** Snowflake, Inc
  - **link:** https://arxiv.org/pdf/2511.12457
  - **Simple LLM Summary:** The paper describes how Snowpark transitioned from its in-house sandboxing solution to gVisor with targeted optimizations to handle modern Data Engineering and AI/ML workloads. The upgraded architecture provides improved security, performance, and maintainability while supporting arbitrary Python package execution. The enhanced Snowpark Execution Environment demonstrates extensibility and flexibility for next-generation workloads through case studies.

- **[arXiv251118] Design of A Low-Latency and Parallelizable SVD Dataflow Architecture on FPGA**
  - **tags:** [sys], [hardware acceleration], [FPGA, SVD, Hestenes method, Dataflow Architecture, Jacobi method, BRAM optimization]
  - **authors:** Fangqiang Du, Sixuan Chong, Zixuan Huang, Rui Qin, Fengnan Mi, Caibao Hu, Jiangang Chen
  - **institution:** East China Normal University, Zhejiang Hospital, Shanghai Publishing and Printing College
  - **link:** https://arxiv.org/pdf/2511.12461
  - **Simple LLM Summary:** The paper proposes a Data Stream-Based SVD processing algorithm (DSB Jacobi) implemented on FPGA that reduces on-chip memory usage while improving computational speed. Experimental results show the method reduces on-chip RAM consumption by 41.5% and improves computational efficiency by 23 times compared to previous works, providing a practical solution for real-time SVD computation of large-scale data streams.

- **[arXiv251118] A Decentralized Root Cause Localization Approach for Edge Computing Environments**
  - **tags:** [mlsys], [fault-tolerance], [Personalized PageRank, microservice clustering, anomaly scoring, decentralized systems]
  - **authors:** Duneesha Fernando, Maria A. Rodriguez, Rajkumar Buyya
  - **institution:** The University of Melbourne
  - **link:** https://arxiv.org/pdf/2511.12486
  - **Simple LLM Summary:** This paper proposes a decentralized root cause localization approach that uses Personalized PageRank within clustered microservices at the edge. The method reduces communication overhead through local cluster analysis and inter-cluster peer-to-peer coordination. Evaluation shows it achieves comparable or better accuracy than centralized approaches while reducing localization time by up to 34%.

- **[arXiv251118] Iris: First-Class Multi-GPU Programming Experience in Triton**
  - **tags:** [mlsys], [GPU kernels], [multi-GPU programming, tile-based symmetric memory, compute-communication overlap, Triton, fused kernels]
  - **authors:** Muhammad Awad, Muhammad Osama, Brandon Potter
  - **institution:** Advanced Micro Devices, Inc.
  - **link:** https://arxiv.org/pdf/2511.12500
  - **Simple LLM Summary:** Iris is a multi-GPU communication library implemented in Python and Triton that provides tile-based symmetric memory abstractions to seamlessly interleave computation and communication. It enables various overlap patterns with minimal code changes while maintaining high performance. The evaluation shows Iris achieves near-optimal bandwidth utilization and up to 1.79x speedup over existing libraries while dramatically simplifying multi-GPU programming.

- **[arXiv251118] Artifact for A Non-Intrusive Framework for Deferred Integration of Cloud Patterns in Energy-Efficient Data-Sharing Pipelines**
  - **tags:** [sys], [cloud computing], [Kubernetes, cloud design patterns, data-sharing pipelines, energy metrics, non-intrusive pattern injection]
  - **authors:** Sepideh Masoudi, Mark Edward Michael Daly, Jannis Kiesel
  - **institution:** Technische Universität Berlin
  - **link:** https://arxiv.org/pdf/2511.12667
  - **Simple LLM Summary:** The paper presents a Kubernetes-based tool that enables non-intrusive application of cloud design patterns to data-sharing pipelines without modifying service code. The tool automates pattern injection and collects energy metrics to support energy-aware decisions. This approach preserves service reusability across different pipeline structures while improving energy efficiency.

- **[arXiv251118] The Time to Consensus in a Blockchain: Insights into Bitcoin's "6 Blocks Rule''**
  - **tags:** [sys], [blockchain consensus], [queueing theory, Laplace transform, simulation, random delays, competing growth processes]
  - **authors:** Partha S. Dey, Aditya S. Gopalan, Vijay G. Subramanian
  - **institution:** University of Illinois Urbana-Champaign
  - **link:** https://arxiv.org/pdf/2511.12687
  - **Simple LLM Summary:** This paper analyzes consensus time in Nakamoto blockchains using queueing techniques to model competing honest and adversarial growth processes with random delays. The authors compute the Laplace transform for time to consensus in a Bitcoin model and validate their approach through simulation, providing insights into Bitcoin's "6 blocks rule" for achieving permanent consensus.

- **[arXiv251118] QPU Micro-Kernels for Stencil Computation**
  - **tags:** [mlsys], [GPU kernels], [QPU micro-kernels, stencil computation, Monte Carlo estimation, shallow quantum circuits, sampling accelerator]
  - **authors:** Stefano Markidis, Luca Pennati, Marco Pasquale, Gilbert Netzer, Ivy Peng
  - **institution:** KTH Royal Institute of Technology
  - **link:** https://arxiv.org/pdf/2511.12617
  - **Simple LLM Summary:** This paper introduces QPU micro-kernels - shallow quantum circuits that perform stencil node updates using Monte Carlo estimation from repeated measurements. The approach treats quantum processors as sampling accelerators for solving PDEs while maintaining classical time loops and parallelizing across grid points. Experimental results show the Bernoulli micro-kernel achieves lower errors than branching methods on quantum hardware, with QPU execution dominating wall time.

- **[arXiv251118] A Closer Look at Personalized Fine-Tuning in Heterogeneous Federated Learning**
  - **tags:** [mlsys], [post-training], [federated learning, personalized fine-tuning, linear probing, feature distortion, domain shift]
  - **authors:** Minghui Chen, Hrad Ghoukasian, Ruinan Jin, Zehua Wang, Sai Praneeth Karimireddy, Xiaoxiao Li
  - **institution:** University of British Columbia, Vector Institute, McMaster University, University of Southern California
  - **link:** https://arxiv.org/pdf/2511.12695
  - **Simple LLM Summary:** This paper adapts Linear Probing followed by Fine-Tuning (LP-FT) to federated learning for personalized model training. The method addresses federated feature distortion by using phased parameter updates during local fine-tuning. The authors demonstrate LP-FT's superiority over standard fine-tuning in balancing personalization and generalization across various datasets and conditions.

- **[arXiv251118] Learning Process Energy Profiles from Node-Level Power Data**
  - **tags:** [mlsys], [cluster infrastructure], [eBPF, perf, power distribution unit, regression model, resource metrics]
  - **authors:** Jonathan Bader, Julius Irion, Jannis Kappel, Joel Witzke, Niklas Fomin, Diellza Sherifi, Odej Kao
  - **institution:** Technische Universit¨at Berlin
  - **link:** https://arxiv.org/pdf/2511.13155
  - **Simple LLM Summary:** The paper proposes a method that uses eBPF and perf to collect process-level resource metrics, which are synchronized with node-level power measurements and modeled through regression to predict per-process energy consumption. This approach enables fine-grained energy profiling without hardware-specific limitations like Intel RAPL. The method provides more accurate process-level energy insights for improving data center energy efficiency.

- **[arXiv251118] MACKO: Sparse Matrix-Vector Multiplication for Low Sparsity**
  - **tags:** [mlsys], [llm inference], [sparse matrix-vector multiplication, GPU optimization, unstructured pruning, kernel co-design, memory reduction]
  - **authors:** Vladimír Macko, Vladimír Boža
  - **institution:** Comenius University Bratislava, GrizzlyTech
  - **link:** https://arxiv.org/pdf/2511.13061
  - **Simple LLM Summary:** The paper introduces MACKO-SpMV, a GPU-optimized format and kernel co-designed for efficient sparse matrix-vector multiplication at low sparsity levels. This approach enables significant memory reduction and speedup for unstructured sparsity without requiring specialized hardware or format-specific precomputation. Empirical results demonstrate that MACKO achieves 1.5× memory reduction and 1.2-1.5× speedup over dense representation at 50% sparsity, making unstructured pruning practical for real-world LLM inference workloads.

- **[arXiv251118] On the Fundamental Limits of LLMs at Scale**
  - **tags:** [mlsys], [llm training], [diagonalization, finite description length, positional curricula, sparse attention, hierarchical attention, bounded-oracle retrieval]
  - **authors:** Muhammad Ahmed Mohsin, Muhammad Umer, Ahsan Bilal, Zeeshan Memon, Muhammad Ibtsaam Qadir, Sagnik Bhattacharya, Hassan Rizwan, Abhiram R. Gorle, Maahe Zehra Kazmi, Ayesha Mohsin, Muhammad Usman Rafique, Zihao He, Pulkit Mehta, Muhammad Ali Jamshed, John M. Cioffi
  - **institution:** Stanford University, The University of Oklahoma, Emory University, Purdue University, UC Riverside, UC Berkeley, National University of Sciences and Technology, Zoox, Meta, Google DeepMind, University of Glasgow
  - **link:** https://arxiv.org/pdf/2511.12869
  - **Simple LLM Summary:** This paper presents a unified theoretical framework that formalizes the fundamental limitations of LLM scaling through computability theory, information theory, and statistical learning. It demonstrates that scaling cannot overcome irreducible errors from uncomputable tasks, information-theoretic bounds, and geometric constraints in context processing. The work provides both theoretical foundations and practical mitigation strategies like positional curricula and sparse attention to address these inherent limitations.

- **[arXiv251118] Pico-Cloud: Cloud Infrastructure for Tiny Edge Devices**
  - **tags:** [mlsys], [cluster infrastructure], [container-based virtualization, service discovery, lightweight orchestration, single-board computers, edge computing]
  - **authors:** Mordechai Guri
  - **institution:** Ben-Gurion University of the Negev
  - **link:** https://arxiv.org/pdf/2511.13253
  - **Simple LLM Summary:** The paper introduces Pico-Cloud, a micro-edge cloud architecture built on minimal hardware platforms like Raspberry Pi Zero that provides container-based virtualization and lightweight orchestration. This approach enables local operation with low latency and power consumption without relying on centralized data centers. The results demonstrate Pico-Cloud as a cost-effective, decentralized platform for lightweight distributed workloads at the network edge.

- **[arXiv251118] Distributed Hierarchical Machine Learning for Joint Resource Allocation and Slice Selection in In-Network Edge Systems**
  - **tags:** [mlsys], [others], [DeepSets, distributed hierarchical machine learning, permutation equivariance, slack-aware normalization, mixed-integer nonlinear programming, network slicing]
  - **authors:** Sulaiman Muhammad Rashid, Ibrahim Aliyu, Jaehyung Park, Jinsul Kim
  - **institution:** Chonnam National University
  - **link:** https://arxiv.org/pdf/2511.13313
  - **Simple LLM Summary:** The paper proposes a distributed hierarchical DeepSets-based model for joint resource allocation and slice selection in edge systems. The method decomposes the optimization problem into three sub-problems and uses a shared encoder with task-specific decoders to achieve near-optimal solutions. Experimental results show the approach reduces execution time by 86.1% while maintaining close-to-optimal system performance.

- **[arXiv251118] Asymptotic analysis of cooperative censoring policies in sensor networks**
  - **tags:** [sys], [sensor networks], [Markov Decision Process, constant-threshold rules, centralized algorithm]
  - **authors:** Jesus Fernandez-Bes, Rocío Arroyo-Valles, Jesús Cid-Sueiro
  - **institution:** Universidad Carlos III de Madrid, Delft University of Technology
  - **link:** https://arxiv.org/pdf/2511.13492
  - **Simple LLM Summary:** This paper models cooperative data censoring in sensor networks using a joint Markov Decision Process to find optimal energy-saving policies. The computationally prohibitive optimal rules are approximated by constant-threshold rules computed via a centralized algorithm. Experimental results show these cooperative censoring policies are energy-efficient and outperform non-cooperative schemes.

- **[arXiv251118] InfoDecom: Decomposing Information for Defending against Privacy Leakage in Split Inference**
  - **tags:** [mlsys], [others], [split inference, information decomposition, privacy protection, data reconstruction attacks, differential privacy]
  - **authors:** Ruijun Deng, Zhihui Lu, Qiang Duan
  - **institution:** Fudan University, Pennsylvania State University
  - **link:** https://arxiv.org/pdf/2511.13365
  - **Simple LLM Summary:** The paper proposes InfoDecom, a defense framework that decomposes and removes redundant information from smashed data before injecting calibrated noise to protect against privacy leakage in split inference. This approach addresses the utility degradation problem in existing defenses by targeting only non-redundant information. Experiments show that InfoDecom achieves a superior utility-privacy trade-off compared to existing baselines.


**cs.AI/cs.LG contains "reinforcement learning" total: 50**
- [arXiv251118] Clustering-Based Weight Orthogonalization for Stabilizing Deep Reinforcement Learning [link](https://arxiv.org/pdf/2511.11607)
- [arXiv251118] Mind Your Entropy: From Maximum Entropy to Trajectory Entropy-Constrained RL [link](https://arxiv.org/pdf/2511.11592)
- [arXiv251118] Environment-Aware Transfer Reinforcement Learning for Sustainable Beam Selection [link](https://arxiv.org/pdf/2511.11647)
- [arXiv251118] Convergence of Multiagent Learning Systems for Traffic control [link](https://arxiv.org/pdf/2511.11654)
- [arXiv251118] Enhancing Reinforcement Learning in 3D Environments through Semantic Segmentation: A Case Study in ViZDoom [link](https://arxiv.org/pdf/2511.11703)
- [arXiv251118] Learning to Refine: An Agentic RL Approach for Iterative SPARQL Query Construction [link](https://arxiv.org/pdf/2511.11770)
- [arXiv251118] Image-POSER: Reflective RL for Multi-Expert Image Generation and Editing [link](https://arxiv.org/pdf/2511.11780)
- [arXiv251118] Conformal Constrained Policy Optimization for Cost-Effective LLM Agents [link](https://arxiv.org/pdf/2511.11828)
- [arXiv251118] Better LLM Reasoning via Dual-Play [link](https://arxiv.org/pdf/2511.11881)
- [arXiv251118] VULPO: Context-Aware Vulnerability Detection via On-Policy LLM Optimization [link](https://arxiv.org/pdf/2511.11896)
- [arXiv251118] Quantile Q-Learning: Revisiting Offline Extreme Q-Learning with Quantile Regression [link](https://arxiv.org/pdf/2511.11973)
- [arXiv251118] Goal-Oriented Multi-Agent Reinforcement Learning for Decentralized Agent Teams [link](https://arxiv.org/pdf/2511.11992)
- [arXiv251118] Look As You Think: Unifying Reasoning and Visual Evidence Attribution for Verifiable Document RAG via Reinforcement Learning [link](https://arxiv.org/pdf/2511.12003)
- [arXiv251118] EARL: Entropy-Aware RL Alignment of LLMs for Reliable RTL Code Generation [link](https://arxiv.org/pdf/2511.12033)
- [arXiv251118] Intelligent Collaborative Optimization for Rubber Tyre Film Production Based on Multi-path Differentiated Clipping Proximal Policy Optimization [link](https://arxiv.org/pdf/2511.12060)
- [arXiv251118] Treatment Stitching with Schrödinger Bridge for Enhancing Offline Reinforcement Learning in Adaptive Treatment Strategies [link](https://arxiv.org/pdf/2511.12075)
- [arXiv251118] HCPO: Hierarchical Conductor-Based Policy Optimization in Multi-Agent Reinforcement Learning [link](https://arxiv.org/pdf/2511.12123)
- [arXiv251118] Reward and Guidance through Rubrics: Promoting Exploration to Improve Multi-Domain Reasoning [link](https://arxiv.org/pdf/2511.12344)
- [arXiv251118] Dynamic Reward Scaling for Multivariate Time Series Anomaly Detection: A VAE-Enhanced Reinforcement Learning Approach [link](https://arxiv.org/pdf/2511.12351)
- [arXiv251118] Integrating Neural Differential Forecasting with Safe Reinforcement Learning for Blood Glucose Regulation [link](https://arxiv.org/pdf/2511.12417)
- [arXiv251118] Tailored Primitive Initialization is the Secret Key to Reinforcement Learning [link](https://arxiv.org/pdf/2511.12429)
- [arXiv251118] Mitigating Length Bias in RLHF through a Causal Lens [link](https://arxiv.org/pdf/2511.12573)
- [arXiv251118] NFQ2.0: The CartPole Benchmark Revisited [link](https://arxiv.org/pdf/2511.12644)
- [arXiv251118] Beyond Fixed Tasks: Unsupervised Environment Design for Task-Level Pairs [link](https://arxiv.org/pdf/2511.12706)
- [arXiv251118] Prompt-Driven Domain Adaptation for End-to-End Autonomous Driving via In-Context RL [link](https://arxiv.org/pdf/2511.12755)
- [arXiv251118] Scalable Multi-Objective and Meta Reinforcement Learning via Gradient Estimation [link](https://arxiv.org/pdf/2511.12779)
- [arXiv251118] Multi-Agent Reinforcement Learning for Heterogeneous Satellite Cluster Resources Optimization [link](https://arxiv.org/pdf/2511.12792)
- [arXiv251118] Maximizing the efficiency of human feedback in AI alignment: a comparative analysis [link](https://arxiv.org/pdf/2511.12796)
- [arXiv251118] Expressive Temporal Specifications for Reward Monitoring [link](https://arxiv.org/pdf/2511.12808)
- [arXiv251118] Mapping fNIRS Signals to Agent Performance: Toward Reinforcement Learning from Neural Feedback [link](https://arxiv.org/pdf/2511.12844)
- [arXiv251118] Think, Speak, Decide: Language-Augmented Multi-Agent Reinforcement Learning for Economic Decision-Making [link](https://arxiv.org/pdf/2511.12876)
- [arXiv251118] DeepSport: A Multimodal Large Language Model for Comprehensive Sports Video Reasoning via Agentic Reinforcement Learning [link](https://arxiv.org/pdf/2511.12908)
- [arXiv251118] Learning Branching Policies for MILPs with Proximal Policy Optimization [link](https://arxiv.org/pdf/2511.12986)
- [arXiv251118] The Good, The Bad, and The Hybrid: A Reward Structure Showdown in Reasoning Models Training [link](https://arxiv.org/pdf/2511.13016)
- [arXiv251118] Scaling Generative Verifiers For Natural Language Mathematical Proof Verification And Selection [link](https://arxiv.org/pdf/2511.13027)
- [arXiv251118] One-Step Generative Policies with Q-Learning: A Reformulation of MeanFlow [link](https://arxiv.org/pdf/2511.13035)
- [arXiv251118] STEP: Success-Rate-Aware Trajectory-Efficient Policy Optimization [link](https://arxiv.org/pdf/2511.13091)
- [arXiv251118] Transformer-Based Scalable Multi-Agent Reinforcement Learning for Networked Systems with Long-Range Interactions [link](https://arxiv.org/pdf/2511.13103)
- [arXiv251118] Soft Conflict-Resolution Decision Transformer for Offline Multi-Task Reinforcement Learning [link](https://arxiv.org/pdf/2511.13133)
- [arXiv251118] Conditional Diffusion Model for Multi-Agent Dynamic Task Decomposition [link](https://arxiv.org/pdf/2511.13137)
- [arXiv251118] DiffFP: Learning Behaviors from Scratch via Diffusion-based Fictitious Play [link](https://arxiv.org/pdf/2511.13186)
- [arXiv251118] Learning to Solve Resource-Constrained Project Scheduling Problems with Duration Uncertainty using Graph Neural Networks [link](https://arxiv.org/pdf/2511.13214)
- [arXiv251118] Explainable RL Policies by Distilling to Locally-Specialized Linear Policies with Voronoi State Partitioning [link](https://arxiv.org/pdf/2511.13322)
- [arXiv251118] Finding Kissing Numbers with Game-theoretic Reinforcement Learning [link](https://arxiv.org/pdf/2511.13391)
- [arXiv251118] Artificial Intelligence-driven Intelligent Wearable Systems: A full-stack Integration from Material Design to Personalized Interaction [link](https://arxiv.org/pdf/2511.13565)
- [arXiv251118] P1: Mastering Physics Olympiads with Reinforcement Learning [link](https://arxiv.org/pdf/2511.13612)
- [arXiv251118] Reinforcement Learning for Charging Optimization of Inhomogeneous Dicke Quantum Batteries [link](https://arxiv.org/pdf/2511.12176)
- [arXiv251118] Reinforcement Learning for Chemical Ordering in Alloy Nanoparticles [link](https://arxiv.org/pdf/2511.12260)
- [arXiv251118] Discovering autonomous quantum error correction via deep reinforcement learning [link](https://arxiv.org/pdf/2511.12482)
- [arXiv251118] Accelerated Distributional Temporal Difference Learning with Linear Function Approximation [link](https://arxiv.org/pdf/2511.12688)

**cs.AI/cs.LG contains "accelerate" total: 34**
- [arXiv251118] Physics-Informed Neural Network-based Reliability Analysis of Buried Pipelines [link](https://arxiv.org/pdf/2511.11613)
- [arXiv251118] DAOpt: Modeling and Evaluation of Data-Driven Optimization under Uncertainty with LLMs [link](https://arxiv.org/pdf/2511.11576)
- [arXiv251118] Lightweight Hopfield Neural Networks for Bioacoustic Detection and Call Monitoring of Captive Primates [link](https://arxiv.org/pdf/2511.11615)
- [arXiv251118] SA-EMO: Structure-Aligned Encoder Mixture of Operators for Generalizable Full-waveform Inversion [link](https://arxiv.org/pdf/2511.11627)
- [arXiv251118] Tactile Data Recording System for Clothing with Motion-Controlled Robotic Sliding [link](https://arxiv.org/pdf/2511.11634)
- [arXiv251118] Environment-Aware Transfer Reinforcement Learning for Sustainable Beam Selection [link](https://arxiv.org/pdf/2511.11647)
- [arXiv251118] Hierarchical Schedule Optimization for Fast and Robust Diffusion Model Sampling [link](https://arxiv.org/pdf/2511.11688)
- [arXiv251118] Diffusion Models: A Mathematical Introduction [link](https://arxiv.org/pdf/2511.11746)
- [arXiv251118] Towards autonomous quantum physics research using LLM agents with access to intelligent tools [link](https://arxiv.org/pdf/2511.11752)
- [arXiv251118] Mesh-based Super-resolution of Detonation Flows with Multiscale Graph Transformers [link](https://arxiv.org/pdf/2511.12041)
- [arXiv251118] D$^{3}$ToM: Decider-Guided Dynamic Token Merging for Accelerating Diffusion MLLMs [link](https://arxiv.org/pdf/2511.12280)
- [arXiv251118] Sangam: Chiplet-Based DRAM-PIM Accelerator with CXL Integration for LLM Inferencing [link](https://arxiv.org/pdf/2511.12286)
- [arXiv251118] FERMI-ML: A Flexible and Resource-Efficient Memory-In-Situ SRAM Macro for TinyML acceleration [link](https://arxiv.org/pdf/2511.12544)
- [arXiv251118] PID-controlled Langevin Dynamics for Faster Sampling of Generative Models [link](https://arxiv.org/pdf/2511.12603)
- [arXiv251118] FedTopo: Topology-Informed Representation Alignment in Federated Learning under Non-I.I.D. Conditions [link](https://arxiv.org/pdf/2511.12628)
- [arXiv251118] Beyond Fixed Tasks: Unsupervised Environment Design for Task-Level Pairs [link](https://arxiv.org/pdf/2511.12706)
- [arXiv251118] INC: An Indirect Neural Corrector for Auto-Regressive Hybrid PDE Solvers [link](https://arxiv.org/pdf/2511.12764)
- [arXiv251118] RoS-Guard: Robust and Scalable Online Change Detection with Delay-Optimal Guarantees [link](https://arxiv.org/pdf/2511.12846)
- [arXiv251118] An approach of deep reinforcement learning for maximizing the net present value of stochastic projects [link](https://arxiv.org/pdf/2511.12865)
- [arXiv251118] MCAQ-YOLO: Morphological Complexity-Aware Quantization for Efficient Object Detection with Curriculum Learning [link](https://arxiv.org/pdf/2511.12976)
- [arXiv251118] MeanFlow Transformers with Representation Autoencoders [link](https://arxiv.org/pdf/2511.13019)
- [arXiv251118] Learning Time-Scale Invariant Population-Level Neural Representations [link](https://arxiv.org/pdf/2511.13022)
- [arXiv251118] MM-Telco: Benchmarks and Multimodal Large Language Models for Telecom Applications [link](https://arxiv.org/pdf/2511.13131)
- [arXiv251118] Warm-starting active-set solvers using graph neural networks [link](https://arxiv.org/pdf/2511.13174)
- [arXiv251118] KForge: Program Synthesis for Diverse AI Hardware Accelerators [link](https://arxiv.org/pdf/2511.13274)
- [arXiv251118] Hardware optimization on Android for inference of AI models [link](https://arxiv.org/pdf/2511.13453)
- [arXiv251118] Automated Construction of Medical Indicator Knowledge Graphs Using Retrieval Augmented Large Language Models [link](https://arxiv.org/pdf/2511.13526)
- [arXiv251118] VVS: Accelerating Speculative Decoding for Visual Autoregressive Generation via Partial Verification Skipping [link](https://arxiv.org/pdf/2511.13587)
- [arXiv251118] Data-driven Acceleration of MPC with Guarantees [link](https://arxiv.org/pdf/2511.13588)
- [arXiv251118] T-SAR: A Full-Stack Co-design for CPU-Only Ternary LLM Inference via In-Place SIMD ALU Reorganization [link](https://arxiv.org/pdf/2511.13676)
- [arXiv251118] QUILL: An Algorithm-Architecture Co-Design for Cache-Local Deformable Attention [link](https://arxiv.org/pdf/2511.13679)
- [arXiv251118] From Black Box to Insight: Explainable AI for Extreme Event Preparedness [link](https://arxiv.org/pdf/2511.13712)
- [arXiv251118] The Singularity Warfare: The metatheoretical Framework [link](https://arxiv.org/pdf/2511.11674)
- [arXiv251118] Discovering autonomous quantum error correction via deep reinforcement learning [link](https://arxiv.org/pdf/2511.12482)

## 2025-11-19

**cs.DC total: 19**

- **[arXiv251119] Boosting performance: Gradient Clock Synchronisation with two-way measured links**
  - **tags:** [sys], [distributed systems], [gradient clock synchronization, two-way measurement, formal model, frequency sources, estimation error, skew bounds]
  - **authors:** Sophie Wenning
  - **institution:** TU Wien
  - **link:** https://arxiv.org/pdf/2511.13727
  - **Simple LLM Summary:** This thesis extends the Gradient Clock Synchronization algorithm by replacing one-way measurements with two-way measurements, which removes previous restrictions and creates a more realistic model. The new approach significantly reduces estimation error by multiple orders of magnitude and provides matching upper bounds on local and global skew while maintaining the core GCS behavior.

- **[arXiv251119] What happens when nanochat meets DiLoCo?**
  - **tags:** [mlsys], [llm training], [DiLoCo, distributed training, data-parallel training, communication-efficient optimization, representation drift]
  - **authors:** Alexander Acker, Soeren Becker, Sasho Nedelkoski, Dominik Scheinert, Odej Kao, Philipp Wiesner
  - **institution:** exalsius, Technische Universität Berlin
  - **link:** https://arxiv.org/pdf/2511.13761
  - **Simple LLM Summary:** This paper implements the DiLoCo algorithm on the nanochat framework to enable communication-efficient distributed LLM training. While DiLoCo achieves stable pretraining convergence, it causes irreversible representation drift that impairs downstream task performance after mid-training and fine-tuning. The study reveals fundamental trade-offs between communication efficiency and model quality in distributed training approaches.

- **[arXiv251119] ParallelKittens: Systematic and Practical Simplification of Multi-GPU AI Kernels**
  - **tags:** [mlsys], [GPU kernels], [multi-GPU communication, compute-communication overlap, CUDA framework, data parallelism, tensor parallelism, sequence parallelism, expert parallelism]
  - **authors:** Stuart H. Sul, Simran Arora, Benjamin F. Spector, Christopher Ré
  - **institution:** Stanford University
  - **link:** https://arxiv.org/pdf/2511.13940
  - **Simple LLM Summary:** ParallelKittens introduces a minimal CUDA framework that simplifies multi-GPU kernel development through eight core primitives and a unified programming template. The framework achieves significant speedups across various parallel workloads while requiring fewer than 50 lines of device code. It demonstrates improved performance on modern GPU architectures by systematically addressing inter-GPU communication bottlenecks.

- **[arXiv251119] Gaia: Hybrid Hardware Acceleration for Serverless AI in the 3D Compute Continuum**
  - **tags:** [mlsys], [cluster infrastructure], [GPU-as-a-service, execution mode identifier, dynamic function runtime, SLO-aware scheduling, hybrid hardware acceleration]
  - **authors:** Maximilian Reisecker, Cynthia Marcelino, Thomas Pusztai, Stefan Nastic
  - **institution:** TU Wien
  - **link:** https://arxiv.org/pdf/2511.13728
  - **Simple LLM Summary:** Gaia introduces a hybrid hardware acceleration architecture that combines an Execution Mode Identifier for function analysis and a Dynamic Function Runtime for continuous resource optimization between CPU and GPU backends. The system dynamically selects the best hardware acceleration based on workload requirements and user-defined SLOs. Evaluation shows Gaia reduces end-to-end latency by up to 95% while providing cost-efficient acceleration for serverless AI across heterogeneous environments.

- **[arXiv251119] Guaranteed DGEMM Accuracy While Using Reduced Precision Tensor Cores Through Extensions of the Ozaki Scheme**
  - **tags:** [mlsys], [GPU kernels], [Ozaki decompositions, Automatic Dynamic Precision, Exponent Span Capacity, unsigned integer slicing, FP64 emulation]
  - **authors:** Angelika Schwarz, Anton Anders, Cole Brower, Harun Bayraktar, John Gunnels, Kate Clark, RuQing G. Xu, Samuel Rodriguez, Sebastien Cayrols, Paweł Tabaszewski, Victor Podlozhnyuk
  - **institution:** NVIDIA Corporation
  - **link:** https://arxiv.org/pdf/2511.13778
  - **Simple LLM Summary:** This paper introduces Automatic Dynamic Precision (ADP), a GPU-resident framework that uses Ozaki decompositions with an Exponent Span Capacity estimator to emulate FP64 accuracy using low-precision Tensor Cores. The method includes unsigned integer slicing and automatic fallback mechanisms to ensure reliability while achieving significant speedups over native FP64. The results demonstrate that low-precision accelerators can serve as a practical foundation for high-fidelity scientific computing workloads.

- **[arXiv251119] Inside VOLT: Designing an Open-Source GPU Compiler**
  - **tags:** [sys], [GPU compiler], [SIMT execution, compiler transformations, divergence management, hierarchical design, middle-end optimizations]
  - **authors:** Shinnung Jeong, Chihyo Ahn, Huanzhi Pu, Jisheng Zhao, Hyesoon Kim, Blaise Tine
  - **institution:** Georgia Tech, University of California, Los Angeles
  - **link:** https://arxiv.org/pdf/2511.13751
  - **Simple LLM Summary:** VOLT is an open-source GPU compiler framework designed with a hierarchical architecture that centralizes SIMT-related analyses and optimizations in the middle-end. It enables efficient code generation for open GPU architectures like Vortex while supporting multiple front-end languages and hardware variants. The compiler demonstrates extensibility through case studies on ISA extensions and host-runtime APIs, addressing the critical gap in compiler support for emerging open GPU hardware.

- **[arXiv251119] TT-Edge: A Hardware-Software Co-Design for Energy-Efficient Tensor-Train Decomposition on Edge AI**
  - **tags:** [mlsys], [others], [tensor-train decomposition, hardware-software co-design, SVD optimization, GEMM accelerator, RISC-V processor]
  - **authors:** Hyunseok Kwak, Kyeongwon Lee, Kyeongpil Min, Chaebin Jung, Woojoo Lee
  - **institution:** Chung-Ang University
  - **link:** https://arxiv.org/pdf/2511.13738
  - **Simple LLM Summary:** TT-Edge presents a hardware-software co-design framework that splits SVD computation into bidiagonalization and diagonalization phases, offloading intensive tasks to a specialized TTD Engine integrated with existing GEMM accelerators. The system achieves 1.7× speedup and 40.2% energy reduction for ResNet-32 compression with minimal hardware overhead. Experimental results demonstrate effective resolution of latency and energy bottlenecks for tensor-train decomposition in edge AI environments.

- **[arXiv251119] Do MPI Derived Datatypes Actually Help? A Single-Node Cross-Implementation Study on Shared-Memory Communication**
  - **tags:** [sys], [MPI performance analysis], [MPI derived datatypes, manual packing, non-blocking communication, neighborhood collectives, persistent operations, cross-implementation benchmarking]
  - **authors:** Temitayo Adefemi
  - **institution:** University of Edinburgh
  - **link:** https://arxiv.org/pdf/2511.13804
  - **Simple LLM Summary:** This paper compares MPI derived datatypes against manual packing methods across three 2D applications and four MPI implementations using identical communication semantics. The study found that performance varies significantly across different MPI stacks and applications, with no single strategy consistently outperforming the other. The authors conclude that performance portability for derived datatypes is not guaranteed and recommend profiling both approaches under target MPI implementations.

- **[arXiv251119] MoE-SpeQ: Speculative Quantized Decoding with Proactive Expert Prefetching and Offloading for Mixture-of-Experts**
  - **tags:** [mlsys], [llm inference], [speculative execution, expert offloading, prefetching, quantization, amortization roofline model]
  - **authors:** Wenfeng Wang, Jiacheng Liu, Xiaofeng Hou, Xinfeng Xia, Peng Tang, Mingxuan Zhang, Chao Li, Minyi Guo
  - **institution:** Shanghai Jiao Tong University, Hong Kong University of Science and Technology
  - **link:** https://arxiv.org/pdf/2511.14102
  - **Simple LLM Summary:** MoE-SpeQ introduces a speculative execution system that uses a small draft model to predict future expert requirements, enabling proactive prefetching and offloading to hide I/O latency. The system employs an adaptive governor guided by an Amortization Roofline Model to dynamically optimize speculation strategies. This approach achieves up to 2.34x speedup over existing offloading frameworks, making MoE inference more efficient on memory-constrained hardware.

- **[arXiv251119] Semantic Multiplexing**
  - **tags:** [mlsys], [others], [semantic multiplexing, task-driven compression, MIMO communication, semantic representation, edge computing]
  - **authors:** Mohammad Abdi, Francesca Meneghello, Francesco Restuccia
  - **institution:** Northeastern University
  - **link:** https://arxiv.org/pdf/2511.13779
  - **Simple LLM Summary:** This paper introduces Semantic Multiplexing, a method that merges multiple task-related compressed representations into a single semantic representation to enable parallel processing of more tasks than available physical channels. The approach was prototyped on an experimental testbed using Jetson Orin Nano and millimeter-wave radios, demonstrating significant reductions in latency, energy consumption, and communication load while maintaining task accuracy. Experimental results show the method reduces latency by up to 8×, energy consumption by 25×, and communication load by 54× compared to baselines.

- **[arXiv251119] Overview and Prospects of Using Integer Surrogate Keys for Data Warehouse Performance Optimization**
  - **tags:** [sys], [database optimization], [integer surrogate keys, indexing, aggregation, compression, batching]
  - **authors:** Sviatoslav Stumpf, Vladislav Povyshev
  - **institution:** ITMO University
  - **link:** https://arxiv.org/pdf/2511.14502
  - **Simple LLM Summary:** This paper proposes replacing standard DATE/TIMESTAMP types with 32-bit and 64-bit integer formats for time-series data in data warehouses. The method demonstrates significant performance improvements, reducing storage requirements by 30-60% and speeding up query execution by 25-40% across various real-world applications including finance, telecommunications, and IoT.

- **[arXiv251119] Hapax Locks : Value-Based Mutual Exclusion**
  - **tags:** [sys], [concurrency control], [mutual exclusion, FIFO admission, constant-time operations, cache coherence]
  - **authors:** Dave Dice, Alex Kogan
  - **institution:** Oracle Labs
  - **link:** https://arxiv.org/pdf/2511.14608
  - **Simple LLM Summary:** Hapax Locks is a novel locking algorithm that provides constant-time arrival and unlock operations with FIFO admission order while generating minimal coherence traffic. The algorithm offers performance comparable to state-of-the-art locks while being easier to integrate into existing systems. A key innovation is that no pointers shift or escape ownership between threads during operation.

- **[arXiv251119] FailSafe: High-performance Resilient Serving**
  - **tags:** [mlsys], [fault-tolerance], [tensor parallelism, cyclic KVCache placement, hybrid attention, fine-grained load-aware routing, proactive KVCache backup, on-demand weight recovery]
  - **authors:** Ziyi Xu, Zhiqiang Xie, Swapnil Gandhi, Christos Kozyrakis
  - **institution:** Shanghai Jiao Tong University, Stanford University, NVIDIA Research
  - **link:** https://arxiv.org/pdf/2511.14116
  - **Simple LLM Summary:** FailSafe introduces a fault-tolerant tensor parallelism system using cyclic KVCache placement, hybrid attention, and load-aware routing to maintain high-performance LLM serving during GPU failures. It employs proactive KVCache backup and on-demand weight recovery to minimize recomputation overhead. Evaluations show 2x higher throughput and significantly lower recovery latency compared to standard approaches, maintaining performance even with multiple GPU failures.

- **[arXiv251119] Analyzing the Impact of Participant Failures in Cross-Silo Federated Learning**
  - **tags:** [mlsys], [fault-tolerance], [federated learning, cross-silo FL, participant failures, model quality, data skew]
  - **authors:** Fabian Stricker, David Bermbach, Christian Zirpins
  - **institution:** Hochschule Karlsruhe – University of Applied Sciences, Technische Universität Berlin
  - **link:** https://arxiv.org/pdf/2511.14456
  - **Simple LLM Summary:** This paper analyzes how participant failures affect model quality in cross-silo federated learning systems with few participants. The study examines influential factors including failure timing, data distribution, and evaluation methods. Results show that high data skews lead to optimistic evaluations that hide real impacts, and failure timing significantly affects final model quality.

- **[arXiv251119] Hyperion: Hierarchical Scheduling for Parallel LLM Acceleration in Multi-tier Networks**
  - **tags:** [mlsys], [llm inference], [hierarchical scheduling, model partitioning, dynamic programming, real-time task scheduling, multi-tier networks]
  - **authors:** Mulei Ma, Minrui Xu, Zihan Chen, Yang Yang, Tony Q.S.Quek
  - **institution:** ShanghaiTech University
  - **link:** https://arxiv.org/pdf/2511.14450
  - **Simple LLM Summary:** Hyperion proposes a hierarchical two-stage framework that jointly optimizes inter-tier model partitioning and intra-tier request scheduling to minimize LLM inference latency in multi-tier networks. The system combines offline partitioning using dynamic programming with online adaptive scheduling based on real-time node capacity estimates. Experimental results show Hyperion reduces end-to-end latency by up to 52.1% compared to GPipe while maintaining higher GPU utilization.

- **[arXiv251119] Seer: Online Context Learning for Fast Synchronous LLM Reinforcement Learning**
  - **tags:** [mlsys], [llm training], [divided rollout, context-aware scheduling, adaptive grouped speculative decoding]
  - **authors:** Ruoyu Qin, Weiran He, Weixiao Huang, Yangkun Zhang, Yikai Zhao, Bo Pang, Xinran Xu, Yingdi Shan, Yongwei Wu, Mingxing Zhang
  - **institution:** Moonshot AI, Tsinghua University
  - **link:** https://arxiv.org/pdf/2511.14617
  - **Simple LLM Summary:** Seer introduces an online context learning system that uses divided rollout, context-aware scheduling, and adaptive grouped speculative decoding to optimize synchronous LLM reinforcement learning. The system addresses workload imbalance and long-tail latency in the rollout phase, achieving 74-97% throughput improvement and 75-93% latency reduction compared to state-of-the-art systems.

- **[arXiv251119] \textit{FLARE}: Adaptive Multi-Dimensional Reputation for Robust Client Reliability in Federated Learning**
  - **tags:** [mlsys], [fault-tolerance], [reputation-based framework, multi-dimensional reputation score, adaptive threshold mechanism, reputation-weighted aggregation, soft exclusion, local differential privacy]
  - **authors:** Abolfazl Younesi, Leon Kiss, Zahra Najafabadi Samani, Juan Aznar Poveda, Thomas Fahringer
  - **institution:** University of Innsbruck
  - **link:** https://arxiv.org/pdf/2511.14715
  - **Simple LLM Summary:** FLARE introduces an adaptive reputation-based framework that evaluates client reliability through multi-dimensional scoring and reputation-weighted aggregation with soft exclusion. It maintains model accuracy and converges faster than existing methods under various Byzantine attacks. The framework improves robustness by up to 16% while preserving convergence within 30% of non-attacked baselines.

- **[arXiv251119] Multi-GPU Quantum Circuit Simulation and the Impact of Network Performance**
  - **tags:** [mlsys], [cluster infrastructure], [MPI, CUDA-Q, multi-GPU communication, interconnect benchmarking]
  - **authors:** W. Michael Brown, Anurag Ramesh, Thomas Lubinski, Thien Nguyen, David E. Bernal Neira
  - **institution:** NVIDIA, Purdue University, QED-C Technical Advisory Committee, Quantum Circuits Inc.
  - **link:** https://arxiv.org/pdf/2511.14664
  - **Simple LLM Summary:** This paper introduces MPI into the QED-C Application-Oriented Benchmarks to enable multi-GPU quantum circuit simulation on HPC systems. The research benchmarks various interconnect technologies and shows that while GPU architecture improvements provided 4.5X speedups, advances in interconnect performance delivered over 16X performance improvements for multi-GPU simulations, demonstrating that network performance has a larger impact than GPU improvements alone.

- **[arXiv251119] 10Cache: Heterogeneous Resource-Aware Tensor Caching and Migration for LLM Training**
  - **tags:** [mlsys], [llm training], [tensor caching, tensor migration, memory offloading, prefetch policies, pinned memory allocation]
  - **authors:** Sabiha Afroz, Redwan Ibne Seraj Khan, Hadeel Albahar, Jingoo Han, Ali R. Butt
  - **institution:** Virginia Tech, Kuwait University
  - **link:** https://arxiv.org/pdf/2511.14124
  - **Simple LLM Summary:** 10Cache is a heterogeneous resource-aware tensor caching and migration system that coordinates memory usage across GPU, CPU, and NVMe tiers by profiling tensor execution order and optimizing memory buffer allocation. The system achieves up to 2× training speedup and significantly improves GPU cache hit rates compared to state-of-the-art offloading methods, demonstrating practical optimization for LLM training throughput in cloud environments.


**cs.AI/cs.LG contains "reinforcement learning" total: 14**
- [arXiv251119] GRPO Privacy Is at Risk: A Membership Inference Attack Against Reinforcement Learning With Verifiable Rewards [link](https://arxiv.org/pdf/2511.14045)
- [arXiv251119] Deep reinforcement learning-based spacecraft attitude control with pointing keep-out constraint [link](https://arxiv.org/pdf/2511.13746)
- [arXiv251119] Beat the long tail: Distribution-Aware Speculative Decoding for RL Training [link](https://arxiv.org/pdf/2511.13841)
- [arXiv251119] Quantifying Distribution Shift in Traffic Signal Control with Histogram-Based GEH Distance [link](https://arxiv.org/pdf/2511.13785)
- [arXiv251119] Fair-GNE : Generalized Nash Equilibrium-Seeking Fairness in Multiagent Healthcare Automation [link](https://arxiv.org/pdf/2511.14135)
- [arXiv251119] Parallelizing Tree Search with Twice Sequential Monte Carlo [link](https://arxiv.org/pdf/2511.14220)
- [arXiv251119] Object-Centric World Models for Causality-Aware Reinforcement Learning [link](https://arxiv.org/pdf/2511.14262)
- [arXiv251119] Self-Supervised Multisensory Pretraining for Contact-Rich Robot Reinforcement Learning [link](https://arxiv.org/pdf/2511.14427)
- [arXiv251119] Masked IRL: LLM-Guided Reward Disambiguation from Demonstrations and Language [link](https://arxiv.org/pdf/2511.14565)
- [arXiv251119] ReflexGrad: Three-Way Synergistic Architecture for Zero-Shot Generalization in LLM Agents [link](https://arxiv.org/pdf/2511.14584)
- [arXiv251119] Failure to Mix: Large language models struggle to answer according to desired probability distributions [link](https://arxiv.org/pdf/2511.14630)
- [arXiv251119] Heterogeneous Multi-Agent Proximal Policy Optimization for Power Distribution System Restoration [link](https://arxiv.org/pdf/2511.14730)
- [arXiv251119] $π^{*}_{0.6}$: a VLA That Learns From Experience [link](https://arxiv.org/pdf/2511.14759)
- [arXiv251119] Towards a Unified Analysis of Neural Networks in Nonparametric Instrumental Variable Regression: Optimization and Generalization [link](https://arxiv.org/pdf/2511.14710)

**cs.AI/cs.LG contains "accelerate" total: 13**
- [arXiv251119] Beat the long tail: Distribution-Aware Speculative Decoding for RL Training [link](https://arxiv.org/pdf/2511.13841)
- [arXiv251119] Can Artificial Intelligence Accelerate Technological Progress? Researchers' Perspectives on AI in Manufacturing and Materials Science [link](https://arxiv.org/pdf/2511.14007)
- [arXiv251119] nuCarla: A nuScenes-Style Bird's-Eye View Perception Dataset for CARLA Simulation [link](https://arxiv.org/pdf/2511.13744)
- [arXiv251119] A Machine Learning-Based Multimodal Framework for Wearable Sensor-Based Archery Action Recognition and Stress Estimation [link](https://arxiv.org/pdf/2511.14057)
- [arXiv251119] Review of Passenger Flow Modelling Approaches Based on a Bibliometric Analysis [link](https://arxiv.org/pdf/2511.13742)
- [arXiv251119] From Graphs to Hypergraphs: Enhancing Aspect-Based Sentiment Analysis via Multi-Level Relational Modeling [link](https://arxiv.org/pdf/2511.14142)
- [arXiv251119] Parallelizing Tree Search with Twice Sequential Monte Carlo [link](https://arxiv.org/pdf/2511.14220)
- [arXiv251119] Algebraformer: A Neural Approach to Linear Systems [link](https://arxiv.org/pdf/2511.14263)
- [arXiv251119] Self-Supervised Multisensory Pretraining for Contact-Rich Robot Reinforcement Learning [link](https://arxiv.org/pdf/2511.14427)
- [arXiv251119] Measuring AI Progress in Drug Discovery: A Reproducible Leaderboard for the Tox21 Challenge [link](https://arxiv.org/pdf/2511.14744)
- [arXiv251119] Look-Ahead Reasoning on Learning Platforms [link](https://arxiv.org/pdf/2511.14745)
- [arXiv251119] Principled Coarse-Grained Acceptance for Speculative Decoding in Speech [link](https://arxiv.org/pdf/2511.13732)
- [arXiv251119] QUASAR: An Evolutionary Algorithm to Accelerate High-Dimensional Optimization [link](https://arxiv.org/pdf/2511.13843)

## 2025-11-20

**cs.DC total: 12**

- **[arXiv251120] PolyKAN: Efficient Fused GPU Operators for Polynomial Kolmogorov-Arnold Network Variants**
  - **tags:** TBD
  - **authors:** Mingkun Yu, Heming Zhong, Dan Huang, Yutong Lu, Jiazhi Jiang
  - **institution:** 
  - **link:** https://arxiv.org/pdf/2511.14852

- **[arXiv251120] GeoShield: Byzantine Fault Detection and Recovery for Geo-Distributed Real-Time Cyber-Physical Systems**
  - **tags:** [sys], [fault-tolerance], [Byzantine fault detection, bounded-time recovery, network measurement protocols, omission fault detection]
  - **authors:** Yifan Cai, Linh Thi Xuan Phan
  - **institution:** University of Pennsylvania
  - **link:** https://arxiv.org/pdf/2511.15031
  - **Simple LLM Summary:** GeoShield introduces a resource-efficient Byzantine fault detection and recovery system for geo-distributed cyber-physical systems that uses network measurement protocols and omission fault detection instead of traditional masking approaches. It guarantees bounded-time recovery without requiring trusted hardware, making it suitable for real-time CPS. Evaluation shows it outperforms existing methods in both effectiveness and resource efficiency.

- **[arXiv251120] Privacy-Preserving IoT in Connected Aircraft Cabin**
  - **tags:** [sys], [privacy-preserving systems], [Differential Privacy, additive secret sharing, Privacy-Enhancing Technologies, CSMIM protocol]
  - **authors:** Nilesh Vyas, Benjamin Zhao, Aygün Baltaci, Gustavo de Carvalho Bertoli, Hassan Asghar, Markus Klügel, Gerrit Schramm, Martin Kubisch, Dali Kaafar
  - **institution:** Airbus Central R&T, Macquarie University
  - **link:** https://arxiv.org/pdf/2511.15278
  - **Simple LLM Summary:** This paper proposes a framework integrating Privacy-Enhancing Technologies (PETs) like Differential Privacy and additive secret sharing atop CSMIM architecture for IoT in aircraft cabins. The research demonstrates that PET computational overhead is negligible compared to network latencies, and architectural choices have greater impact on performance than the privacy techniques themselves. The findings provide practical guidance for implementing trustworthy collaborative IoT systems in avionics.

- **[arXiv251120] Multiple Sides of 36 Coins: Measuring Peer-to-Peer Infrastructure Across Cryptocurrencies**
  - **tags:** [sys], [blockchain networks], [peer-to-peer measurement, network crawling, internet-wide scanning, connectivity probes, discovery protocols]
  - **authors:** Lucianna Kiffer, Lioba Heimbach, Dennis Trautwein, Yann Vonlanthen, Oliver Gasser
  - **institution:** IMDEA Networks, Category Labs, University of Göttingen, Ethereum Foundation, IPinfo
  - **link:** https://arxiv.org/pdf/2511.15388
  - **Simple LLM Summary:** This paper presents a comprehensive measurement study of 36 blockchain networks using active crawlers, community crawlers, connectivity probes, and internet-wide scanning techniques. The research reveals dramatic variations in network size, infrastructure characteristics, and decentralization levels across different cryptocurrencies. The findings expose critical differences in network resilience and observability while establishing a general framework for measuring decentralized networks at scale.

- **[arXiv251120] A Tensor Compiler for Processing-In-Memory Architectures**
  - **tags:** [mlsys], [llm inference], [data-centric compiler, joint optimization, PIM abstraction, performance prediction model]
  - **authors:** Peiming Yang, Sankeerth Durvasula, Ivan Fernandez, Mohammad Sadrosadati, Onur Mutlu, Gennady Pekhimenko, Christina Giannoula
  - **institution:** University of Toronto, Barcelona Supercomputing Center, ETH Zurich, Max Planck Institute for Software Systems
  - **link:** https://arxiv.org/pdf/2511.15503
  - **Simple LLM Summary:** The paper introduces DCC, a data-centric ML compiler that jointly optimizes data rearrangements and compute code for Processing-In-Memory architectures. It uses a multi-layer PIM abstraction and performance prediction model to select optimal configurations. Evaluation shows DCC achieves significant speedups (up to 13.17×) for ML kernels and LLM inference compared to GPU-only execution.

- **[arXiv251120] Towards a Formal Verification of Secure Vehicle Software Updates**
  - **tags:** [sys], [automotive cybersecurity], [formal verification, ProVerif, symbolic execution, security analysis]
  - **authors:** Martin Slind Hagen, Emil Lundqvist, Alex Phu, Yenan Wang, Kim Strandberg, Elad Michael Schiller
  - **institution:** Chalmers University of Technology, Volvo Car Corporation
  - **link:** https://arxiv.org/pdf/2511.15479
  - **Simple LLM Summary:** This paper performs a formal security analysis of the Unified Software Update Framework (UniSUF) using ProVerif-based symbolic execution. The researchers modeled UniSUF's architecture and verified compliance with key security requirements including confidentiality, integrity, and authenticity. The results demonstrate that UniSUF adheres to specified security guarantees, ensuring the correctness and reliability of its security framework.

- **[arXiv251120] When Can You Trust Bitcoin? Value-Dependent Block Confirmation to Determine Transaction Finalit**
  - **tags:** [sys], [blockchain security], [blockchain forks, transaction confirmation, prospect theory, network delay analysis, mining pools]
  - **authors:** Ethan Hicks, Joseph Oglio, Mikhail Nesterenko, Gokarna Sharma
  - **institution:** Kent State University, Rio Grande University
  - **link:** https://arxiv.org/pdf/2511.15421
  - **Simple LLM Summary:** This paper analyzes Bitcoin transaction finality by studying blockchain forks through simulation and real data to establish the relationship between block depth and confirmation probability. The authors use prospect theory to relate confirmation probability to transaction amount and user risk tolerance. They conclude that transaction confirmation wait time should be value-dependent rather than using fixed block depths like the common 6-block rule.

- **[arXiv251120] BlueBottle: Fast and Robust Blockchains through Subsystem Specialization**
  - **tags:** [sys], [blockchain consensus], [two-layer architecture, n=5f+1 protocol, Byzantine fault tolerance, DAG-based consensus, synchronous recovery]
  - **authors:** Preston Vander Vos, Alberto Sonnino, Giorgos Tsimos, Philipp Jovanovic, Lefteris Kokoris-Kogias
  - **institution:** Mysten Labs, pod Network, University College London (UCL)
  - **link:** https://arxiv.org/pdf/2511.15361
  - **Simple LLM Summary:** BlueBottle introduces a two-layer consensus architecture with BB-Core for low-latency transaction processing and BB-Guard for decentralized monitoring and recovery. This subsystem specialization achieves optimistic sub-second finality while maintaining strong security guarantees. Experimental results show 20-25% latency reduction compared to Mysticeti while tolerating Byzantine failures.

- **[arXiv251120] A Graph-Based, Distributed Memory, Modeling Abstraction for Optimization**
  - **tags:** [sys], [optimization modeling], [RemoteOptiGraph, OptiGraph, distributed memory, Benders decomposition, hypergraphs, InterWorkerEdges]
  - **authors:** David L. Cole, Jordan Jalving, Jonah Langlieb, Jesse D. Jenkins
  - **institution:** Princeton University, Atomic Machines Inc.
  - **link:** https://arxiv.org/pdf/2511.14966
  - **Simple LLM Summary:** The paper introduces RemoteOptiGraph, a graph-based modeling abstraction that extends the OptiGraph model to enable distributed memory optimization by managing linking constraints across workers. This approach provides a unified framework for large-scale optimization problems and supports decomposition algorithms like Benders decomposition. The method demonstrated a 7.5x speedup when solving a mixed integer capacity expansion model with over 12 million variables and constraints compared to non-decomposed approaches.

- **[arXiv251120] GPU-Initiated Networking for NCCL**
  - **tags:** [mlsys], [cluster infrastructure], [GPU-Initiated Networking, NCCL Device API, RDMA, device-initiated communication, GPUDirect Async Kernel-Initiated, DOCA GPUNetIO, MoE architectures]
  - **authors:** Khaled Hamidouche, John Bachan, Pak Markthub, Peter-Jan Gootzen, Elena Agostini, Sylvain Jeaugey, Aamir Shafi, Georgios Theodorakis, Manjunath Gorentla Venkata
  - **institution:** NVIDIA Corporation
  - **link:** https://arxiv.org/pdf/2511.15076
  - **Simple LLM Summary:** This paper introduces GPU-Initiated Networking (GIN) within NCCL 2.28, which enables GPUs to directly initiate network communication without CPU involvement through a three-layer architecture with dual backend implementations. The method provides low-latency, device-initiated communication that eliminates CPU coordination overhead for modern AI workloads. Benchmarking shows GIN successfully integrates device-initiated operations with NCCL's collective algorithms while maintaining production infrastructure compatibility.

- **[arXiv251120] Proving there is a leader without naming it**
  - **tags:** [sys], [distributed computing], [local certification, leader election, graph theory, sublogarithmic certification, chordal graphs, grid graphs]
  - **authors:** Laurent Feuilloley, Josef Erik Sedláček, Martin Slávik
  - **institution:** Unknown (affiliations not provided in text)
  - **link:** https://arxiv.org/pdf/2511.15491
  - **Simple LLM Summary:** This paper studies local certification for leader election in networks, focusing on whether sublogarithmic certification is possible in graph classes excluding cycles. The authors develop certification schemes using graph structure properties rather than explicit identifiers, achieving efficient certification in chordal graphs, grids, and dense graphs while proving lower bounds for constant-diameter graphs. The results demonstrate that network topology significantly impacts certification complexity, with sparse structures like cycles requiring more bits than structured graphs with limited "holes".

- **[arXiv251120] Beluga: Block Synchronization for BFT Consensus Protocols**
  - **tags:** [sys], [blockchain consensus], [block synchronization, BFT consensus, push-pull mechanisms, resource-aware exchange, adversarial resilience]
  - **authors:** Tasos Kichidis, Lefteris Kokoris-Kogias, Arun Koshy, Ilya Sergey, Alberto Sonnino, Mingwei Tian, Jianting Zhang
  - **institution:** Mysten Labs, University College London, National University of Singapore, Purdue University
  - **link:** https://arxiv.org/pdf/2511.15517
  - **Simple LLM Summary:** This paper introduces Beluga, a block synchronizer for BFT consensus protocols that provides resource-aware block exchange and incremental retrieval. It addresses performance vulnerabilities in existing designs by bounding recovery costs under faults and adversarial behavior. Experimental results show Beluga delivers up to 3x higher throughput and 25x lower latency than prior approaches under attack conditions.


**cs.AI/cs.LG contains "reinforcement learning" total: 23**
- [arXiv251120] Empowering Multi-Turn Tool-Integrated Reasoning with Group Turn Policy Optimization [link](https://arxiv.org/pdf/2511.14846)
- [arXiv251120] Learning Interestingness in Automated Mathematical Theory Formation [link](https://arxiv.org/pdf/2511.14778)
- [arXiv251120] Kandinsky 5.0: A Family of Foundation Models for Image and Video Generation [link](https://arxiv.org/pdf/2511.14993)
- [arXiv251120] EntroPIC: Towards Stable Long-Term Training of LLMs via Entropy Stabilization with Proportional-Integral Control [link](https://arxiv.org/pdf/2511.15248)
- [arXiv251120] Task Specific Sharpness Aware O-RAN Resource Management using Multi Agent Reinforcement Learning [link](https://arxiv.org/pdf/2511.15002)
- [arXiv251120] Causally-Informed Reinforcement Learning for Adaptive Emotion-Aware Social Media Recommendation [link](https://arxiv.org/pdf/2511.14768)
- [arXiv251120] From Solving to Verifying: A Unified Objective for Robust Reasoning in LLMs [link](https://arxiv.org/pdf/2511.15137)
- [arXiv251120] Reasoning in Diffusion Large Language Models is Concentrated in Dynamic Confusion Zones [link](https://arxiv.org/pdf/2511.15208)
- [arXiv251120] Vehicle Routing Problems via Quantum Graph Attention Network Deep Reinforcement Learning [link](https://arxiv.org/pdf/2511.15175)
- [arXiv251120] Transformer-Guided Deep Reinforcement Learning for Optimal Takeoff Trajectory Design of an eVTOL Drone [link](https://arxiv.org/pdf/2511.14887)
- [arXiv251120] GRPO-RM: Fine-Tuning Representation Models via GRPO-Driven Reinforcement Learning [link](https://arxiv.org/pdf/2511.15256)
- [arXiv251120] Skin-R1: Toward Trustworthy Clinical Reasoning for Dermatological Diagnosis [link](https://arxiv.org/pdf/2511.14900)
- [arXiv251120] Masked Auto-Regressive Variational Acceleration: Fast Inference Makes Practical Reinforcement Learning [link](https://arxiv.org/pdf/2511.15190)
- [arXiv251120] Learning Where, What and How to Transfer: A Multi-Role Reinforcement Learning Approach for Evolutionary Multitasking [link](https://arxiv.org/pdf/2511.15199)
- [arXiv251120] Path Planning through Multi-Agent Reinforcement Learning in Dynamic Environments [link](https://arxiv.org/pdf/2511.15284)
- [arXiv251120] Terra Nova: A Comprehensive Challenge Environment for Intelligent Agents [link](https://arxiv.org/pdf/2511.15378)
- [arXiv251120] Simulated Human Learning in a Dynamic, Partially-Observed, Time-Series Environment [link](https://arxiv.org/pdf/2511.15032)
- [arXiv251120] Learning Human-Like RL Agents Through Trajectory Optimization With Action Quantization [link](https://arxiv.org/pdf/2511.15055)
- [arXiv251120] Continual Reinforcement Learning for Cyber-Physical Systems: Lessons Learned and Open Challenges [link](https://arxiv.org/pdf/2511.15652)
- [arXiv251120] VisPlay: Self-Evolving Vision-Language Models from Images [link](https://arxiv.org/pdf/2511.15661)
- [arXiv251120] DeepThinkVLA: Enhancing Reasoning Capability of Vision-Language-Action Models [link](https://arxiv.org/pdf/2511.15669)
- [arXiv251120] The Impact of Quantization on Large Reasoning Model Reinforcement Learning [link](https://arxiv.org/pdf/2511.15694)
- [arXiv251120] Reinforcement Learning in Queue-Reactive Models: Application to Optimal Execution [link](https://arxiv.org/pdf/2511.15262)

**cs.AI/cs.LG contains "accelerate" total: 11**
- [arXiv251120] Optimizing Agricultural Research: A RAG-Based Approach to Mycorrhizal Fungi Information [link](https://arxiv.org/pdf/2511.14765)
- [arXiv251120] Masked Auto-Regressive Variational Acceleration: Fast Inference Makes Practical Reinforcement Learning [link](https://arxiv.org/pdf/2511.15190)
- [arXiv251120] Quant-Trim in Practice: Improved Cross-Platform Low-Bit Deployment on Edge NPUs [link](https://arxiv.org/pdf/2511.15300)
- [arXiv251120] NTK-Guided Implicit Neural Teaching [link](https://arxiv.org/pdf/2511.15487)
- [arXiv251120] SVBRD-LLM: Self-Verifying Behavioral Rule Discovery for Autonomous Vehicle Identification [link](https://arxiv.org/pdf/2511.14977)
- [arXiv251120] D2D Power Allocation via Quantum Graph Neural Network [link](https://arxiv.org/pdf/2511.15246)
- [arXiv251120] Path Planning through Multi-Agent Reinforcement Learning in Dynamic Environments [link](https://arxiv.org/pdf/2511.15284)
- [arXiv251120] B+ANN: A Fast Billion-Scale Disk-based Nearest-Neighbor Index [link](https://arxiv.org/pdf/2511.15557)
- [arXiv251120] What Does It Take to Be a Good AI Research Agent? Studying the Role of Ideation Diversity [link](https://arxiv.org/pdf/2511.15593)
- [arXiv251120] Fully Differentiable dMRI Streamline Propagation in PyTorch [link](https://arxiv.org/pdf/2511.14807)
- [arXiv251120] Particle Monte Carlo methods for Lattice Field Theory [link](https://arxiv.org/pdf/2511.15196)
