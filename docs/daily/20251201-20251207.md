# 20251201-20251207

## 2025-12-01

**cs.DC total: 23**

- **[arXiv251201] PAT: Accelerating LLM Decoding via Prefix-Aware Attention with Resource Efficient Multi-Tile Kernel**
  - **tags:** [mlsys], [llm inference], [prefix-aware attention, multi-tile kernel, KV cache optimization, pack-forward-merge, vLLM plugin]
  - **authors:** Jinjun Yi, Zhixin Zhao, Yitao Hu, Ke Yan, Weiwei Sun, Hao Wang, Laiping Zhao, Yuhao Zhang, Wenxin Li, Keqiu Li
  - **institution:** Tianjin University, Stevens Institute of Technology
  - **link:** https://arxiv.org/pdf/2511.22333
  - **Simple LLM Summary:** This paper introduces PAT, a prefix-aware attention kernel that accelerates LLM decoding by organizing queries by shared prefix to reduce redundant KV cache loads and using a resource-efficient multi-tile kernel. Evaluations show PAT significantly reduces attention latency and improves throughput compared to state-of-the-art kernels.

- **[arXiv251201] Silence Speaks Volumes: A New Paradigm for Covert Communication via History Timing Patterns**
  - **tags:** [sys], [network security], [History Covert Channels, relative pointers, timing patterns, covert amplification factor, bitrate]
  - **authors:** Christoph Weissenborn, Steffen Wendzel
  - **institution:** Federal Office for Information Security, Ulm University
  - **link:** https://arxiv.org/pdf/2511.22259
  - **Simple LLM Summary:** This paper introduces a novel covert communication method called History Covert Channels (HCC), which uses relative pointers to past network timing patterns to embed hidden messages, reducing reliance on centralized timekeeping. The method is designed to be more robust and less detectable than traditional approaches. The experiments demonstrate that this new method achieves a higher bitrate compared to previous work.

- **[arXiv251201] ZipperChain: Transmuting Trusted Third-Party Services Into Trustless Atomic Broadcast**
  - **tags:** [sys], [distributed ledger technology], [ZipperChain, atomic broadcast, trust transfer, third-party services, block pipeline, fast data center network]
  - **authors:** Matteo Bjornsson, Taylor Hardin, Taylor Heinecke, Marcin Furtak, David L. Millman, Mike P. Wittie
  - **institution:** BLOCKY, Inc.
  - **link:** https://arxiv.org/pdf/2511.21969
  - **Simple LLM Summary:** The paper proposes ZipperChain, a blockchain that replaces distributed consensus with a pipeline of specialized services on a small number of nodes, transferring trust from established third-party services. This approach achieves high transaction throughput near network line speeds and fast block finality (~500 ms) without needing a native token.

- **[arXiv251201] An Empirical Study of Cross-Language Interoperability in Replicated Data Systems**
  - **tags:** [sys], [distributed systems], [replicated data libraries, foreign-function interface, common data format, cross-language interoperability, empirical study]
  - **authors:** Provakar Mondal, Eli Tilevich
  - **institution:** Virginia Tech
  - **link:** https://arxiv.org/pdf/2511.22010
  - **Simple LLM Summary:** This paper empirically studies two strategies for integrating Replicated Data Libraries (RDLs) in multilingual distributed systems: Foreign-Function Interface (FFI) and Common Data Format (CDF). It finds that the CDF approach offers superior software quality, latency, memory consumption, and throughput, and validates this by creating a CDF-based RDL with plug-in extensibility.

- **[arXiv251201] When AI Bends Metal: AI-Assisted Optimization of Design Parameters in Sheet Metal Forming**
  - **tags:** [mlsys], [others], [Bayesian optimization, deep learning, active learning, design space exploration, numerical simulation]
  - **authors:** Ahmad Tarraf, Koutaiba Kassem-Manthey, Seyed Ali Mohammadi, Philipp Martin, Lukas Moj, Semih Burak, Enju Park, Christian Terboven, Felix Wolf
  - **institution:** Technical University of Darmstadt, GNS Gesellschaft für numerische Simulation mbH, RWTH Aachen University, GNS Systems GmbH
  - **link:** https://arxiv.org/pdf/2511.22302
  - **Simple LLM Summary:** This paper presents an AI-assisted workflow that combines deep learning and Bayesian optimization to automate the tuning of design parameters in sheet metal forming simulations. The method reduces the need for expert involvement and computational cost by providing an initial parameter estimate and iteratively refining the design. The approach accelerates design space exploration and can be adapted to other simulation-driven engineering tasks.

- **[arXiv251201] Clock2Q+: A Simple and Efficient Replacement Algorithm for Metadata Cache in VMware vSAN**
  - **tags:** [sys], [storage systems], [Clock2Q+, cache replacement algorithm, metadata cache, correlated references, S3-FIFO, three queues, correlation window]
  - **authors:** Yiyan Zhai, Bintang Dwi Marthen, Sarath Balivada, Vamsi Sudhakar Bojji, Eric Knauft, Jitender Rohilla, Jiaqi Zuo, Quanxing Liu, Maxime Austruy, Wenguang Wang, Juncheng Yang
  - **institution:** Carnegie Mellon University, Bandung Institute of Technology, Broadcom Inc., Harvard University
  - **link:** https://arxiv.org/pdf/2511.21958
  - **Simple LLM Summary:** This paper proposes Clock2Q+, a cache replacement algorithm designed for metadata caches that introduces a correlation window in its Small FIFO queue to prevent correlated references from being mistakenly categorized as hot blocks. The method outperforms state-of-the-art algorithms like S3-FIFO, achieving up to a 28.5% lower miss ratio on metadata traces while maintaining low overhead and scalability. It has been implemented in VMware vSAN and VDFS, demonstrating effectiveness for large-scale storage systems.

- **[arXiv251201] A Sustainable and Reward Incentivized High-Performance Cluster Computing for Artificial Intelligence: A Novel Bayesian-Time-Decay Trust Mechanism in Blockchain**
  - **tags:** [mlsys], [cluster infrastructure], [blockchain, proof-of-work, trust rating, bayesian-time-decay, high-performance cluster computing, statistical draw system]
  - **authors:** Murat Yaslioglu
  - **institution:** Istanbul University
  - **link:** https://arxiv.org/pdf/2511.21844
  - **Simple LLM Summary:** This paper proposes a novel blockchain-based framework that integrates high-performance cluster computing with AI, using an evolved proof-of-work consensus and a Bayesian-time-decay trust mechanism to incentivize participation and ensure sustainability. The method links computational effort to rewards and employs a dynamic trust rating and statistical draw to create a more equitable and energy-efficient system for AI development. The main conclusion is that this approach fosters a more inclusive, merit-based, and environmentally conscious landscape for AI progression.

- **[arXiv251201] OOCO: Latency-disaggregated Architecture for Online-Offline Co-locate LLM Serving**
  - **tags:** [mlsys], [llm inference], [prefill/decode disaggregation, latency-constraint disaggregated architecture, bottleneck-based scheduler, roofline-based performance model, fast preemption mechanism]
  - **authors:** Siyu Wu, Zihan Tang, Yuting Zeng, Hui Chen, Guiguang Ding, Tongxuan Liu, Ke Zhang, Hailong Yang
  - **institution:** Beihang University, Tsinghua University, University of Science and Technology of China, JD Company
  - **link:** https://arxiv.org/pdf/2511.21862
  - **Simple LLM Summary:** The paper proposes OOCO, a latency-disaggregated architecture that separates cluster resources into latency-strict and latency-relaxed pools to co-locate online and offline LLM workloads. It introduces a bottleneck-based scheduler and a fast preemption mechanism to mitigate Prefill/Decode imbalance and enforce SLOs. Experiments show the method improves offline throughput by up to 3x while maintaining online request SLOs.

- **[arXiv251201] Equivalence and Separation between Heard-Of and Asynchronous Message-Passing Models**
  - **tags:** [sys], [distributed computing], [Heard-Of model, asynchronous message-passing, colorless tasks, colored tasks, bidirectional simulation, message adversaries, crash failures, message omissions]
  - **authors:** Hagit Attiya, Armando Castañeda, Dhrubajyoti Ghosh, Thomas Nowak
  - **institution:** Technion – Israel Institute of Technology, Instituto de Matemáticas, Universidad Nacional Autónoma de México, Université Paris-Saclay, CNRS, ENS Paris-Saclay, Laboratoire Méthodes Formelles, Institut Universitaire de France
  - **link:** https://arxiv.org/pdf/2511.21859
  - **Simple LLM Summary:** This paper analyzes the relationship between the asynchronous message-passing model (AMP) and the Heard-Of model (HO) through bidirectional simulations and an intermediate model capturing process silencing. It concludes that the models are equivalent for solving colorless tasks when n &gt; 2f, but for colored tasks, equivalence only holds for f=1, with separation arising for larger f due to silenced processes.

- **[arXiv251201] A Fast and Flat Federated Learning Method via Weighted Momentum and Sharpness-Aware Minimization**
  - **tags:** [mlsys], [others], [federated learning, sharpness-aware minimization, momentum, non-IID data, convergence analysis]
  - **authors:** Tianle Li, Yongzhi Huang, Linshan Jiang, Chang Liu, Qipeng Xie, Wenfeng Du, Lu Wang, Kaishun Wu
  - **institution:** Shenzhen University, The Hong Kong University of Science and Technology (Guangzhou), National University of Singapore, Nanyang Technological University, Singapore
  - **link:** https://arxiv.org/pdf/2511.22080
  - **Simple LLM Summary:** This paper proposes FedWMSAM, a federated learning method that combines weighted momentum and sharpness-aware minimization to address local-global curvature misalignment and momentum-echo oscillation in non-IID settings. It uses a momentum-guided global perturbation and an adaptive two-phase training schedule. Experiments show the method is effective and superior for fast, flat convergence in federated learning.

- **[arXiv251201] Optimality of Simultaneous Consensus with Limited Information Exchange (Extended Abstract)**
  - **tags:** [sys], [distributed consensus], [epistemic logic, knowledge-based program, simultaneous agreement, crash failures, limited information exchange, optimality]
  - **authors:** Kaya Alpturer, Ron van der Meyden, Sushmita Ruj, Godfrey Wong
  - **institution:** Princeton University, UNSW Sydney
  - **link:** https://arxiv.org/pdf/2511.22380
  - **Simple LLM Summary:** The paper studies the Simultaneous Agreement problem in distributed systems under crash failures, using epistemic logic and knowledge-based programming to derive optimal protocols for various limited information exchange schemes. It introduces a new information exchange that achieves near-optimal decision time with lower computational and space costs compared to prior optimal protocols.

- **[arXiv251201] DisCEdge: Distributed Context Management for Large Language Models at the Edge**
  - **tags:** [mlsys], [llm inference], [distributed context management, tokenized context, geo-distributed edge nodes, data replication, client-side context storage]
  - **authors:** Mohammadreza Malekabbasi, Minghe Wang, David Bermbach
  - **institution:** TU Berlin
  - **link:** https://arxiv.org/pdf/2511.22599
  - **Simple LLM Summary:** The paper proposes DisCEdge, a system that manages user context for LLMs by storing and replicating it in tokenized form across distributed edge nodes. This approach reduces redundant computation and network overhead compared to raw-text or client-side storage. The evaluation shows it improves response times, lowers synchronization costs, and significantly reduces client request sizes while maintaining data consistency.

- **[arXiv251201] Federated Learning Survey: A Multi-Level Taxonomy of Aggregation Techniques, Experimental Insights, and Future Frontiers**
  - **tags:** [mlsys], [others], [federated learning, aggregation methods, privacy-preserving, security, heterogeneity, optimization, personalization, robustness, IID, non-IID]
  - **authors:** Meriem Arbaoui, Mohamed-el-Amine Brahmia, Abdellatif Rahmoun, Mourad Zghal
  - **institution:** LabRi-SBA Laboratory, CESI LINEACT UR 7527
  - **link:** https://arxiv.org/pdf/2511.22616
  - **Simple LLM Summary:** This survey paper employs a hybrid methodology combining bibliometric analysis and systematic review to classify and analyze Federated Learning research, focusing on aggregation techniques, personalization, optimization, and robustness. It concludes by comparing aggregation methods under different data distributions and outlining future research directions to advance the field.

- **[arXiv251201] RetryGuard: Preventing Self-Inflicted Retry Storms in Cloud Microservices Applications**
  - **tags:** [sys], [cloud computing, microservices], [retry policy, analytic model, distributed framework, denial-of-wallet, auto-scaling]
  - **authors:** Jhonatan Tavori, Anat Bremler-Barr, Hanoch Levy, Ofek Lavi
  - **institution:** Tel Aviv University
  - **link:** https://arxiv.org/pdf/2511.23278
  - **Simple LLM Summary:** The paper introduces RetryGuard, a distributed framework that uses an analytic model to manage retry policies per microservice and prevent retry storms. It demonstrates that RetryGuard effectively reduces resource usage and operational costs compared to standard cloud retry policies in complex deployments.

- **[arXiv251201] Serving Heterogeneous LoRA Adapters in Distributed LLM Inference Systems**
  - **tags:** [mlsys], [llm inference], [LoRA, dynamic adapter placement, GPU Direct RDMA, multi-tenant serving, performance skew]
  - **authors:** Shashwat Jaiswal, Shrikara Arun, Anjaly Parayil, Ankur Mallick, Spyros Mastorakis, Alind Khare, Chloi Alverti, Renee St Amant, Chetan Bansal, Victor Rühle, Josep Torrellas
  - **institution:** University of Illinois Urbana-Champaign, Microsoft, National Technical University of Athens
  - **link:** https://arxiv.org/pdf/2511.22880
  - **Simple LLM Summary:** The paper introduces LoRAServe, a workload-aware framework for distributed LLM inference that dynamically places and routes heterogeneous LoRA adapters across GPUs to address performance skew. It leverages GPU Direct RDMA for remote access to improve resource utilization. The system demonstrates significantly higher throughput, lower latency, and reduced GPU requirements compared to state-of-the-art serving systems.

- **[arXiv251201] OmniInfer: System-Wide Acceleration Techniques for Optimizing LLM Serving Throughput and Latency**
  - **tags:** [mlsys], [llm inference], [Mixture-of-Experts scheduling, sparse attention acceleration, prefill-decode disaggregation, continuous batching, KV-cache reuse, resource disaggregation]
  - **authors:** Jun Wang, Yunxiang Yao, Wenwei Kuang, Runze Mao, Zhenhao Sun, Zhuang Tao, Ziyang Zhang, Dengyu Li, Jiajun Chen, Zhili Wang, Kai Cui, Congzhi Cai, Longwen Lan, Ken Zhang
  - **institution:** Huawei Technologies Co., Ltd.
  - **link:** https://arxiv.org/pdf/2511.22481
  - **Simple LLM Summary:** The paper introduces OmniInfer, a system-level acceleration framework built on vLLM that optimizes LLM serving through three components: OmniPlacement for expert scheduling, OmniAttn for sparse attention, and OmniProxy for request scheduling. It achieves performance gains by adaptively disaggregating resources and coordinating prefill and decode phases. Evaluated on a 10-node cluster, the framework significantly reduces time per output token and time to first token.

- **[arXiv251201] Communication-Computation Pipeline Parallel Split Learning over Wireless Edge Networks**
  - **tags:** [mlsys], [others], [split learning, pipeline parallelism, wireless edge networks, communication-computation overlap, alternating optimization, task split, resource allocation]
  - **authors:** Chenyu Liu, Zhaoyang Zhang, Zirui Chen, Zhaohui Yang
  - **institution:** Zhejiang University
  - **link:** https://arxiv.org/pdf/2511.23167
  - **Simple LLM Summary:** This paper proposes C²P²SL, a method that applies pipeline parallelism to split learning in wireless networks to overlap communication and computation processes, thereby reducing training time. It formulates a joint optimization problem for task split and resource allocation, solved via alternating optimization. Experiments show the approach reduces system training time by over 38% while maintaining accuracy.

- **[arXiv251201] Areon: Latency-Friendly and Resilient Multi-Proposer Consensus**
  - **tags:** [sys], [blockchain consensus], [proof-of-stake, directed acyclic graph (DAG), multi-proposer, fork choice rule, VRF, partial synchrony, finality]
  - **authors:** Álvaro Castro-Castilla, Marcin Pawlowski, Hong-Sheng Zhou
  - **institution:** Nomos, Institute of Free Technology, Jagiellonian University, Virginia Commonwealth University
  - **link:** https://arxiv.org/pdf/2511.23025
  - **Simple LLM Summary:** The paper presents Areon, a multi-proposer proof-of-stake consensus protocol that organizes blocks into a DAG to achieve robustness under partial synchrony. Its fork choice rule resolves conflicts by comparing subDAG weights within a sliding window. Simulation results show it achieves bounded-latency finality with lower reorganization frequency and depth compared to a chain-based baseline.

- **[arXiv251201] Accelerating mesh-based Monte Carlo simulations using contemporary graphics ray-tracing hardware**
  - **tags:** [sys], [biophotonics simulation], [mesh-based Monte Carlo, ray-tracing, GPU acceleration, RT-cores, OptiX, hardware-accelerated ray traversal]
  - **authors:** Shijie Yan, Douglas Dwyer, David R. Kaeli, Qianqian Fang
  - **institution:** Northeastern University
  - **link:** https://arxiv.org/pdf/2511.22779
  - **Simple LLM Summary:** The paper proposes RT-MMC, a mesh-based Monte Carlo method for light transport simulation that leverages modern GPU ray-tracing hardware (RT-cores via NVIDIA OptiX) to accelerate computationally expensive ray-boundary intersection tests. This approach eliminates the need for complex tetrahedral mesh generation and achieves speedups of 1.5x to 4.5x over traditional software-based methods. The migration to hardware-based ray-tracing simplifies simulation workflows and significantly enhances the practicality of MMC for biophotonics applications.

- **[arXiv251201] Closing the Generalization Gap in Parameter-efficient Federated Edge Learning**
  - **tags:** [mlsys], [others], [model pruning, client selection, joint resource management, generalization analysis, alternating optimization]
  - **authors:** Xinnong Du, Zhonghao Lyu, Xiaowen Cao, Chunyang Wen, Shuguang Cui, Jie Xu
  - **institution:** The Chinese University of Hong Kong (Shenzhen), KTH Royal Institute of Technology, Shenzhen University, University of Science and Technology of China
  - **link:** https://arxiv.org/pdf/2511.23282
  - **Simple LLM Summary:** The paper proposes a parameter-efficient federated edge learning framework that jointly optimizes model pruning, client selection, and communication-computation resources to minimize a generalization-aware objective under energy and delay constraints. It solves the resulting non-convex mixed-integer problem using an alternating optimization algorithm. Experiments show the proposed design achieves superior learning performance compared to baselines, validating the effectiveness of integrating generalization analysis with system-level optimization.

- **[arXiv251201] Beyond 2-Edge-Connectivity: Algorithms and Impossibility for Content-Oblivious Leader Election**
  - **tags:** [sys], [distributed computing], [content-oblivious communication, leader election, topology knowledge, edge symmetry, tree algorithms, impossibility results]
  - **authors:** Yi-Jun Chang, Lyuting Chen, Haoran Zhou
  - **institution:** National University of Singapore
  - **link:** https://arxiv.org/pdf/2511.23297
  - **Simple LLM Summary:** This paper studies leader election in the content-oblivious communication model, where nodes can only send asynchronous, content-less pulses. It shows that with exact knowledge of the network topology, leader election is possible in many non-2-edge-connected graphs like trees, but is impossible for graphs symmetric about an edge, and that precise topology knowledge is sometimes necessary.

- **[arXiv251201] Accelerated Execution of Bayesian Neural Networks using a Single Probabilistic Forward Pass and Code Generation**
  - **tags:** [mlsys], [others], [Probabilistic Forward Pass, Bayesian Neural Networks, TVM, code generation, Gaussian propagation, Stochastic Variational Inference]
  - **authors:** Bernhard Klein, Falk Selker, Hendrik Borras, Sophie Steger, Franz Pernkopf, Holger Fröning
  - **institution:** Heidelberg University, Graz University of Technology
  - **link:** https://arxiv.org/pdf/2511.23440
  - **Simple LLM Summary:** This paper presents an end-to-end pipeline that uses a Probabilistic Forward Pass (PFP) to approximate Bayesian Neural Networks, enabling efficient uncertainty estimation with a single deterministic forward pass instead of multiple sampling passes. The method is implemented and optimized for embedded ARM CPUs using the TVM deep learning compiler with custom Gaussian-propagating operators. The results show that PFP-based BNNs match the accuracy and uncertainty quality of traditional methods while achieving speedups of up to 4200x, enabling efficient deployment on resource-constrained systems.

- **[arXiv251201] A lasso-alternative to Dijkstra's algorithm for identifying short paths in networks**
  - **tags:** [sys], [graph theory, optimization], [lasso, LARS, ADMM, bi-directional Dijkstra, ℓ1-regularized regression]
  - **authors:** Anqi Dong, Amirhossein Taghvaei, Tryphon T. Georgiou
  - **institution:** KTH Royal Institute of Technology, University of Washington, University of California, Irvine
  - **link:** https://arxiv.org/pdf/2511.22745
  - **Simple LLM Summary:** This paper formulates the shortest path problem in graphs as an ℓ1-regularized regression (lasso) problem. It connects this formulation to the LARS algorithm and the bi-directional Dijkstra algorithm, and highlights the applicability of ADMM for solving it. The main conclusion is that this lasso-based approach offers an alternative for finding short paths, with benefits like efficient updates to network topology changes.


**cs.AI/cs.LG contains "reinforcement learning" total: 33**
- [arXiv251201] An energy-efficient spiking neural network with continuous learning for self-adaptive brain-machine interface [link](https://arxiv.org/pdf/2511.22108)
- [arXiv251201] BiCQL-ML: A Bi-Level Conservative Q-Learning Framework for Maximum Likelihood Inverse Reinforcement Learning [link](https://arxiv.org/pdf/2511.22210)
- [arXiv251201] Adaptive Dueling Double Deep Q-networks in Uniswap V3 Replication and Extension with Mamba [link](https://arxiv.org/pdf/2511.22101)
- [arXiv251201] Heterogeneous Multi-Agent Reinforcement Learning with Attention for Cooperative and Scalable Feature Transformation [link](https://arxiv.org/pdf/2511.21934)
- [arXiv251201] Goal-Directed Search Outperforms Goal-Agnostic Memory Compression in Long-Context Memory Tasks [link](https://arxiv.org/pdf/2511.21726)
- [arXiv251201] Focused Chain-of-Thought: Efficient LLM Reasoning via Structured Input Information [link](https://arxiv.org/pdf/2511.22176)
- [arXiv251201] Prompted Policy Search: Reinforcement Learning through Linguistic and Numerical Reasoning in LLMs [link](https://arxiv.org/pdf/2511.21928)
- [arXiv251201] GPS: General Per-Sample Prompter [link](https://arxiv.org/pdf/2511.21714)
- [arXiv251201] TinyLLM: Evaluation and Optimization of Small Language Models for Agentic Tasks on Edge Devices [link](https://arxiv.org/pdf/2511.22138)
- [arXiv251201] Embedded Universal Predictive Intelligence: a coherent framework for multi-agent learning [link](https://arxiv.org/pdf/2511.22226)
- [arXiv251201] Training High-Level Schedulers with Execution-Feedback Reinforcement Learning for Long-Horizon GUI Automation [link](https://arxiv.org/pdf/2511.22235)
- [arXiv251201] Representative Action Selection for Large Action Space: From Bandits to MDPs [link](https://arxiv.org/pdf/2511.22104)
- [arXiv251201] MedEyes: Learning Dynamic Visual Focus for Medical Progressive Diagnosis [link](https://arxiv.org/pdf/2511.22018)
- [arXiv251201] Hybrid Stackelberg Game and Diffusion-based Auction for Two-tier Agentic AI Task Offloading in Internet of Agents [link](https://arxiv.org/pdf/2511.22076)
- [arXiv251201] Energy Efficient Sleep Mode Optimization in 5G mmWave Networks via Multi Agent Deep Reinforcement Learning [link](https://arxiv.org/pdf/2511.22105)
- [arXiv251201] Factors That Support Grounded Responses in LLM Conversations: A Rapid Review [link](https://arxiv.org/pdf/2511.21762)
- [arXiv251201] Improving Stochastic Action-Constrained Reinforcement Learning via Truncated Distributions [link](https://arxiv.org/pdf/2511.22406)
- [arXiv251201] DeepSeekMath-V2: Towards Self-Verifiable Mathematical Reasoning [link](https://arxiv.org/pdf/2511.22570)
- [arXiv251201] ReAG: Reasoning-Augmented Generation for Knowledge-based Visual Question Answering [link](https://arxiv.org/pdf/2511.22715)
- [arXiv251201] ORION: Teaching Language Models to Reason Efficiently in the Language of Thought [link](https://arxiv.org/pdf/2511.22891)
- [arXiv251201] Switching-time bioprocess control with pulse-width-modulated optogenetics [link](https://arxiv.org/pdf/2511.22893)
- [arXiv251201] Language-conditioned world model improves policy generalization by reading environmental descriptions [link](https://arxiv.org/pdf/2511.22904)
- [arXiv251201] Commanding Humanoid by Free-form Language: A Large Language Action Model with Unified Motion Vocabulary [link](https://arxiv.org/pdf/2511.22963)
- [arXiv251201] Evolutionary Discovery of Heuristic Policies for Traffic Signal Control [link](https://arxiv.org/pdf/2511.23122)
- [arXiv251201] Peer-to-Peer Energy Trading in Dairy Farms using Multi-Agent Reinforcement Learning [link](https://arxiv.org/pdf/2511.23148)
- [arXiv251201] REVEAL: Reasoning-enhanced Forensic Evidence Analysis for Explainable AI-generated Image Detection [link](https://arxiv.org/pdf/2511.23158)
- [arXiv251201] Fault-Tolerant MARL for CAVs under Observation Perturbations for Highway On-Ramp Merging [link](https://arxiv.org/pdf/2511.23193)
- [arXiv251201] Adapting Like Humans: A Metacognitive Agent with Test-time Reasoning [link](https://arxiv.org/pdf/2511.23262)
- [arXiv251201] Emergent Coordination and Phase Structure in Independent Multi-Agent Reinforcement Learning [link](https://arxiv.org/pdf/2511.23315)
- [arXiv251201] ASTRO: Adaptive Stitching via Dynamics-Guided Trajectory Rollouts [link](https://arxiv.org/pdf/2511.23442)
- [arXiv251201] ThetaEvolve: Test-time Learning on Open Problems [link](https://arxiv.org/pdf/2511.23473)
- [arXiv251201] RELiQ: Scalable Entanglement Routing via Reinforcement Learning in Quantum Networks [link](https://arxiv.org/pdf/2511.22321)
- [arXiv251201] OBLR-PO: A Theoretical Framework for Stable Reinforcement Learning [link](https://arxiv.org/pdf/2511.23310)

**cs.AI/cs.LG contains "accelerate" total: 19**
- [arXiv251201] Orchestrating Dual-Boundaries: An Arithmetic Intensity Inspired Acceleration Framework for Diffusion Language Models [link](https://arxiv.org/pdf/2511.21759)
- [arXiv251201] Co-Evolving Agents: Learning from Failures as Hard Negatives [link](https://arxiv.org/pdf/2511.22254)
- [arXiv251201] MRI-Based Brain Age Estimation with Supervised Contrastive Learning of Continuous Representation [link](https://arxiv.org/pdf/2511.22102)
- [arXiv251201] ResearchArcade: Graph Interface for Academic Tasks [link](https://arxiv.org/pdf/2511.22036)
- [arXiv251201] R2Q: Towards Robust 2-Bit Large Language Models via Residual Refinement Quantization [link](https://arxiv.org/pdf/2511.21736)
- [arXiv251201] Massively Parallel Imitation Learning of Mouse Forelimb Musculoskeletal Reaching Dynamics [link](https://arxiv.org/pdf/2511.21848)
- [arXiv251201] Standardized Threat Taxonomy for AI Security, Governance, and Regulatory Compliance [link](https://arxiv.org/pdf/2511.21901)
- [arXiv251201] Toward Automated and Trustworthy Scientific Analysis and Visualization with LLM-Generated Code [link](https://arxiv.org/pdf/2511.21920)
- [arXiv251201] Cacheback: Speculative Decoding With Nothing But Cache [link](https://arxiv.org/pdf/2511.21699)
- [arXiv251201] GLA-Grad++: An Improved Griffin-Lim Guided Diffusion Model for Speech Synthesis [link](https://arxiv.org/pdf/2511.22293)
- [arXiv251201] FastFHE: Packing-Scalable and Depthwise-Separable CNN Inference Over FHE [link](https://arxiv.org/pdf/2511.22434)
- [arXiv251201] An Efficient Embedding Based Ad Retrieval with GPU-Powered Feature Interaction [link](https://arxiv.org/pdf/2511.22460)
- [arXiv251201] Revisiting the Necessity of Lengthy Chain-of-Thought in Vision-centric Reasoning Generalization [link](https://arxiv.org/pdf/2511.22586)
- [arXiv251201] GAVINA: flexible aggressive undervolting for bit-serial mixed-precision DNN acceleration [link](https://arxiv.org/pdf/2511.23203)
- [arXiv251201] Simultaneous Image Quality Improvement and Artefacts Correction in Accelerated MRI [link](https://arxiv.org/pdf/2511.23274)
- [arXiv251201] QuantumChem-200K: A Large-Scale Open Organic Molecular Dataset for Quantum-Chemistry Property Screening and Language Model Benchmarking [link](https://arxiv.org/pdf/2511.21747)
- [arXiv251201] Automated Statistical and Machine Learning Platform for Biological Research [link](https://arxiv.org/pdf/2511.21770)
- [arXiv251201] Generative models for crystalline materials [link](https://arxiv.org/pdf/2511.22652)
- [arXiv251201] Escaping Barren Plateaus in Variational Quantum Algorithms Using Negative Learning Rate in Quantum Internet of Things [link](https://arxiv.org/pdf/2511.22861)
