# 20251208-20251214

## 2025-12-08

**cs.DC total: 7**

- **[arXiv251208] Metronome: Differentiated Delay Scheduling for Serverless Functions**
  - **tags:** [mlsys], [cluster infrastructure], [delay scheduling, online random forest regression, differentiated scheduling, locality-aware scheduling, SLA compliance]
  - **authors:** Zhuangbin Chen, Juzheng Zheng, Zibin Zheng
  - **institution:** Sun Yat-sen University
  - **link:** https://arxiv.org/pdf/2512.05703
  - **Simple LLM Summary:** This paper proposes Metronome, a differentiated delay scheduling framework for serverless functions that uses an online Random Forest Regression model to predict function execution times and identify optimal locality-aware nodes. The system significantly reduces mean execution time by 64.88%-95.83% compared to baselines while maintaining SLA compliance under increased concurrency.

- **[arXiv251208] FedGMR: Federated Learning with Gradual Model Restoration under Asynchrony and Model Heterogeneity**
  - **tags:** [mlsys], [others], [federated learning, model heterogeneity, gradual model restoration, mask-aware aggregation, asynchronous training, bandwidth-constrained clients]
  - **authors:** Chengjie Ma, Seungeun Oh, Jihong Park, Seong-Lyun Kim
  - **institution:** Yonsei University
  - **link:** https://arxiv.org/pdf/2512.05372
  - **Simple LLM Summary:** The paper proposes FedGMR, a federated learning method that gradually increases the density of sub-models for bandwidth-constrained clients during training to maintain their effectiveness. It introduces a mask-aware aggregation rule for asynchronous, model-heterogeneous settings and provides convergence guarantees. Experiments show FedGMR achieves faster convergence and higher accuracy, especially under high heterogeneity and non-IID data.

- **[arXiv251208] NVLang: Unified Static Typing for Actor-Based Concurrency on the BEAM**
  - **tags:** [sys], [programming languages], [algebraic data types, Hindley-Milner type inference, typed process identifiers, typed futures, Core Erlang]
  - **authors:** Miguel de Oliveira Guerreiro
  - **institution:** University of Lisbon
  - **link:** https://arxiv.org/pdf/2512.05224
  - **Simple LLM Summary:** NVLang is a statically typed functional language that uses algebraic data types to encode actor message protocols and extends Hindley-Milner type inference to enforce them at compile time. It introduces typed process identifiers and futures to provide type safety for message passing on the BEAM virtual machine. The paper concludes that this approach eliminates a class of runtime errors while preserving interoperability with the Erlang ecosystem.

- **[arXiv251208] InvarDiff: Cross-Scale Invariance Caching for Accelerated Diffusion Models**
  - **tags:** [mlsys], [diffusion inference], [invariance caching, deterministic sampling, quantile-based change metrics, re-sampling correction, binary cache plan matrix]
  - **authors:** Zihao Wu
  - **institution:** Peking University
  - **link:** https://arxiv.org/pdf/2512.05134
  - **Simple LLM Summary:** InvarDiff is a training-free acceleration method for diffusion models that exploits feature invariance across timesteps and layers to cache and reuse computations, guided by a precomputed binary cache plan. It achieves 2–3× end-to-end speed-ups on models like DiT and FLUX with minimal impact on fidelity or visual quality.

- **[arXiv251208] Model Gateway: Model Management Platform for Model-Driven Drug Discovery**
  - **tags:** [mlsys], [cluster infrastructure], [MLOps, model registry, LLM Agents, Generative AI, dynamic consensus model, asynchronous execution, cloud computing]
  - **authors:** Yan-Shiun Wu, Nathan A. Morin
  - **institution:** Eli Lilly and Company
  - **link:** https://arxiv.org/pdf/2512.05462
  - **Simple LLM Summary:** The paper presents Model Gateway, a cloud-based platform for managing machine learning and scientific computational models in drug discovery pipelines. It integrates MLOps practices, LLM Agents, and Generative AI tools to handle tasks like model registration, asynchronous execution, and dynamic consensus building. The platform demonstrated scalability with a 0% failure rate under high load and is concluded to be a fundamental component for accelerating model-driven drug discovery.

- **[arXiv251208] Are Bus-Mounted Edge Servers Feasible?**
  - **tags:** [sys], [edge computing, vehicular networks], [bus-mounted edge servers, server placement, greedy heuristic algorithm, trace-driven simulation, coverage optimization]
  - **authors:** Xuezhi Li, Jiancong He, Ming Xie, Xuyang Chen, Le Chang, Li Jiang, Gui Gui
  - **institution:** Guangdong University of Technology, Central South University
  - **link:** https://arxiv.org/pdf/2512.05543
  - **Simple LLM Summary:** This paper investigates the feasibility of deploying edge servers on public buses to serve vehicular networks, using real-world datasets from Shanghai. It proposes a mathematical model and a greedy heuristic algorithm to select a limited number of buses to maximize coverage of demand points under capacity and budget constraints. The trace-driven simulation results demonstrate that bus-mounted edge servers are a feasible, beneficial, and valuable approach for handling dynamic user demand in urban areas.

- **[arXiv251208] Compiler-supported reduced precision and AoS-SoA transformations for heterogeneous hardware**
  - **tags:** [sys], [high-performance computing, GPU optimization], [AoS-to-SoA transformation, reduced precision, compiler annotations, GPU offloading, unified memory]
  - **authors:** Pawel K. Radtke, Tobias Weinzierl
  - **institution:** Durham University
  - **link:** https://arxiv.org/pdf/2512.05516
  - **Simple LLM Summary:** This paper introduces compiler annotations to support AoS-to-SoA data layout transformations and reduced precision for particle simulation codes on heterogeneous GPU hardware. It evaluates the performance of these optimizations across different GPU platforms, finding significant speedups on NVIDIA G200 and more robust performance on AMD MI300A. The authors conclude that their compiler-based techniques are broadly applicable to Lagrangian codes and similar workloads.


**cs.AI/cs.LG contains "reinforcement learning" total: 9**
- [arXiv251208] Entropy Ratio Clipping as a Soft Global Constraint for Stable Reinforcement Learning [link](https://arxiv.org/pdf/2512.05591)
- [arXiv251208] Hierarchical Reinforcement Learning for the Dynamic VNE with Alternatives Problem [link](https://arxiv.org/pdf/2512.05207)
- [arXiv251208] Whatever Remains Must Be True: Filtering Drives Reasoning in LLMs, Shaping Diversity [link](https://arxiv.org/pdf/2512.05962)
- [arXiv251208] Variational Quantum Rainbow Deep Q-Network for Optimizing Resource Allocation Problem [link](https://arxiv.org/pdf/2512.05946)
- [arXiv251208] Semore: VLM-guided Enhanced Semantic Motion Representations for Visual Reinforcement Learning [link](https://arxiv.org/pdf/2512.05172)
- [arXiv251208] Bayesian Active Inference for Intelligent UAV Anti-Jamming and Adaptive Trajectory Planning [link](https://arxiv.org/pdf/2512.05711)
- [arXiv251208] Bridging Interpretability and Optimization: Provably Attribution-Weighted Actor-Critic in Reproducing Kernel Hilbert Spaces [link](https://arxiv.org/pdf/2512.05291)
- [arXiv251208] A Fast Anti-Jamming Cognitive Radar Deployment Algorithm Based on Reinforcement Learning [link](https://arxiv.org/pdf/2512.05753)
- [arXiv251208] Enhancing Deep Deterministic Policy Gradients on Continuous Control Tasks with Decoupled Prioritized Experience Replay [link](https://arxiv.org/pdf/2512.05320)

**cs.AI/cs.LG contains "accelerate" total: 9**
- [arXiv251208] Documenting SME Processes with Conversational AI: From Tacit Knowledge to BPMN [link](https://arxiv.org/pdf/2512.05122)
- [arXiv251208] When Forgetting Builds Reliability: LLM Unlearning for Reliable Hardware Code Generation [link](https://arxiv.org/pdf/2512.05341)
- [arXiv251208] Coefficient of Variation Masking: A Volatility-Aware Strategy for EHR Foundation Models [link](https://arxiv.org/pdf/2512.05216)
- [arXiv251208] Trusted AI Agents in the Cloud [link](https://arxiv.org/pdf/2512.05951)
- [arXiv251208] Bootstrapping Fuzzers for Compilers of Low-Resource Language Dialects Using Language Models [link](https://arxiv.org/pdf/2512.05887)
- [arXiv251208] KQ-SVD: Compressing the KV Cache with Provable Guarantees on Attention Fidelity [link](https://arxiv.org/pdf/2512.05916)
- [arXiv251208] To Err Is Human: Systematic Quantification of Errors in Published AI Papers via LLM Analysis [link](https://arxiv.org/pdf/2512.05925)
- [arXiv251208] AI & Human Co-Improvement for Safer Co-Superintelligence [link](https://arxiv.org/pdf/2512.05356)
- [arXiv251208] UniFS: Unified Multi-Contrast MRI Reconstruction via Frequency-Spatial Fusion [link](https://arxiv.org/pdf/2512.05481)
