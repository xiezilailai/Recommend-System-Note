# 20251215-20251221

## 2025-12-15

**cs.DC total: 15**

- **[arXiv251215] Enhanced Pruning for Distributed Closeness Centrality under Multi-Packet Messaging**
  - **tags:** [sys], [distributed network analysis], [multi-packet messaging, distributed pruning, closeness centrality, leader election, decentralized computation]
  - **authors:** Patrick D. Manya, Eugene M. Mbuyi, Gothy T. Ngoie, Jordan F. Masakuna
  - **institution:** University of Kinshasa
  - **link:** https://arxiv.org/pdf/2512.11512
  - **Simple LLM Summary:** This paper enhances a distributed pruning method for closeness centrality by introducing multi-packet messaging to batch data into larger blocks. This approach reduces the number of exchanged messages and improves communication efficiency in large networks, outperforming the original method in message count and computation time.

- **[arXiv251215] An Efficient Approach for Energy Conservation in Cloud Computing Environment**
  - **tags:** [sys], [cloud computing], [task scheduling, resource utilization, energy conservation, virtual machine, fitness value]
  - **authors:** Sohan Kumar Pande, Sanjaya Kumar Panda, Preeti Ranjan Sahu
  - **institution:** Not specified
  - **link:** https://arxiv.org/pdf/2512.10974
  - **Simple LLM Summary:** The paper proposes a multi-criteria energy-efficient task scheduling (MCEETS) algorithm for cloud computing that uses a fitness value based on CPU, disk, I/O utilization, and task processing time to improve resource utilization. The algorithm is shown through simulations to consume less energy than the existing MaxUtil algorithm.

- **[arXiv251215] Seamless Transitions: A Comprehensive Review of Live Migration Technologies**
  - **tags:** [sys], [virtualization], [live migration, container migration, virtual machine migration, migration techniques, migration units, infrastructure characteristics]
  - **authors:** Sima Attar-Khorasani, Lincoln Sherpa, Matthias Lieber, Siavash Ghiasvand
  - **institution:** TUD Dresden University of Technology
  - **link:** https://arxiv.org/pdf/2512.10979
  - **Simple LLM Summary:** This paper provides a comprehensive review of live migration technologies, focusing on container-based and virtual machine-based approaches. It analyzes migration techniques, units, and infrastructure, concluding that the complexity and resource demands can sometimes outweigh the benefits, creating a disparity in adoption and practical challenges.

- **[arXiv251215] An LLVM-Based Optimization Pipeline for SPDZ**
  - **tags:** [sys], [secure multiparty computation], [LLVM, SPDZ, secret sharing, batching, GPU kernels, non-blocking scheduler]
  - **authors:** Tianye Dai, Hammurabi Mendes, Heuichan Lim
  - **institution:** Davidson College
  - **link:** https://arxiv.org/pdf/2512.11112
  - **Simple LLM Summary:** This paper presents an LLVM-based compiler pipeline for the SPDZ MPC protocol, which automatically batches operations and uses a non-blocking runtime scheduler to overlap communication and computation. The system, which can also map operations to GPU kernels, achieved speedups of up to 5.56x in evaluations, demonstrating that leveraging LLVM with protocol-aware scheduling is effective for extracting parallelism without sacrificing usability.

- **[arXiv251215] Evaluation Framework for Centralized and Decentralized Aggregation Algorithm in Federated Systems**
  - **tags:** [mlsys], [others], [hierarchical federated learning, aggregated federated learning, continual federated learning, decentralized aggregation, gossip-based protocols]
  - **authors:** Sumit Chongder
  - **institution:** Maharashtra Institute of Technology - Art, Design and Technology University
  - **link:** https://arxiv.org/pdf/2512.10987
  - **Simple LLM Summary:** This paper compares centralized Hierarchical Federated Learning (HFL) with decentralized Aggregated (AFL) and Continual Federated Learning (CFL) architectures. It evaluates these methods on Fashion MNIST and MNIST datasets and concludes that the decentralized approaches (AFL and CFL) outperform HFL in key metrics like precision, recall, and F1 score.

- **[arXiv251215] Agentic Operator Generation for ML ASICs**
  - **tags:** [mlsys], [GPU kernels], [Triton, ATen kernels, PyTorch OpInfo, large language models, JIT compilation, agentic AI, MTIA]
  - **authors:** Alec M. Hammond, Aram Markosyan, Aman Dontula, Simon Mahns, Zacharias Fisches, Dmitrii Pedchenko, Keyur Muzumdar, Natacha Supper, Mark Saroufim, Joe Isaacson, Laura Wang, Warren Hunt, Kaustubh Gondkar, Roman Levenstein, Gabriel Synnaeve, Richard Li, Jacob Kahn, Ajit Mathews
  - **institution:** Meta
  - **link:** https://arxiv.org/pdf/2512.10977
  - **Simple LLM Summary:** The paper presents TritorX, an agentic AI system that uses large language models to automatically generate and test Triton PyTorch ATen kernels for new hardware accelerators like the MTIA. The system prioritizes broad operator coverage and correctness, successfully generating kernels for 481 unique operators that pass over 20,000 tests, enabling rapid backend development for new platforms.

- **[arXiv251215] Reducing Fragmentation and Starvation in GPU Clusters through Dynamic Multi-Objective Scheduling**
  - **tags:** [mlsys], [cluster infrastructure], [dynamic scheduling, hybrid priority scheduling, predictive backfill, smart batch scheduling, GPU utilization, fragmentation reduction, fairness variance, workload simulation]
  - **authors:** Akhmadillo Mamirov
  - **institution:** The College of Wooster
  - **link:** https://arxiv.org/pdf/2512.10980
  - **Simple LLM Summary:** The paper introduces three dynamic multi-objective schedulers (Hybrid Priority, Predictive Backfill, and Smart Batch) designed to reduce fragmentation and starvation in GPU clusters. Through simulation with 1,000 AI jobs, these schedulers significantly outperform static baselines, achieving up to 78.2% GPU utilization and higher throughput. The results demonstrate that dynamic scheduling strategies can meaningfully improve efficiency in heterogeneous AI clusters.

- **[arXiv251215] Dora: QoE-Aware Hybrid Parallelism for Distributed Edge AI**
  - **tags:** [mlsys], [llm inference], [hybrid parallelism, data parallelism, pipeline parallelism, model partitioning, network scheduling, runtime adaptation, QoE-aware scheduling]
  - **authors:** Jianli Jin, Ziyang Lin, Qianli Dong, Yi Chen, Jayanth Srinivasa, Myungjin Lee, Zhaowei Tan, Fan Lai
  - **institution:** UIUC, Northwestern University, University of California, Riverside, Cisco Research
  - **link:** https://arxiv.org/pdf/2512.10990
  - **Simple LLM Summary:** Dora is a framework that optimizes distributed edge AI training and inference by jointly managing heterogeneous computation and network contention. It uses a heterogeneity-aware model partitioner, a contention-aware network scheduler, and a runtime adapter to meet Quality of Experience (QoE) objectives like latency and energy efficiency. The system achieves faster execution and significant energy savings while maintaining QoE under dynamic runtime conditions.

- **[arXiv251215] Theoretical Foundations of GPU-Native Compilation for Rapid Code Iteration**
  - **tags:** [mlsys], [GPU kernels], [GPU-native compilation, parallel traditional compilation, neural compilation, sequence-to-sequence translation, probabilistic verification, hybrid architecture, in-VRAM iteration]
  - **authors:** Adilet Metinov, Gulida M. Kudakeeva, Gulnara D. Kabaeva
  - **institution:** Institute of Information Technology, Kyrgyz State Technical University named after I. Razzakov
  - **link:** https://arxiv.org/pdf/2512.11200
  - **Simple LLM Summary:** This paper establishes theoretical foundations for GPU-native compilation to eliminate CPU-GPU data transfer bottlenecks in AI code iteration. It proposes three complementary approaches: parallel traditional compilation, neural compilation with probabilistic verification, and hybrid architectures. The analysis concludes these methods can achieve 10-100x speedups in code iteration cycles by keeping compilation and execution entirely in GPU memory.

- **[arXiv251215] RollMux: Phase-Level Multiplexing for Disaggregated RL Post-Training**
  - **tags:** [mlsys], [post-training], [cluster scheduling, disaggregated architecture, co-execution group, two-tier scheduling, conservative stochastic planning, round-robin schedule, warm-start context switching]
  - **authors:** Tianyuan Wu, Lunxi Cao, Yining Wei, Wei Gao, Yuheng Zhao, Dakai An, Shaopan Xiong, Zhiqiang Lv, Ju Huang, Siran Yang, Yinghao Yu, Jiamang Wang, Lin Qu, Wei Wang
  - **institution:** Hong Kong University of Science and Technology, University of Illinois Urbana-Champaign, Alibaba Group
  - **link:** https://arxiv.org/pdf/2512.11306
  - **Simple LLM Summary:** The paper presents RollMux, a cluster scheduling framework that improves efficiency in disaggregated RL post-training by multiplexing jobs across clusters to reclaim dependency bubbles. It introduces a co-execution group abstraction and a two-tier scheduler to orchestrate cross-cluster execution. The evaluation shows RollMux achieves up to 1.84x better cost efficiency over standard disaggregation while maintaining 100% SLO attainment.

- **[arXiv251215] Parallax: Runtime Parallelization for Operator Fallbacks in Heterogeneous Edge Systems**
  - **tags:** [mlsys], [others], [runtime parallelization, branch-aware memory management, adaptive scheduling, DAG partitioning, heterogeneous inference, operator fallback]
  - **authors:** Chong Tang, Hao Dai, Jagmohan Chauhan
  - **institution:** University of Southampton, University College London
  - **link:** https://arxiv.org/pdf/2512.11532
  - **Simple LLM Summary:** Parallax is a framework that accelerates mobile DNN inference by partitioning the computation graph to expose parallelism and using branch-aware memory management with adaptive scheduling. It reduces latency by up to 46% and energy consumption by up to 30% compared to existing frameworks, while controlling memory overhead.

- **[arXiv251215] Stateless Snowflake: A Cloud-Agnostic Distributed ID Generator Using Network-Derived Identity**
  - **tags:** [sys], [distributed systems], [Snowflake algorithm, network-derived identity, private IPv4 address, bit-allocation scheme, stateless microservices, Kubernetes]
  - **authors:** Manideep Reddy Chinthareddy
  - **institution:** Independent researcher (based on email domain and location)
  - **link:** https://arxiv.org/pdf/2512.11643
  - **Simple LLM Summary:** This paper proposes a stateless, cloud-agnostic distributed ID generator that eliminates the need for manual worker IDs by deriving node uniqueness from a container's private IPv4 address. It introduces a modified bit-allocation scheme (1-41-16-6) to preserve monotonicity. The method achieves performance comparable to traditional stateful generators while offering improved scalability in containerized environments.

- **[arXiv251215] FirecREST v2: lessons learned from redesigning an API for scalable HPC resource access**
  - **tags:** [sys], [HPC resource access], [RESTful API, performance testing, proxy-based API, I/O bottlenecks, architectural redesign, authorization]
  - **authors:** Elia Palme, Juan Pablo Dorsch, Ali Khosravi, Giovanni Pizzi, Francesco Pagnamenta, Andrea Ceriani, Eirini Koutsaniti, Rafael Sarmiento, Ivano Bonesana, Alejandro Dabin
  - **institution:** CSCS – Swiss National Supercomputing Centre, PSI Center for Scientific Computing, Theory, and Data
  - **link:** https://arxiv.org/pdf/2512.11634
  - **Simple LLM Summary:** This paper presents FirecREST v2, a redesigned RESTful API for programmatic access to HPC resources, focusing on security and high throughput. The authors detail a systematic performance testing methodology to identify bottlenecks in proxy-based APIs and describe key architectural changes. The main conclusion is that the redesign achieved a ~100x performance improvement over its predecessor, as validated by independent peer review.

- **[arXiv251215] ECCO: Leveraging Cross-Camera Correlations for Efficient Live Video Continuous Learning**
  - **tags:** [mlsys], [others], [continuous learning, video analytics, cross-camera correlation, dynamic grouping, GPU resource allocation, transmission control, frame sampling]
  - **authors:** Yuze He, Ferdi Kossmann, Srinivasan Seshan, Peter Steenkiste
  - **institution:** Carnegie Mellon University, Massachusetts Institute of Technology
  - **link:** https://arxiv.org/pdf/2512.11727
  - **Simple LLM Summary:** ECCO is a video analytics framework that improves resource efficiency for continuous learning by grouping cameras with similar data drift patterns to share retrained models. It dynamically forms camera groups, allocates GPU resources, and controls frame transmission to reduce compute and communication costs. The system achieves higher accuracy or supports more cameras compared to existing baselines.

- **[arXiv251215] Hypergraph based Multi-Party Payment Channel**
  - **tags:** [sys], [blockchain scalability], [payment channel networks, hypergraph, multi-party channels, off-chain scaling, DAG updates]
  - **authors:** Ayush Nainwal, Atharva Kamble, Nitin Awathare
  - **institution:** Indian Institute of Technology, Jodhpur; Indian Institute of Technology, Bombay
  - **link:** https://arxiv.org/pdf/2512.11775
  - **Simple LLM Summary:** The paper introduces Hypergraph-based Multi-Party Payment Channels (H-MPCs), a new off-chain construction that replaces traditional bilateral channels with collectively funded hyperedges to enable leaderless, concurrent payments. This design addresses liquidity fragmentation and channel depletion in existing payment networks. The implementation demonstrates a high transaction success rate of approximately 94%, highlighting the protocol's robustness.


**cs.AI/cs.LG contains "reinforcement learning" total: 16**
- [arXiv251215] Rethinking Expert Trajectory Utilization in LLM Post-training [link](https://arxiv.org/pdf/2512.11470)
- [arXiv251215] In-Context Multi-Objective Optimization [link](https://arxiv.org/pdf/2512.11114)
- [arXiv251215] Motif-2-12.7B-Reasoning: A Practitioner's Guide to RL Training Recipes [link](https://arxiv.org/pdf/2512.11463)
- [arXiv251215] Mitigating the Safety Alignment Tax with Null-Space Constrained Policy Optimization [link](https://arxiv.org/pdf/2512.11391)
- [arXiv251215] DAPO: Design Structure-Aware Pass Ordering in High-Level Synthesis with Graph Contrastive and Reinforcement Learning [link](https://arxiv.org/pdf/2512.11342)
- [arXiv251215] A-LAMP: Agentic LLM-Based Framework for Automated MDP Modeling and Policy Generation [link](https://arxiv.org/pdf/2512.11270)
- [arXiv251215] Multi-Objective Reinforcement Learning for Large-Scale Mixed Traffic Control [link](https://arxiv.org/pdf/2512.11247)
- [arXiv251215] Three methods, one problem: Classical and AI approaches to no-three-in-line [link](https://arxiv.org/pdf/2512.11469)
- [arXiv251215] CORL: Reinforcement Learning of MILP Policies Solved via Branch and Bound [link](https://arxiv.org/pdf/2512.11169)
- [arXiv251215] Towards Trustworthy Multi-Turn LLM Agents via Behavioral Guidance [link](https://arxiv.org/pdf/2512.11421)
- [arXiv251215] Symmetry-Aware Steering of Equivariant Diffusion Policies: Benefits and Limits [link](https://arxiv.org/pdf/2512.11345)
- [arXiv251215] Bandwidth-constrained Variational Message Encoding for Cooperative Multi-agent Reinforcement Learning [link](https://arxiv.org/pdf/2512.11179)
- [arXiv251215] When Actions Teach You to Think: Reasoning-Action Synergy via Reinforcement Learning in Conversational Agents [link](https://arxiv.org/pdf/2512.11277)
- [arXiv251215] DentalGPT: Incentivizing Multimodal Complex Reasoning in Dentistry [link](https://arxiv.org/pdf/2512.11558)
- [arXiv251215] Agile Flight Emerges from Multi-Agent Competitive Racing [link](https://arxiv.org/pdf/2512.11781)
- [arXiv251215] Marti-5: A Mathematical Model of "Self in the World" as a First Step Toward Self-Awareness [link](https://arxiv.org/pdf/2512.10985)

**cs.AI/cs.LG contains "accelerate" total: 6**
- [arXiv251215] A Scalable Multi-GPU Framework for Encrypted Large-Model Inference [link](https://arxiv.org/pdf/2512.11269)
- [arXiv251215] DAPO: Design Structure-Aware Pass Ordering in High-Level Synthesis with Graph Contrastive and Reinforcement Learning [link](https://arxiv.org/pdf/2512.11342)
- [arXiv251215] Refining Graphical Neural Network Predictions Using Flow Matching for Optimal Power Flow with Constraint-Satisfaction Guarantee [link](https://arxiv.org/pdf/2512.11127)
- [arXiv251215] CIP: A Plug-and-Play Causal Prompting Framework for Mitigating Hallucinations under Long-Context Noise [link](https://arxiv.org/pdf/2512.11282)
- [arXiv251215] Deep Learning--Accelerated Multi-Start Large Neighborhood Search for Real-time Freight Bundling [link](https://arxiv.org/pdf/2512.11187)
- [arXiv251215] Gradient Descent as a Perceptron Algorithm: Understanding Dynamics and Implicit Acceleration [link](https://arxiv.org/pdf/2512.11587)

## 2025-12-16

**cs.DC total: 26**

- **[arXiv251216] Strategic Server Deployment under Uncertainty in Mobile Edge Computing**
  - **tags:** [sys], [mobile edge computing], [stochastic bilevel optimization, submodular maximization, greedy algorithm, server placement, server assignment]
  - **authors:** Duc A. Tran, Dung Truong, Duy Le
  - **institution:** University of Massachusetts Boston
  - **link:** https://arxiv.org/pdf/2512.12532
  - **Simple LLM Summary:** The paper formulates the strategic server deployment problem in mobile edge computing as a stochastic bilevel optimization and solves it by approximating the objective with submodular functions, enabling the use of greedy algorithms. Evaluation with real-world data shows the proposed method can outperform alternatives by up to 55%.

- **[arXiv251216] Beyond right or wrong : towards redefining adaptive learning indicators in virtual learning environments**
  - **tags:** [ai], [educational technology], [Systematic Literature Review, adaptive learning, learning indicators, motivation, emotions, physiological responses, brain imaging, prior knowledge]
  - **authors:** Andreia dos Santos Sachete, Alba Valeria de SantAnna de Freitas Loiola, Fabio Diniz Rossi, Jose Valdeni de Lima, Raquel Salcedo Gomes
  - **institution:** Federal Institute Farroupilha, Federal University of Rio Grande do Sul
  - **link:** https://arxiv.org/pdf/2512.12105
  - **Simple LLM Summary:** This paper conducts a Systematic Literature Review to identify learning indicators beyond correctness that can enhance adaptive learning in Virtual Learning Environments. It concludes that factors like motivation, emotions, physiological responses, brain imaging, and prior knowledge are crucial for a more comprehensive assessment. The findings aim to guide developers in creating more effective adaptive learning solutions tailored to student realities.

- **[arXiv251216] BOOST: BOttleneck-Optimized Scalable Training Framework for Low-Rank Large Language Models**
  - **tags:** [mlsys], [llm training], [bottleneck-aware tensor parallelism, online-RMSNorm, linear layer grouping, low-rank activation checkpointing, low-rank bottleneck architectures, 3D parallelism]
  - **authors:** Zhengyang Wang, Ziyue Liu, Ruijie Zhang, Avinash Maurya, Paul Hovland, Bogdan Nicolae, Franck Cappello, Zheng Zhang
  - **institution:** University of California, Santa Barbara, Argonne National Laboratory
  - **link:** https://arxiv.org/pdf/2512.12131
  - **Simple LLM Summary:** The paper proposes BOOST, a training framework for low-rank large language models that introduces Bottleneck-aware Tensor Parallelism and other optimizations to improve scalability. It demonstrates significant speedups over both full-rank baselines and naively parallelized low-rank models by reducing communication overhead and improving GPU utilization.

- **[arXiv251216] A Conflict-Aware Resource Management Framework for the Computing Continuum**
  - **tags:** [mlsys], [cluster infrastructure], [deep reinforcement learning, kubernetes, resource orchestration, conflict resolution, computing continuum]
  - **authors:** Vlad Popescu-Vifor, Ilir Murturi, Praveen Kumar Donta, Schahram Dustdar
  - **institution:** TU Wien, University of Prishtina, Stockholm University, ICREA
  - **link:** https://arxiv.org/pdf/2512.12299
  - **Simple LLM Summary:** The paper proposes a framework for adaptive conflict resolution in resource orchestration for the computing continuum using Deep Reinforcement Learning (DRL). It was prototyped and validated on a Kubernetes-based testbed. The results show the framework achieves efficient resource reallocation and adaptive learning, providing a scalable and resilient solution.

- **[arXiv251216] Near-Zero-Overhead Freshness for Recommendation Systems via Inference-Side Model Updates**
  - **tags:** [mlsys], [cluster infrastructure], [Low-Rank Adaptation (LoRA), dynamic rank adaptation, NUMA-aware scheduling, embedding tables (EMTs), delta-update, parameter synchronization]
  - **authors:** Wenjun Yu, Sitian Chen, Cheng Chen, Amelie Chi Zhou
  - **institution:** Hong Kong Baptist University, ByteDance
  - **link:** https://arxiv.org/pdf/2512.12295
  - **Simple LLM Summary:** This paper introduces LiveUpdate, a system that co-locates Low-Rank Adaptation (LoRA) trainers within inference nodes to perform near-zero-overhead model updates for recommendation systems. It uses dynamic rank adaptation and NUMA-aware resource scheduling to minimize memory overhead and latency impact. The system reduces update costs and improves recommendation accuracy compared to baseline delta-update methods.

- **[arXiv251216] MVP-ORAM: a Wait-free Concurrent ORAM for Confidential BFT Storage**
  - **tags:** [sys], [secure storage], [Oblivious RAM, Byzantine fault tolerance, wait-free concurrency, secret sharing, access pattern hiding]
  - **authors:** Robin Vassantlal, Hasan Heydari, Bernardo Ferreira, Alysson Bessani
  - **institution:** LASIGE, Faculdade de Ciências, Universidade de Lisboa
  - **link:** https://arxiv.org/pdf/2512.12006
  - **Simple LLM Summary:** The paper introduces MVP-ORAM, a wait-free concurrent Oblivious RAM protocol that allows clients to perform independent operations and merge conflicting updates without inter-client coordination. It achieves a weaker, practical notion of obliviousness for skewed workloads and integrates with confidential Byzantine fault-tolerant storage. The prototype demonstrates the ability to process hundreds of 4KB accesses per second in cloud environments.

- **[arXiv251216] HetRL: Efficient Reinforcement Learning for LLMs in Heterogeneous Environments**
  - **tags:** [mlsys], [post-training], [reinforcement learning, heterogeneous environments, scheduling algorithm, multi-level search, successive halving, Proximal Policy Optimization (PPO)]
  - **authors:** Yongjun He, Shuai Zhang, Jiading Gai, Xiyuan Zhang, Boran Han, Bernie Wang, Huzefa Rangwala, George Karypis
  - **institution:** ETH Zurich, Amazon Web Services (AWS)
  - **link:** https://arxiv.org/pdf/2512.12476
  - **Simple LLM Summary:** The paper presents HetRL, a distributed system for efficient reinforcement learning training of large language models in environments with heterogeneous GPUs and networks. It formulates the scheduling as a constrained optimization problem and introduces a novel algorithm using a multi-level search framework and successive halving. The evaluation shows HetRL achieves up to 9.17x higher throughput compared to state-of-the-art systems.

- **[arXiv251216] Evaluating Asynchronous Semantics in Trace-Discovered Resilience Models: A Case Study on the OpenTelemetry Demo**
  - **tags:** [sys], [fault-tolerance], [distributed tracing, Monte Carlo simulation, service dependency graph, chaos engineering, OpenTelemetry]
  - **authors:** Anatoly A. Krasnovsky
  - **institution:** Innopolis University, MB3R Lab
  - **link:** https://arxiv.org/pdf/2512.12314
  - **Simple LLM Summary:** This paper develops a trace-discovered resilience model that builds a service dependency graph from OpenTelemetry traces and uses Monte Carlo simulation to estimate endpoint availability under service failures. The study applies this model to the OpenTelemetry Demo and finds that adding asynchronous semantics for Kafka messaging has a negligible impact on predicted availability. The main conclusion is that for immediate HTTP availability in this case, a simpler connectivity-only model is sufficient, and explicit modeling of asynchronous dependencies is not necessary.

- **[arXiv251216] Reputation-Based Leader Election under Partial Synchrony: Towards a Protocol-Independent Abstraction with Enhanced Guarantees**
  - **tags:** [sys], [distributed consensus], [Sliding Window Leader Election (SWLE), Byzantine Fault Tolerance (BFT), partial synchrony, reputation-based, protocol-independent abstraction, Global Stabilization Time (GST)]
  - **authors:** Xuyang Liu, Zijian Zhang, Zhen Li, Jiahang Sun, Jiamou Liu, Peng Jiang
  - **institution:** Beijing Institute of Technology, The University of Auckland
  - **link:** https://arxiv.org/pdf/2512.12409
  - **Simple LLM Summary:** This paper introduces a protocol-independent abstraction for leader election in partially synchronous Byzantine Fault Tolerant systems and proposes the Sliding Window Leader Election (SWLE) mechanism, which uses reputation scores based on consensus behavior. The authors prove SWLE's correctness and effectiveness, and their experimental deployment shows it significantly outperforms the state-of-the-art in throughput, latency, and Byzantine leader frequency under common faults.

- **[arXiv251216] Accelerating Sparse Matrix-Matrix Multiplication on GPUs with Processing Near HBMs**
  - **tags:** [mlsys], [GPU kernels], [SpGEMM, near-memory processing, hardware-software co-design, hash-based multi-phase, acceleration of indirect memory access (AIA), graph neural networks (GNNs)]
  - **authors:** Shiju Li, Younghoon Min, Hane Yie, Hoshik Kim, Soohong Ahn, Joonseop Sim, Chul-Ho Lee, Jongryool Kim
  - **institution:** SK hynix, Texas State University
  - **link:** https://arxiv.org/pdf/2512.12036
  - **Simple LLM Summary:** This paper introduces a hardware-software co-designed framework for accelerating Sparse General Matrix-Matrix Multiplication (SpGEMM) on GPUs using a novel near-memory processing technique called Acceleration of Indirect Memory Access (AIA). The method employs a hash-based multi-phase approach to optimize irregular memory access patterns. It demonstrates significant performance improvements over state-of-the-art software libraries like cuSPARSE in graph analytics and GNN training workloads.

- **[arXiv251216] Ethical Risk Analysis of L2 Rollups**
  - **tags:** [sys], [blockchain], [ethical risk analysis, layer 2 rollups, governance design, upgrade timing, exit windows, proposer liveness, forced inclusion, data availability]
  - **authors:** Georgy Ishmaev, Emmanuelle Anceaume, Davide Frey, François Taïani
  - **institution:** Univ Rennes, Inria, CNRS, IRISA
  - **link:** https://arxiv.org/pdf/2512.12732
  - **Simple LLM Summary:** The paper adapts Ethical Risk Analysis to Layer 2 rollup architectures, using a role-based taxonomy and empirical data from 129 projects and incident reports. It concludes that ethically problematic risks, such as instant upgrades without exit windows and proposer controls that can freeze withdrawals, are widespread in current designs.

- **[arXiv251216] SPARK: Igniting Communication-Efficient Decentralized Learning via Stage-wise Projected NTK and Accelerated Regularization**
  - **tags:** [mlsys], [others], [decentralized federated learning, neural tangent kernel, random projection, Jacobian compression, stage-wise annealed distillation, Nesterov momentum]
  - **authors:** Li Xia
  - **institution:** Minzu University of China
  - **link:** https://arxiv.org/pdf/2512.12737
  - **Simple LLM Summary:** The paper proposes SPARK, a communication-efficient decentralized federated learning method that compresses Jacobian matrices using random projections and employs stage-wise annealed distillation and Nesterov momentum. It achieves a 98.7% communication reduction while maintaining convergence speed and superior accuracy, enabling practical deployment in bandwidth-limited edge environments.

- **[arXiv251216] Spectral Sentinel: Scalable Byzantine-Robust Decentralized Federated Learning via Sketched Random Matrix Theory on Blockchain**
  - **tags:** [mlsys], [fault-tolerance], [sketched random matrix theory, marchenko-pastur law, frequent directions sketching, byzantine-robust aggregation, decentralized federated learning]
  - **authors:** Animesh Mishra
  - **institution:** Department of Computer Science & Engineering (implied from email domain: snu.edu.in, likely Shiv Nadar University)
  - **link:** https://arxiv.org/pdf/2512.12617
  - **Simple LLM Summary:** The paper proposes Spectral Sentinel, a Byzantine-robust decentralized federated learning framework that detects malicious updates by analyzing the eigenspectra of gradient covariances against the Marchenko-Pastur law, using sketching for scalability. It achieves provably optimal convergence and demonstrates high accuracy in experiments, including deployment on a blockchain network.

- **[arXiv251216] Toward Self-Healing Networks-on-Chip: RL-Driven Routing in 2D Torus Architectures**
  - **tags:** [mlsys], [fault-tolerance], [reinforcement learning, adaptive routing, torus topology, networks-on-chip, packet delivery ratio, fault-adaptive score]
  - **authors:** Mohammad Walid Charrwi, Zaid Hussain
  - **institution:** Kuwait University
  - **link:** https://arxiv.org/pdf/2512.13096
  - **Simple LLM Summary:** This paper proposes a reinforcement learning (RL) method where each router acts as an agent to adaptively route packets in a 2D torus Network-on-Chip (NoC). Compared to a baseline adaptive routing scheme, the RL-based approach achieves significantly higher throughput and maintains better packet delivery under increasing node faults by exploiting path diversity.

- **[arXiv251216] PROSERVE: Unified Multi-Priority Request Scheduling for LLM Serving**
  - **tags:** [mlsys], [llm inference], [request scheduling, service gain maximization, two-tier scheduling, SlideBatching, GoRouting, SLO attainment, multi-priority]
  - **authors:** Weizhe Huang, Tao Peng, Tongxuan Liu, Donghe Jin, Xianzhe Dong, Ke Zhang
  - **institution:** JD.com, USTC
  - **link:** https://arxiv.org/pdf/2512.12928
  - **Simple LLM Summary:** The paper proposes PROSERVE, a two-tier scheduling framework for LLM serving that maximizes overall service gain by jointly optimizing for SLO attainment and client priorities. Its engine-level SlideBatching adapts batch formation, while service-level GoRouting performs gain-aware dispatching across instances. Evaluation shows PROSERVE improves system gain by up to 35% and SLO attainment by up to 52% compared to baselines.

- **[arXiv251216] Fine-Grained Energy Prediction For Parallellized LLM Inference With PIE-P**
  - **tags:** [mlsys], [llm inference], [fine-grained energy prediction, multi-GPU inference, tensor parallelism, pipeline parallelism, data parallelism, inter-GPU communication modeling]
  - **authors:** Anurag Dutt, Young Won Choi, Avirup Sil, Anshul Gandhi, Aruna Balasubramanian, Niranjan Balasubramanian
  - **institution:** Stony Brook University, IBM Research
  - **link:** https://arxiv.org/pdf/2512.12801
  - **Simple LLM Summary:** This paper introduces PIE-P, a framework for fine-grained energy prediction of LLM inference parallelized across multiple GPUs. It addresses challenges like non-deterministic communication and overheads through precise sampling and modeling. The evaluation shows PIE-P provides accurate energy predictions across different parallelism strategies, outperforming existing baselines.

- **[arXiv251216] FlashFuser: Expanding the Scale of Kernel Fusion for Compute-Intensive Operators via Inter-Core Connection**
  - **tags:** [mlsys], [GPU kernels], [kernel fusion, distributed shared memory (DSM), inter-core connection, dataflow analysis, cost modeling, tile selection]
  - **authors:** Ziyu Huang, Yangjie Zhou, Zihan Liu, Xinhao Luo, Yijia Diao, Minyi Guo, Jidong Zhai, Yu Feng, Chen Zhang, Anbang Wu, Jingwen Leng
  - **institution:** Shanghai Jiao Tong University, Shanghai Qi Zhi Institute, National University of Singapore, Tsinghua University
  - **link:** https://arxiv.org/pdf/2512.12949
  - **Simple LLM Summary:** FlashFuser is a compiler framework that leverages the inter-core Distributed Shared Memory (DSM) on modern GPUs to enable large-scale kernel fusion for memory-bound workloads. It introduces a DSM communication abstraction, a dataflow analyzer for distributed memory, and a unified search engine to find optimal execution plans. Evaluations on an NVIDIA H100 show it reduces memory access by 58% and achieves significant speedups over existing libraries and compilers.

- **[arXiv251216] Towards Secure Decentralized Applications and Consensus Protocols in Blockchains (on Selfish Mining, Undercutting Attacks, DAG-Based Blockchains, E-Voting, Cryptocurrency Wallets, Secure-Logging, and CBDC)**
  - **tags:** [sys], [blockchain security], [selfish mining, undercutting attacks, DAG-based blockchains, e-voting, cryptocurrency wallets, secure-logging, CBDC]
  - **authors:** Ivan Homoliak
  - **institution:** Brno University of Technology
  - **link:** https://arxiv.org/pdf/2512.13213
  - **Simple LLM Summary:** This thesis proposes a holistic security reference architecture for blockchains and decentralized applications, analyzing threats across consensus protocols, wallets, e-voting, and logging. It contributes specific methods like a two-factor wallet authentication and a scalable, privacy-preserving boardroom voting protocol. The main conclusion is that securing complex blockchain systems requires integrated approaches across multiple subsystems, as demonstrated by the proposed frameworks for consensus security, voting, and central bank digital currency interoperability.

- **[arXiv251216] Temporal parallelisation of continuous-time maximum-a-posteriori trajectory estimation**
  - **tags:** [ai], [control and estimation], [parallel-in-time, maximum-a-posteriori, stochastic differential equations, Onsager-Machlup, optimal control, parallel associative scan, Kalman-Bucy filter, Rauch-Tung-Striebel smoother]
  - **authors:** Hassan Razavi, Ángel F. García-Fernández, Simo Särkkä
  - **institution:** Aalto University, Universidad Politécnica de Madrid, ELLIS Institute Finland
  - **link:** https://arxiv.org/pdf/2512.13319
  - **Simple LLM Summary:** This paper proposes a parallel-in-time method for computing continuous-time MAP trajectory estimates by reformulating the problem as an optimal control problem based on the Onsager-Machlup functional. The method leverages parallel associative scan algorithms and extends to linear and nonlinear models, including parallel versions of the Kalman-Bucy filter and smoother. GPU experiments demonstrate the framework achieves significant computational speedup while maintaining the accuracy of sequential algorithms.

- **[arXiv251216] SPARS: A Reinforcement Learning-Enabled Simulator for Power Management in HPC Job Scheduling**
  - **tags:** [mlsys], [cluster infrastructure], [reinforcement learning, discrete-event simulation, job scheduling, power management, energy efficiency, EASY Backfilling, First Come First Served]
  - **authors:** Muhammad Alfian Amrizal, Raka Satya Prasasta, Santana Yuda Pradata, Kadek Gemilang Santiyuda, Reza Pulungan, Hiroyuki Takizawa
  - **institution:** Universitas Gadjah Mada, Universitas Ahmad Dahlan, Institut Bisnis dan Teknologi Indonesia, National Taiwan University of Science and Technology, Tohoku University
  - **link:** https://arxiv.org/pdf/2512.13268
  - **Simple LLM Summary:** The paper presents SPARS, a reinforcement learning-enabled simulator that integrates job scheduling and node power state management within a discrete-event framework to optimize energy efficiency in HPC clusters. It supports traditional policies and RL-enhanced variants to dynamically manage node power transitions. The main conclusion is that SPARS provides a lightweight, reproducible, and extensible platform for evaluating power-aware scheduling strategies, enabling better trade-offs between energy savings and performance.

- **[arXiv251216] Design in Tiles: Automating GEMM Deployment on Tile-Based Many-PE Accelerators**
  - **tags:** [mlsys], [GPU kernels], [tile-based architecture, automated deployment, network on chip, collective primitives, scratchpad memory]
  - **authors:** Aofeng Shen, Chi Zhang, Yakup Budanaz, Alexandru Calotoiu, Torsten Hoefler, Luca Benini
  - **institution:** ETH Zurich
  - **link:** https://arxiv.org/pdf/2512.13638
  - **Simple LLM Summary:** The paper proposes "Design in Tiles (DiT)", an automated framework for deploying GEMM on tile-based many-PE accelerators by connecting a deployment toolchain with a configurable executable model. It demonstrates that this approach achieves higher PE utilization than expert-tuned libraries on comparable hardware, resulting in a 1.2–2.0x speedup across diverse matrix shapes.

- **[arXiv251216] SEDULity: A Proof-of-Learning Framework for Distributed and Secure Blockchains with Efficient Useful Work**
  - **tags:** [mlsys], [others], [proof-of-learning, consensus mechanism, incentive mechanism, distributed training, blockchain security]
  - **authors:** Weihang Cao, Mustafa Doger, Sennur Ulukus
  - **institution:** University of Maryland, College Park
  - **link:** https://arxiv.org/pdf/2512.13666
  - **Simple LLM Summary:** The paper proposes SEDULity, a Proof-of-Learning framework that replaces the energy-wasting Proof-of-Work puzzle in blockchains with a useful machine learning training task. It demonstrates that this framework is secure, distributed, and efficiently trains models while incentivizing honest participation through a designed mechanism.

- **[arXiv251216] SIGMA: An AI-Empowered Training Stack on Early-Life Hardware**
  - **tags:** [mlsys], [cluster infrastructure], [early-life AI accelerators, fault tolerance, distributed training, MoE model, training stability, platform-framework separation]
  - **authors:** Lei Qu, Lianhai Ren, Peng Cheng, Rui Gao, Ruizhe Wang, Tianyu Chen, Xiao Liu, Xingjian Zhang, Yeyun Gong, Yifan Xiong, Yucheng Ding, Yuting Jiang, Zhenghao Lin, Zhongxin Guo, Ziyue Yang
  - **institution:** Microsoft Research
  - **link:** https://arxiv.org/pdf/2512.13488
  - **Simple LLM Summary:** SIGMA is an open-source training stack designed for large-scale distributed training on unreliable early-life AI hardware. It introduces a two-layer architecture (LUCIA TRAINING PLATFORM and LUCIA TRAINING FRAMEWORK) to centrally handle hardware reliability and fault mitigation while optimizing for numerical stability and training efficiency. The system demonstrated high reliability and efficiency, successfully training a 200B MoE model with state-of-the-art accuracy, establishing a robust and cost-effective alternative to established accelerator stacks.

- **[arXiv251216] TreeVQA: A Tree-Structured Execution Framework for Shot Reduction in Variational Quantum Algorithms**
  - **tags:** [mlsys], [cluster infrastructure], [variational quantum algorithms, tree-structured execution, shot reduction, quantum circuit execution, VQA wrapper]
  - **authors:** Yuewen Hou, Dhanvi Bharadwaj, Gokul Subramanian Ravi
  - **institution:** University of Michigan
  - **link:** https://arxiv.org/pdf/2512.12068
  - **Simple LLM Summary:** The paper proposes TreeVQA, a tree-structured execution framework that reduces the computational cost of Variational Quantum Algorithms by exploiting similarities across tasks. It begins with joint execution and branches only when quantum executions diverge. Evaluations show significant shot count reductions, averaging 25.9x, with benefits increasing for larger problems.

- **[arXiv251216] Janus: Disaggregating Attention and Experts for Scalable MoE Inference**
  - **tags:** [mlsys], [llm inference], [mixture-of-experts (MoE), disaggregated architecture, two-phase communication, GPU kernel scheduler, fine-grained resource management]
  - **authors:** Zhexiang Zhang, Ye Wang, Xiangyu Wang, Yumiao Zhao, Jingzhe Jiang, Qizhen Weng, Shaohuai Shi, Yin Chen, Minchen Yu
  - **institution:** The Chinese University of Hong Kong, Shenzhen; Institute of Artificial Intelligence (TeleAI), China Telecom; Shenzhen Loop Area Institute; Harbin Institute of Technology, Shenzhen
  - **link:** https://arxiv.org/pdf/2512.13525
  - **Simple LLM Summary:** The paper proposes Janus, a scalable inference system for large Mixture-of-Experts (MoE) models that disaggregates the attention and expert modules onto separate GPU sub-clusters for independent management and scaling. Its key designs include an adaptive two-phase communication scheme, a lightweight GPU-kernel scheduler for expert load balancing, and fine-grained resource management. The evaluation shows Janus achieves up to 3.9x higher per-GPU throughput than state-of-the-art systems while meeting latency requirements.

- **[arXiv251216] astroCAMP: A Community Benchmark and Co-Design Framework for Sustainable SKA-Scale Radio Imaging**
  - **tags:** [sys], [high-performance computing], [benchmarking, co-design, energy efficiency, radio interferometry, Pareto optimization, FPGA, GPU, CPU]
  - **authors:** Denisa-Andreea Constantinescu, Rubén Rodríguez Álvarez, Jacques Morin, Etienne Orliac, Mickaël Dardaillon, Sunrise Wang, Hugo Miomandre, Miguel Peón-Quirós, Jean-François Nezan, David Atienza
  - **institution:** EPFL, Univ Rennes, INSA Rennes, CNRS, Univ Côte d’Azur, OCA
  - **link:** https://arxiv.org/pdf/2512.13591
  - **Simple LLM Summary:** The paper introduces astroCAMP, a framework for hardware-software co-design and benchmarking to improve the computational and energy efficiency of radio astronomy imaging pipelines for the SKA telescope. It provides standardized metrics, datasets, and a multi-objective formulation to explore trade-offs between scientific fidelity and sustainability. The main conclusion is that such a framework is essential for identifying Pareto-optimal system designs that maximize scientific return within the SKA's strict operational and environmental constraints.


**cs.AI/cs.LG contains "reinforcement learning" total: 38**
- [arXiv251216] Reinforcement Learning for Latent-Space Thinking in LLMs [link](https://arxiv.org/pdf/2512.11816)
- [arXiv251216] Mirror Mode in Fire Emblem: Beating Players at their own Game with Imitation and Reinforcement Learning [link](https://arxiv.org/pdf/2512.11902)
- [arXiv251216] WAM-Diff: A Masked Diffusion VLA Framework with MoE and Online Reinforcement Learning for Autonomous Driving [link](https://arxiv.org/pdf/2512.11872)
- [arXiv251216] Policy Gradient Algorithms for Age-of-Information Cost Minimization [link](https://arxiv.org/pdf/2512.11990)
- [arXiv251216] ElasticVR: Elastic Task Computing in Multi-User Multi-Connectivity Wireless Virtual Reality (VR) Systems [link](https://arxiv.org/pdf/2512.12366)
- [arXiv251216] Hierarchical Task Offloading and Trajectory Optimization in Low-Altitude Intelligent Networks Via Auction and Diffusion-based MARL [link](https://arxiv.org/pdf/2512.11862)
- [arXiv251216] A Review of Learning-Based Motion Planning: Toward a Data-Driven Optimal Control Approach [link](https://arxiv.org/pdf/2512.11944)
- [arXiv251216] Learning to Get Up Across Morphologies: Zero-Shot Recovery with a Unified Humanoid Policy [link](https://arxiv.org/pdf/2512.12230)
- [arXiv251216] Evolutionary Reinforcement Learning based AI tutor for Socratic Interdisciplinary Instruction [link](https://arxiv.org/pdf/2512.11930)
- [arXiv251216] Learning to Extract Context for Context-Aware LLM Inference [link](https://arxiv.org/pdf/2512.11986)
- [arXiv251216] Goal Reaching with Eikonal-Constrained Hierarchical Quasimetric Reinforcement Learning [link](https://arxiv.org/pdf/2512.12046)
- [arXiv251216] World Models Unlock Optimal Foraging Strategies in Reinforcement Learning Agents [link](https://arxiv.org/pdf/2512.12548)
- [arXiv251216] Coupled Variational Reinforcement Learning for Language Model General Reasoning [link](https://arxiv.org/pdf/2512.12576)
- [arXiv251216] Reassessing the Role of Supervised Fine-Tuning: An Empirical Study in VLM Reasoning [link](https://arxiv.org/pdf/2512.12690)
- [arXiv251216] Synergizing Code Coverage and Gameplay Intent: Coverage-Aware Game Playtesting with LLM-Guided Reinforcement Learning [link](https://arxiv.org/pdf/2512.12706)
- [arXiv251216] Self-Motivated Growing Neural Network for Adaptive Architecture via Local Structural Plasticity [link](https://arxiv.org/pdf/2512.12713)
- [arXiv251216] Information-Consistent Language Model Recommendations through Group Relative Policy Optimization [link](https://arxiv.org/pdf/2512.12858)
- [arXiv251216] LLM-based Personalized Portfolio Recommender: Integrating Large Language Models and Reinforcement Learning for Intelligent Investment Strategy Optimization [link](https://arxiv.org/pdf/2512.12922)
- [arXiv251216] Tackling Snow-Induced Challenges: Safe Autonomous Lane-Keeping with Robust Reinforcement Learning [link](https://arxiv.org/pdf/2512.12987)
- [arXiv251216] GTR-Turbo: Merged Checkpoint is Secretly a Free Teacher for Agentic VLM Training [link](https://arxiv.org/pdf/2512.13043)
- [arXiv251216] Deep Q-Learning-Based Intelligent Scheduling for ETL Optimization in Heterogeneous Data Environments [link](https://arxiv.org/pdf/2512.13060)
- [arXiv251216] M-GRPO: Stabilizing Self-Supervised Reinforcement Learning for Large Language Models with Momentum-Anchored Policy Optimization [link](https://arxiv.org/pdf/2512.13070)
- [arXiv251216] PvP: Data-Efficient Humanoid Robot Learning with Proprioceptive-Privileged Contrastive Representations [link](https://arxiv.org/pdf/2512.13093)
- [arXiv251216] ADHint: Adaptive Hints with Difficulty Priors for Reinforcement Learning [link](https://arxiv.org/pdf/2512.13095)
- [arXiv251216] TraPO: A Semi-Supervised Reinforcement Learning Framework for Boosting LLM Reasoning [link](https://arxiv.org/pdf/2512.13106)
- [arXiv251216] SpeakRL: Synergizing Reasoning, Speaking, and Acting in Language Models with Reinforcement Learning [link](https://arxiv.org/pdf/2512.13159)
- [arXiv251216] SACn: Soft Actor-Critic with n-step Returns [link](https://arxiv.org/pdf/2512.13165)
- [arXiv251216] Reflective Preference Optimization (RPO): Enhancing On-Policy Alignment via Hint-Guided Reflection [link](https://arxiv.org/pdf/2512.13240)
- [arXiv251216] AutoTool: Dynamic Tool Selection and Integration for Agentic Reasoning [link](https://arxiv.org/pdf/2512.13278)
- [arXiv251216] Intrinsic-Motivation Multi-Robot Social Formation Navigation with Coordinated Exploration [link](https://arxiv.org/pdf/2512.13293)
- [arXiv251216] Control of a Twin Rotor using Twin Delayed Deep Deterministic Policy Gradient (TD3) [link](https://arxiv.org/pdf/2512.13356)
- [arXiv251216] Fast Policy Learning for 6-DOF Position Control of Underwater Vehicles [link](https://arxiv.org/pdf/2512.13359)
- [arXiv251216] Differentiable Evolutionary Reinforcement Learning [link](https://arxiv.org/pdf/2512.13399)
- [arXiv251216] MedCEG: Reinforcing Verifiable Medical Reasoning with Critical Evidence Graph [link](https://arxiv.org/pdf/2512.13510)
- [arXiv251216] Memory in the Age of AI Agents [link](https://arxiv.org/pdf/2512.13564)
- [arXiv251216] Image Diffusion Preview with Consistency Solver [link](https://arxiv.org/pdf/2512.13592)
- [arXiv251216] Nemotron-Cascade: Scaling Cascaded Reinforcement Learning for General-Purpose Reasoning Models [link](https://arxiv.org/pdf/2512.13607)
- [arXiv251216] A Scientific Reasoning Model for Organic Synthesis Procedure Generation [link](https://arxiv.org/pdf/2512.13668)

**cs.AI/cs.LG contains "accelerate" total: 20**
- [arXiv251216] KV Cache Recycling to Expand Usable Context Capacity in Low Parameter LLMs [link](https://arxiv.org/pdf/2512.11851)
- [arXiv251216] Beyond Automation: Rethinking Work, Creativity, and Governance in the Age of Generative AI [link](https://arxiv.org/pdf/2512.11893)
- [arXiv251216] Synthetic Swarm Mosquito Dataset for Acoustic Classification: A Proof of Concept [link](https://arxiv.org/pdf/2512.12365)
- [arXiv251216] Using Socio-economic Indicators, Smart Transit Systems, and Urban Simulator to Accelerate ZEV Adoption and Reduce VMT [link](https://arxiv.org/pdf/2512.11870)
- [arXiv251216] MeltwaterBench: Deep learning for spatiotemporal downscaling of surface meltwater [link](https://arxiv.org/pdf/2512.12142)
- [arXiv251216] CXL-SpecKV: A Disaggregated FPGA Speculative KV-Cache for Datacenter LLM Serving [link](https://arxiv.org/pdf/2512.11920)
- [arXiv251216] Neural CDEs as Correctors for Learned Time Series Models [link](https://arxiv.org/pdf/2512.12116)
- [arXiv251216] AGAPI-Agents: An Open-Access Agentic AI Platform for Accelerated Materials Design on AtomGPT.org [link](https://arxiv.org/pdf/2512.11935)
- [arXiv251216] Skillful Subseasonal-to-Seasonal Forecasting of Extreme Events with a Multi-Sphere Coupled Probabilistic Model [link](https://arxiv.org/pdf/2512.12545)
- [arXiv251216] Torch Geometric Pool: the Pytorch library for pooling in Graph Neural Networks [link](https://arxiv.org/pdf/2512.12642)
- [arXiv251216] Intelligent Scientific Literature Explorer using Machine Learning (ISLE) [link](https://arxiv.org/pdf/2512.12760)
- [arXiv251216] HaShiFlex: A High-Throughput Hardened Shifter DNN Accelerator with Fine-Tuning Flexibility [link](https://arxiv.org/pdf/2512.12847)
- [arXiv251216] Distillation of Discrete Diffusion by Exact Conditional Distribution Matching [link](https://arxiv.org/pdf/2512.12889)
- [arXiv251216] MADTempo: An Interactive System for Multi-Event Temporal Video Retrieval with Query Augmentation [link](https://arxiv.org/pdf/2512.12929)
- [arXiv251216] SeVeDo: A Heterogeneous Transformer Accelerator for Low-Bit Inference via Hierarchical Group Quantization and SVD-Guided Mixed Precision [link](https://arxiv.org/pdf/2512.12930)
- [arXiv251216] Efficient Adaptive Rejection Sampling for Accelerating Speculative Decoding in Large Language Models [link](https://arxiv.org/pdf/2512.13194)
- [arXiv251216] Fast Policy Learning for 6-DOF Position Control of Underwater Vehicles [link](https://arxiv.org/pdf/2512.13359)
- [arXiv251216] Image Diffusion Preview with Consistency Solver [link](https://arxiv.org/pdf/2512.13592)
- [arXiv251216] V-Rex: Real-Time Streaming Video LLM Acceleration via Dynamic KV Cache Retrieval [link](https://arxiv.org/pdf/2512.12284)
- [arXiv251216] Efficient Level-Crossing Probability Calculation for Gaussian Process Modeled Data [link](https://arxiv.org/pdf/2512.12442)

## 2025-12-17

**cs.DC total: 7**

- **[arXiv251217] Real-Time Service Subscription and Adaptive Offloading Control in Vehicular Edge Computing**
  - **tags:** [mlsys], [others], [approximation algorithm, linear program rounding, local-ratio technique, deadline-constrained offloading, resource allocation, VEC simulator]
  - **authors:** Chuanchao Gao, Arvind Easwaran
  - **institution:** Nanyang Technological University
  - **link:** https://arxiv.org/pdf/2512.14002
  - **Simple LLM Summary:** The paper proposes an approximation algorithm called SARound, based on linear program rounding and local-ratio techniques, to solve a deadline-constrained task offloading and resource allocation problem in Vehicular Edge Computing. It also designs an online service subscription and offloading control framework. Experimental results show that SARound outperforms state-of-the-art baselines in maximizing vehicle utility under varying network conditions.

- **[arXiv251217] A Hybrid Reactive-Proactive Auto-scaling Algorithm for SLA-Constrained Edge Computing**
  - **tags:** [mlsys], [cluster infrastructure], [LSTM, Kubernetes, auto-scaling, microservices, SLA compliance]
  - **authors:** Suhrid Gupta, Muhammed Tawfiqul Islam, Rajkumar Buyya
  - **institution:** The University of Melbourne
  - **link:** https://arxiv.org/pdf/2512.14290
  - **Simple LLM Summary:** This paper proposes a hybrid auto-scaling algorithm for edge computing that combines a machine learning-based proactive scaler (using LSTM for demand prediction) with a reactive scaler for immediate adjustments, integrated into Kubernetes. The method significantly reduces SLA violation rates from up to 23% in existing solutions to only 6%, ensuring stable compliance across various applications.

- **[arXiv251217] Performance and Stability of Barrier Mode Parallel Systems with Heterogeneous and Redundant Jobs**
  - **tags:** [mlsys], [cluster infrastructure], [barrier execution mode, parallel systems, stability analysis, performance bounds, Apache Spark, simulation]
  - **authors:** Brenton Walker, Markus Fidler
  - **institution:** Institute of Communications Technology, Leibniz Universität Hannover
  - **link:** https://arxiv.org/pdf/2512.14445
  - **Simple LLM Summary:** This paper analyzes the performance and stability penalties introduced by synchronization barriers in parallel systems, such as Apache Spark's Barrier Execution Mode. It develops models for systems with heterogeneous and redundant jobs, deriving performance bounds and validating them through simulation against real benchmark data. The main conclusion is that barriers cause worker idle time, reducing system stability and performance, and the overhead is attributed to the dual event and polling-driven scheduling mechanism.

- **[arXiv251217] PruneX: A Hierarchical Communication-Efficient System for Distributed CNN Training with Structured Pruning**
  - **tags:** [mlsys], [cluster infrastructure], [structured pruning, ADMM, hierarchical communication, gradient compression, collective primitives]
  - **authors:** Alireza Olama, Andreas Lundell, Izzat El Hajj, Johan Lilius, Jerker Björkqvist
  - **institution:** Åbo Akademi University, American University of Beirut, CSC - IT Center for Science
  - **link:** https://arxiv.org/pdf/2512.14628
  - **Simple LLM Summary:** This paper introduces PruneX, a distributed training system that co-designs structured pruning algorithms with cluster hierarchy to reduce inter-node communication. Its core method, Hierarchical Structured ADMM, enforces node-level sparsity to enable efficient gradient synchronization. The system significantly reduces communication volume and achieves superior scaling performance compared to dense baselines and gradient compression techniques.

- **[arXiv251217] Improving Slow Transfer Predictions: Generative Methods Compared**
  - **tags:** [mlsys], [others], [class imbalance, data augmentation, oversampling, SMOTE, CTGAN, stratified sampling]
  - **authors:** Jacob Taegon Kim, Alex Sim, Kesheng Wu, Jinoh Kim
  - **institution:** University of California, Berkeley, Lawrence Berkeley National Laboratory, Texas A&M University
  - **link:** https://arxiv.org/pdf/2512.14522
  - **Simple LLM Summary:** This paper compares data augmentation strategies, including traditional oversampling and generative methods like CTGAN, to address class imbalance for improving machine learning predictions of slow data transfers in scientific networks. It finds that as the imbalance ratio increases, augmentation does not significantly improve performance. The main conclusion is that even advanced generative techniques do not outperform simple stratified sampling for this task.

- **[arXiv251217] Cornserve: Efficiently Serving Any-to-Any Multimodal Models**
  - **tags:** [mlsys], [multi-modal inference], [computation graph, model disaggregation, distributed runtime, planner, Any-to-Any models]
  - **authors:** Jeff J. Ma, Jae-Won Chung, Jisang Ahn, Yizhuo Liang, Akshay Jajoo, Myungjin Lee, Mosharaf Chowdhury
  - **institution:** University of Michigan, University of Southern California, Cisco Research
  - **link:** https://arxiv.org/pdf/2512.14098
  - **Simple LLM Summary:** The paper introduces Cornserve, a serving system for Any-to-Any multimodal models. It uses a planner to automatically generate optimized deployment plans by disaggregating models based on characteristics, and a distributed runtime to execute them. Evaluations show Cornserve significantly improves throughput and reduces latency compared to existing solutions.

- **[arXiv251217] Q-IRIS: The Evolution of the IRIS Task-Based Runtime to Enable Classical-Quantum Workflows**
  - **tags:** [sys], [quantum-classical hybrid runtime], [task-based runtime, quantum intermediate representation (QIR), quantum circuit cutting, heterogeneous scheduling, XACC, IRIS]
  - **authors:** Narasinga Rao Miniskar, Mohammad Alaul Haque Monil, Elaine Wong, Vicente Leyton-Ortega, Jeffrey S. Vetter, Seth R. Johnson, Travis S. Humble
  - **institution:** Oak Ridge National Laboratory
  - **link:** https://arxiv.org/pdf/2512.13931
  - **Simple LLM Summary:** This paper presents Q-IRIS, a proof-of-concept hybrid execution framework that integrates the IRIS task-based runtime with the XACC quantum programming framework via QIR-EE to orchestrate classical and quantum workloads across heterogeneous backends. It demonstrates the framework's capability through the asynchronous scheduling of quantum tasks and uses quantum circuit cutting to illustrate how task granularity can improve simulator throughput. The authors conclude by outlining key scaling challenges for hybrid runtimes, including coordinated scheduling and management of classical-quantum interactions.


**cs.AI/cs.LG contains "reinforcement learning" total: 18**
- [arXiv251217] Model-Based Reinforcement Learning in Discrete-Action Non-Markovian Reward Decision Processes [link](https://arxiv.org/pdf/2512.14617)
- [arXiv251217] Explainable reinforcement learning from human feedback to improve alignment [link](https://arxiv.org/pdf/2512.13837)
- [arXiv251217] A data-physics hybrid generative model for patient-specific post-stroke motor rehabilitation using wearable sensor data [link](https://arxiv.org/pdf/2512.14329)
- [arXiv251217] RAST-MoE-RL: A Regime-Aware Spatio-Temporal MoE Framework for Deep Reinforcement Learning in Ride-Hailing [link](https://arxiv.org/pdf/2512.13727)
- [arXiv251217] RADAR: Accelerating Large Language Model Inference With RL-Based Dynamic Draft Trees [link](https://arxiv.org/pdf/2512.14069)
- [arXiv251217] A First-Order Logic-Based Alternative to Reward Models in RLHF [link](https://arxiv.org/pdf/2512.14100)
- [arXiv251217] OmniDrive-R1: Reinforcement-driven Interleaved Multi-modal Chain-of-Thought for Trustworthy Vision-Language Autonomous Driving [link](https://arxiv.org/pdf/2512.14044)
- [arXiv251217] Group-Theoretic Reinforcement Learning of Dynamical Decoupling Sequences [link](https://arxiv.org/pdf/2512.13890)
- [arXiv251217] Time-Constrained Recommendations: Reinforcement Learning Strategies for E-Commerce [link](https://arxiv.org/pdf/2512.13726)
- [arXiv251217] Meta Hierarchical Reinforcement Learning for Scalable Resource Management in O-RAN [link](https://arxiv.org/pdf/2512.13715)
- [arXiv251217] Understanding and Improving Hyperbolic Deep Reinforcement Learning [link](https://arxiv.org/pdf/2512.14202)
- [arXiv251217] Adaptive digital twins for predictive decision-making: Online Bayesian learning of transition dynamics [link](https://arxiv.org/pdf/2512.13919)
- [arXiv251217] Incentivizing Tool-augmented Thinking with Images for Medical Image Analysis [link](https://arxiv.org/pdf/2512.14157)
- [arXiv251217] A Threshold-Triggered Deep Q-Network-Based Framework for Self-Healing in Autonomic Software-Defined IIoT-Edge Networks [link](https://arxiv.org/pdf/2512.14297)
- [arXiv251217] Sample-Efficient Robot Skill Learning for Construction Tasks: Benchmarking Hierarchical Reinforcement Learning and Vision-Language-Action VLA Model [link](https://arxiv.org/pdf/2512.14031)
- [arXiv251217] TimeLens: Rethinking Video Temporal Grounding with Multimodal LLMs [link](https://arxiv.org/pdf/2512.14698)
- [arXiv251217] AI-Powered Annotation Pipelines for Stabilizing Large Language Models: A Human-AI Synergy Approach [link](https://arxiv.org/pdf/2512.13714)
- [arXiv251217] Context-Picker: Dynamic context selection using multi-stage reinforcement learning [link](https://arxiv.org/pdf/2512.14465)

**cs.AI/cs.LG contains "accelerate" total: 9**
- [arXiv251217] AnySleep: a channel-agnostic deep learning system for high-resolution sleep staging in multi-center cohorts [link](https://arxiv.org/pdf/2512.14461)
- [arXiv251217] OPTIMA: Optimal One-shot Pruning for LLMs via Quadratic Programming Reconstruction [link](https://arxiv.org/pdf/2512.13886)
- [arXiv251217] ProtoFlow: Interpretable and Robust Surgical Workflow Modeling with Learned Dynamic Scene Graph Prototypes [link](https://arxiv.org/pdf/2512.14092)
- [arXiv251217] RADAR: Accelerating Large Language Model Inference With RL-Based Dynamic Draft Trees [link](https://arxiv.org/pdf/2512.14069)
- [arXiv251217] SuperWing: a comprehensive transonic wing dataset for data-driven aerodynamic design [link](https://arxiv.org/pdf/2512.14397)
- [arXiv251217] Hierarchical Multi-agent Large Language Model Reasoning for Autonomous Functional Materials Discovery [link](https://arxiv.org/pdf/2512.13930)
- [arXiv251217] Evaluating Frontier LLMs on PhD-Level Mathematical Reasoning: A Benchmark on a Textbook in Theoretical Computer Science about Randomized Algorithms [link](https://arxiv.org/pdf/2512.13978)
- [arXiv251217] Informing Acquisition Functions via Foundation Models for Molecular Discovery [link](https://arxiv.org/pdf/2512.13935)
- [arXiv251217] Leveraging LLMs for Structured Data Extraction from Unstructured Patient Records [link](https://arxiv.org/pdf/2512.13700)

## 2025-12-18

**cs.DC total: 7**

- **[arXiv251218] Optimizing Sensor Node Localization for Achieving Sustainable Smart Agriculture System Connectivity**
  - **tags:** [sys], [wireless sensor networks], [Gradient-Based Iteration, Lagrange, grid-based allocation, Bluetooth, particle swarm distribution, FAHP, clustering]
  - **authors:** Mohamed Naeem
  - **institution:** Arab Academy for Science, Technology and Maritime Transport
  - **link:** https://arxiv.org/pdf/2512.14971
  - **Simple LLM Summary:** This paper proposes a sensor allocation optimization method using Gradient-Based Iteration with Lagrange to enhance coverage in smart agriculture. The method minimizes the number of sensor nodes in a grid-based deployment and extends coverage with Bluetooth. It outperforms classic deterministic and particle swarm distributions, achieving 98.5% wireless sensor coverage.

- **[arXiv251218] LeaseGuard: Raft Leases Done Right**
  - **tags:** [sys], [distributed systems], [Raft, leader leases, consensus algorithm, TLA+, availability, quorum checks]
  - **authors:** A. Jesse Jiryu Davis, Murat Demirbas, Lingzhi Deng
  - **institution:** MongoDB
  - **link:** https://arxiv.org/pdf/2512.15659
  - **Simple LLM Summary:** The paper introduces LeaseGuard, a novel leader lease algorithm for the Raft consensus protocol designed to provide consistent reads without the overhead of quorum checks. It leverages specific Raft election guarantees and includes optimizations to maximize read and write availability during leader failover. The evaluation shows that LeaseGuard reduces read latency to zero network roundtrips and significantly improves write throughput compared to traditional mechanisms.

- **[arXiv251218] Optimizing Bloom Filters for Modern GPU Architectures**
  - **tags:** [sys], [GPU-accelerated data structures], [Bloom filter, CUDA, vectorization, thread cooperation, compute latency, cache optimization]
  - **authors:** Daniel Jünger, Kevin Kristensen, Yunsong Wang, Xiangyao Yu, Bertil Schmidt
  - **institution:** NVIDIA Corporation, University of Wisconsin-Madison, Johannes Gutenberg University Mainz
  - **link:** https://arxiv.org/pdf/2512.15595
  - **Simple LLM Summary:** This paper explores the optimization of Bloom filters for modern GPU architectures by focusing on vectorization, thread cooperation, and compute latency. The optimized design achieves high throughput while maintaining accuracy, outperforming the state-of-the-art by up to 15.4x in construction and 11.35x in lookup operations.

- **[arXiv251218] Privacy-Preserving Feature Valuation in Vertical Federated Learning Using Shapley-CMI and PSI Permutation**
  - **tags:** [mlsys], [others], [Shapley-CMI, Private Set Intersection (PSI), Vertical Federated Learning (VFL), Conditional Mutual Information, feature valuation]
  - **authors:** Unai Laskurain, Aitor Aguirre-Ortuzar, Urko Zurutuza
  - **institution:** Mondragon Unibertsitatea
  - **link:** https://arxiv.org/pdf/2512.14767
  - **Simple LLM Summary:** This paper proposes a privacy-preserving system for evaluating feature contributions in Vertical Federated Learning using the Shapley-CMI method. It introduces a PSI server to securely compute encrypted intersection sizes for feature permutations without sharing raw data. The initial experiments confirm the system's correctness and privacy, enabling secure and fair data valuation before model training.

- **[arXiv251218] Dynamic Rebatching for Efficient Early-Exit Inference with DREX**
  - **tags:** [mlsys], [llm inference], [early-exit, dynamic rebatching, copy-free buffer, SLA-aware scheduler, KV cache, state-copying]
  - **authors:** Xuting Liu, Daniel Alexander, Siva Kesava Reddy Kakarla, Behnaz Arzani, Vincent Liu
  - **institution:** University of Pennsylvania, Microsoft Research
  - **link:** https://arxiv.org/pdf/2512.15705
  - **Simple LLM Summary:** The paper proposes DREX, an inference system that uses Dynamic Rebatching to reorganize requests at each early-exit point, allowing tokens to exit individually without degrading quality. It introduces optimizations like a copy-free rebatching buffer and an analytical scheduler to predict rebatching profitability. The evaluation shows DREX improves throughput by 2-12% while eliminating involuntary exits, preserving the intended output quality of the early-exit model.

- **[arXiv251218] LLMQ: Efficient Lower-Precision Pretraining for Consumer GPUs**
  - **tags:** [mlsys], [llm training], [8-bit training, activation checkpointing, offloading, copy-engine collectives, dynamic tensor-level scaling, ZeRO-1]
  - **authors:** Erik Schultheis, Dan Alistarh
  - **institution:** IST Austria
  - **link:** https://arxiv.org/pdf/2512.15306
  - **Simple LLM Summary:** The paper presents LLMQ, a CUDA/C++ framework that enables efficient 8-bit pretraining and fine-tuning of medium-sized language models (3B to 32B parameters) on consumer-grade GPUs. It achieves this through optimizations like activation checkpointing, offloading, and specialized collectives to overcome memory and communication bottlenecks. The system's efficiency rivals production-scale setups, making high-quality LLM training feasible on affordable local hardware like a single 16GB GPU or a workstation with four RTX 4090s.

- **[arXiv251218] Reexamining Paradigms of End-to-End Data Movement**
  - **tags:** [sys], [high-performance data transfer], [WAN performance prediction, hardware-software co-design, latency emulation, TCP congestion control, edge-to-core data movement]
  - **authors:** Chin Fang, Timothy Stitt, Michael J. McManus, Toshio Moriya
  - **institution:** Not explicitly provided in the given text.
  - **link:** https://arxiv.org/pdf/2512.15028
  - **Simple LLM Summary:** This paper reexamines paradigms of end-to-end data movement by investigating bottlenecks beyond raw network bandwidth, including host-side factors like CPU performance. It validates findings using a latency-emulation testbed and production measurements from edge environments to a 100 Gbps international link. The main conclusion is that a holistic hardware-software co-design is essential for consistent performance across diverse environments, closing the gap between benchmarks and production.


**cs.AI/cs.LG contains "reinforcement learning" total: 17**
- [arXiv251218] Beyond Fast and Slow: Cognitive-Inspired Elastic Reasoning for Large Language Models [link](https://arxiv.org/pdf/2512.15089)
- [arXiv251218] Graph Contextual Reinforcement Learning for Efficient Directed Controller Synthesis [link](https://arxiv.org/pdf/2512.15295)
- [arXiv251218] Spectral Representation-based Reinforcement Learning [link](https://arxiv.org/pdf/2512.15036)
- [arXiv251218] Entropy-Reservoir Bregman Projection: An Information-Geometric Unification of Model Collapse [link](https://arxiv.org/pdf/2512.14879)
- [arXiv251218] EUBRL: Epistemic Uncertainty Directed Bayesian Reinforcement Learning [link](https://arxiv.org/pdf/2512.15405)
- [arXiv251218] FM-EAC: Feature Model-based Enhanced Actor-Critic for Multi-Task Control in Dynamic Environments [link](https://arxiv.org/pdf/2512.15430)
- [arXiv251218] Automatic Reward Shaping from Multi-Objective Human Heuristics [link](https://arxiv.org/pdf/2512.15120)
- [arXiv251218] Can LLMs Guide Their Own Exploration? Gradient-Guided Reinforcement Learning for LLM Reasoning [link](https://arxiv.org/pdf/2512.15687)
- [arXiv251218] Double Horizon Model-Based Policy Optimization [link](https://arxiv.org/pdf/2512.15439)
- [arXiv251218] QoS-Aware Hierarchical Reinforcement Learning for Joint Link Selection and Trajectory Optimization in SAGIN-Supported UAV Mobility Management [link](https://arxiv.org/pdf/2512.15119)
- [arXiv251218] Adaptive Partitioning and Learning for Stochastic Control of Diffusion Processes [link](https://arxiv.org/pdf/2512.14991)
- [arXiv251218] Autonomous Pressure Control in MuVacAS via Deep Reinforcement Learning and Deep Learning Surrogate Models [link](https://arxiv.org/pdf/2512.15521)
- [arXiv251218] Well Begun, Half Done: Reinforcement Learning with Prefix Optimization for LLM Reasoning [link](https://arxiv.org/pdf/2512.15274)
- [arXiv251218] Stepwise Think-Critique: A Unified Framework for Robust and Interpretable LLM Reasoning [link](https://arxiv.org/pdf/2512.15662)
- [arXiv251218] Autoregressive Language Models are Secretly Energy-Based Models: Insights into the Lookahead Capabilities of Next-Token Prediction [link](https://arxiv.org/pdf/2512.15605)
- [arXiv251218] Quantum Decision Transformers (QDT): Synergistic Entanglement and Interference for Offline Reinforcement Learning [link](https://arxiv.org/pdf/2512.14726)
- [arXiv251218] A Bayesian latent class reinforcement learning framework to capture adaptive, feedback-driven travel behaviour [link](https://arxiv.org/pdf/2512.14713)

**cs.AI/cs.LG contains "accelerate" total: 8**
- [arXiv251218] PIP$^2$ Net: Physics-informed Partition Penalty Deep Operator Network [link](https://arxiv.org/pdf/2512.15086)
- [arXiv251218] How Does Fourier Analysis Network Work? A Mechanism Analysis and a New Dual-Activation Layer Proposal [link](https://arxiv.org/pdf/2512.14873)
- [arXiv251218] Restless Multi-Process Multi-Armed Bandits with Applications to Self-Driving Microscopies [link](https://arxiv.org/pdf/2512.14930)
- [arXiv251218] Accelerating High-Throughput Catalyst Screening by Direct Generation of Equilibrium Adsorption Structures [link](https://arxiv.org/pdf/2512.15228)
- [arXiv251218] A Roadmap for Applying Graph Neural Networks to Numerical Data: Insights from Cementitious Materials [link](https://arxiv.org/pdf/2512.14855)
- [arXiv251218] Autonomous Pressure Control in MuVacAS via Deep Reinforcement Learning and Deep Learning Surrogate Models [link](https://arxiv.org/pdf/2512.15521)
- [arXiv251218] Nemotron-Math: Efficient Long-Context Distillation of Mathematical Reasoning from Multi-Mode Supervision [link](https://arxiv.org/pdf/2512.15489)
- [arXiv251218] Photonics-Enhanced Graph Convolutional Networks [link](https://arxiv.org/pdf/2512.15549)
