# 20251215-20251221

## 2025-12-15

**cs.DC total: 15**

- **[arXiv251215] Enhanced Pruning for Distributed Closeness Centrality under Multi-Packet Messaging**
  - **tags:** [sys], [distributed network analysis], [multi-packet messaging, distributed pruning, closeness centrality, leader election, decentralized computation]
  - **authors:** Patrick D. Manya, Eugene M. Mbuyi, Gothy T. Ngoie, Jordan F. Masakuna
  - **institution:** University of Kinshasa
  - **link:** https://arxiv.org/pdf/2512.11512
  - **Simple LLM Summary:** This paper enhances a distributed pruning method for closeness centrality by introducing multi-packet messaging to batch data into larger blocks. This approach reduces the number of exchanged messages and improves communication efficiency in large networks, outperforming the original method in message count and computation time.

- **[arXiv251215] An Efficient Approach for Energy Conservation in Cloud Computing Environment**
  - **tags:** [sys], [cloud computing], [task scheduling, resource utilization, energy conservation, virtual machine, fitness value]
  - **authors:** Sohan Kumar Pande, Sanjaya Kumar Panda, Preeti Ranjan Sahu
  - **institution:** Not specified
  - **link:** https://arxiv.org/pdf/2512.10974
  - **Simple LLM Summary:** The paper proposes a multi-criteria energy-efficient task scheduling (MCEETS) algorithm for cloud computing that uses a fitness value based on CPU, disk, I/O utilization, and task processing time to improve resource utilization. The algorithm is shown through simulations to consume less energy than the existing MaxUtil algorithm.

- **[arXiv251215] Seamless Transitions: A Comprehensive Review of Live Migration Technologies**
  - **tags:** [sys], [virtualization], [live migration, container migration, virtual machine migration, migration techniques, migration units, infrastructure characteristics]
  - **authors:** Sima Attar-Khorasani, Lincoln Sherpa, Matthias Lieber, Siavash Ghiasvand
  - **institution:** TUD Dresden University of Technology
  - **link:** https://arxiv.org/pdf/2512.10979
  - **Simple LLM Summary:** This paper provides a comprehensive review of live migration technologies, focusing on container-based and virtual machine-based approaches. It analyzes migration techniques, units, and infrastructure, concluding that the complexity and resource demands can sometimes outweigh the benefits, creating a disparity in adoption and practical challenges.

- **[arXiv251215] An LLVM-Based Optimization Pipeline for SPDZ**
  - **tags:** [sys], [secure multiparty computation], [LLVM, SPDZ, secret sharing, batching, GPU kernels, non-blocking scheduler]
  - **authors:** Tianye Dai, Hammurabi Mendes, Heuichan Lim
  - **institution:** Davidson College
  - **link:** https://arxiv.org/pdf/2512.11112
  - **Simple LLM Summary:** This paper presents an LLVM-based compiler pipeline for the SPDZ MPC protocol, which automatically batches operations and uses a non-blocking runtime scheduler to overlap communication and computation. The system, which can also map operations to GPU kernels, achieved speedups of up to 5.56x in evaluations, demonstrating that leveraging LLVM with protocol-aware scheduling is effective for extracting parallelism without sacrificing usability.

- **[arXiv251215] Evaluation Framework for Centralized and Decentralized Aggregation Algorithm in Federated Systems**
  - **tags:** [mlsys], [others], [hierarchical federated learning, aggregated federated learning, continual federated learning, decentralized aggregation, gossip-based protocols]
  - **authors:** Sumit Chongder
  - **institution:** Maharashtra Institute of Technology - Art, Design and Technology University
  - **link:** https://arxiv.org/pdf/2512.10987
  - **Simple LLM Summary:** This paper compares centralized Hierarchical Federated Learning (HFL) with decentralized Aggregated (AFL) and Continual Federated Learning (CFL) architectures. It evaluates these methods on Fashion MNIST and MNIST datasets and concludes that the decentralized approaches (AFL and CFL) outperform HFL in key metrics like precision, recall, and F1 score.

- **[arXiv251215] Agentic Operator Generation for ML ASICs**
  - **tags:** [mlsys], [GPU kernels], [Triton, ATen kernels, PyTorch OpInfo, large language models, JIT compilation, agentic AI, MTIA]
  - **authors:** Alec M. Hammond, Aram Markosyan, Aman Dontula, Simon Mahns, Zacharias Fisches, Dmitrii Pedchenko, Keyur Muzumdar, Natacha Supper, Mark Saroufim, Joe Isaacson, Laura Wang, Warren Hunt, Kaustubh Gondkar, Roman Levenstein, Gabriel Synnaeve, Richard Li, Jacob Kahn, Ajit Mathews
  - **institution:** Meta
  - **link:** https://arxiv.org/pdf/2512.10977
  - **Simple LLM Summary:** The paper presents TritorX, an agentic AI system that uses large language models to automatically generate and test Triton PyTorch ATen kernels for new hardware accelerators like the MTIA. The system prioritizes broad operator coverage and correctness, successfully generating kernels for 481 unique operators that pass over 20,000 tests, enabling rapid backend development for new platforms.

- **[arXiv251215] Reducing Fragmentation and Starvation in GPU Clusters through Dynamic Multi-Objective Scheduling**
  - **tags:** [mlsys], [cluster infrastructure], [dynamic scheduling, hybrid priority scheduling, predictive backfill, smart batch scheduling, GPU utilization, fragmentation reduction, fairness variance, workload simulation]
  - **authors:** Akhmadillo Mamirov
  - **institution:** The College of Wooster
  - **link:** https://arxiv.org/pdf/2512.10980
  - **Simple LLM Summary:** The paper introduces three dynamic multi-objective schedulers (Hybrid Priority, Predictive Backfill, and Smart Batch) designed to reduce fragmentation and starvation in GPU clusters. Through simulation with 1,000 AI jobs, these schedulers significantly outperform static baselines, achieving up to 78.2% GPU utilization and higher throughput. The results demonstrate that dynamic scheduling strategies can meaningfully improve efficiency in heterogeneous AI clusters.

- **[arXiv251215] Dora: QoE-Aware Hybrid Parallelism for Distributed Edge AI**
  - **tags:** [mlsys], [llm inference], [hybrid parallelism, data parallelism, pipeline parallelism, model partitioning, network scheduling, runtime adaptation, QoE-aware scheduling]
  - **authors:** Jianli Jin, Ziyang Lin, Qianli Dong, Yi Chen, Jayanth Srinivasa, Myungjin Lee, Zhaowei Tan, Fan Lai
  - **institution:** UIUC, Northwestern University, University of California, Riverside, Cisco Research
  - **link:** https://arxiv.org/pdf/2512.10990
  - **Simple LLM Summary:** Dora is a framework that optimizes distributed edge AI training and inference by jointly managing heterogeneous computation and network contention. It uses a heterogeneity-aware model partitioner, a contention-aware network scheduler, and a runtime adapter to meet Quality of Experience (QoE) objectives like latency and energy efficiency. The system achieves faster execution and significant energy savings while maintaining QoE under dynamic runtime conditions.

- **[arXiv251215] Theoretical Foundations of GPU-Native Compilation for Rapid Code Iteration**
  - **tags:** [mlsys], [GPU kernels], [GPU-native compilation, parallel traditional compilation, neural compilation, sequence-to-sequence translation, probabilistic verification, hybrid architecture, in-VRAM iteration]
  - **authors:** Adilet Metinov, Gulida M. Kudakeeva, Gulnara D. Kabaeva
  - **institution:** Institute of Information Technology, Kyrgyz State Technical University named after I. Razzakov
  - **link:** https://arxiv.org/pdf/2512.11200
  - **Simple LLM Summary:** This paper establishes theoretical foundations for GPU-native compilation to eliminate CPU-GPU data transfer bottlenecks in AI code iteration. It proposes three complementary approaches: parallel traditional compilation, neural compilation with probabilistic verification, and hybrid architectures. The analysis concludes these methods can achieve 10-100x speedups in code iteration cycles by keeping compilation and execution entirely in GPU memory.

- **[arXiv251215] RollMux: Phase-Level Multiplexing for Disaggregated RL Post-Training**
  - **tags:** [mlsys], [post-training], [cluster scheduling, disaggregated architecture, co-execution group, two-tier scheduling, conservative stochastic planning, round-robin schedule, warm-start context switching]
  - **authors:** Tianyuan Wu, Lunxi Cao, Yining Wei, Wei Gao, Yuheng Zhao, Dakai An, Shaopan Xiong, Zhiqiang Lv, Ju Huang, Siran Yang, Yinghao Yu, Jiamang Wang, Lin Qu, Wei Wang
  - **institution:** Hong Kong University of Science and Technology, University of Illinois Urbana-Champaign, Alibaba Group
  - **link:** https://arxiv.org/pdf/2512.11306
  - **Simple LLM Summary:** The paper presents RollMux, a cluster scheduling framework that improves efficiency in disaggregated RL post-training by multiplexing jobs across clusters to reclaim dependency bubbles. It introduces a co-execution group abstraction and a two-tier scheduler to orchestrate cross-cluster execution. The evaluation shows RollMux achieves up to 1.84x better cost efficiency over standard disaggregation while maintaining 100% SLO attainment.

- **[arXiv251215] Parallax: Runtime Parallelization for Operator Fallbacks in Heterogeneous Edge Systems**
  - **tags:** [mlsys], [others], [runtime parallelization, branch-aware memory management, adaptive scheduling, DAG partitioning, heterogeneous inference, operator fallback]
  - **authors:** Chong Tang, Hao Dai, Jagmohan Chauhan
  - **institution:** University of Southampton, University College London
  - **link:** https://arxiv.org/pdf/2512.11532
  - **Simple LLM Summary:** Parallax is a framework that accelerates mobile DNN inference by partitioning the computation graph to expose parallelism and using branch-aware memory management with adaptive scheduling. It reduces latency by up to 46% and energy consumption by up to 30% compared to existing frameworks, while controlling memory overhead.

- **[arXiv251215] Stateless Snowflake: A Cloud-Agnostic Distributed ID Generator Using Network-Derived Identity**
  - **tags:** [sys], [distributed systems], [Snowflake algorithm, network-derived identity, private IPv4 address, bit-allocation scheme, stateless microservices, Kubernetes]
  - **authors:** Manideep Reddy Chinthareddy
  - **institution:** Independent researcher (based on email domain and location)
  - **link:** https://arxiv.org/pdf/2512.11643
  - **Simple LLM Summary:** This paper proposes a stateless, cloud-agnostic distributed ID generator that eliminates the need for manual worker IDs by deriving node uniqueness from a container's private IPv4 address. It introduces a modified bit-allocation scheme (1-41-16-6) to preserve monotonicity. The method achieves performance comparable to traditional stateful generators while offering improved scalability in containerized environments.

- **[arXiv251215] FirecREST v2: lessons learned from redesigning an API for scalable HPC resource access**
  - **tags:** [sys], [HPC resource access], [RESTful API, performance testing, proxy-based API, I/O bottlenecks, architectural redesign, authorization]
  - **authors:** Elia Palme, Juan Pablo Dorsch, Ali Khosravi, Giovanni Pizzi, Francesco Pagnamenta, Andrea Ceriani, Eirini Koutsaniti, Rafael Sarmiento, Ivano Bonesana, Alejandro Dabin
  - **institution:** CSCS – Swiss National Supercomputing Centre, PSI Center for Scientific Computing, Theory, and Data
  - **link:** https://arxiv.org/pdf/2512.11634
  - **Simple LLM Summary:** This paper presents FirecREST v2, a redesigned RESTful API for programmatic access to HPC resources, focusing on security and high throughput. The authors detail a systematic performance testing methodology to identify bottlenecks in proxy-based APIs and describe key architectural changes. The main conclusion is that the redesign achieved a ~100x performance improvement over its predecessor, as validated by independent peer review.

- **[arXiv251215] ECCO: Leveraging Cross-Camera Correlations for Efficient Live Video Continuous Learning**
  - **tags:** [mlsys], [others], [continuous learning, video analytics, cross-camera correlation, dynamic grouping, GPU resource allocation, transmission control, frame sampling]
  - **authors:** Yuze He, Ferdi Kossmann, Srinivasan Seshan, Peter Steenkiste
  - **institution:** Carnegie Mellon University, Massachusetts Institute of Technology
  - **link:** https://arxiv.org/pdf/2512.11727
  - **Simple LLM Summary:** ECCO is a video analytics framework that improves resource efficiency for continuous learning by grouping cameras with similar data drift patterns to share retrained models. It dynamically forms camera groups, allocates GPU resources, and controls frame transmission to reduce compute and communication costs. The system achieves higher accuracy or supports more cameras compared to existing baselines.

- **[arXiv251215] Hypergraph based Multi-Party Payment Channel**
  - **tags:** [sys], [blockchain scalability], [payment channel networks, hypergraph, multi-party channels, off-chain scaling, DAG updates]
  - **authors:** Ayush Nainwal, Atharva Kamble, Nitin Awathare
  - **institution:** Indian Institute of Technology, Jodhpur; Indian Institute of Technology, Bombay
  - **link:** https://arxiv.org/pdf/2512.11775
  - **Simple LLM Summary:** The paper introduces Hypergraph-based Multi-Party Payment Channels (H-MPCs), a new off-chain construction that replaces traditional bilateral channels with collectively funded hyperedges to enable leaderless, concurrent payments. This design addresses liquidity fragmentation and channel depletion in existing payment networks. The implementation demonstrates a high transaction success rate of approximately 94%, highlighting the protocol's robustness.


**cs.AI/cs.LG contains "reinforcement learning" total: 16**
- [arXiv251215] Rethinking Expert Trajectory Utilization in LLM Post-training [link](https://arxiv.org/pdf/2512.11470)
- [arXiv251215] In-Context Multi-Objective Optimization [link](https://arxiv.org/pdf/2512.11114)
- [arXiv251215] Motif-2-12.7B-Reasoning: A Practitioner's Guide to RL Training Recipes [link](https://arxiv.org/pdf/2512.11463)
- [arXiv251215] Mitigating the Safety Alignment Tax with Null-Space Constrained Policy Optimization [link](https://arxiv.org/pdf/2512.11391)
- [arXiv251215] DAPO: Design Structure-Aware Pass Ordering in High-Level Synthesis with Graph Contrastive and Reinforcement Learning [link](https://arxiv.org/pdf/2512.11342)
- [arXiv251215] A-LAMP: Agentic LLM-Based Framework for Automated MDP Modeling and Policy Generation [link](https://arxiv.org/pdf/2512.11270)
- [arXiv251215] Multi-Objective Reinforcement Learning for Large-Scale Mixed Traffic Control [link](https://arxiv.org/pdf/2512.11247)
- [arXiv251215] Three methods, one problem: Classical and AI approaches to no-three-in-line [link](https://arxiv.org/pdf/2512.11469)
- [arXiv251215] CORL: Reinforcement Learning of MILP Policies Solved via Branch and Bound [link](https://arxiv.org/pdf/2512.11169)
- [arXiv251215] Towards Trustworthy Multi-Turn LLM Agents via Behavioral Guidance [link](https://arxiv.org/pdf/2512.11421)
- [arXiv251215] Symmetry-Aware Steering of Equivariant Diffusion Policies: Benefits and Limits [link](https://arxiv.org/pdf/2512.11345)
- [arXiv251215] Bandwidth-constrained Variational Message Encoding for Cooperative Multi-agent Reinforcement Learning [link](https://arxiv.org/pdf/2512.11179)
- [arXiv251215] When Actions Teach You to Think: Reasoning-Action Synergy via Reinforcement Learning in Conversational Agents [link](https://arxiv.org/pdf/2512.11277)
- [arXiv251215] DentalGPT: Incentivizing Multimodal Complex Reasoning in Dentistry [link](https://arxiv.org/pdf/2512.11558)
- [arXiv251215] Agile Flight Emerges from Multi-Agent Competitive Racing [link](https://arxiv.org/pdf/2512.11781)
- [arXiv251215] Marti-5: A Mathematical Model of "Self in the World" as a First Step Toward Self-Awareness [link](https://arxiv.org/pdf/2512.10985)

**cs.AI/cs.LG contains "accelerate" total: 6**
- [arXiv251215] A Scalable Multi-GPU Framework for Encrypted Large-Model Inference [link](https://arxiv.org/pdf/2512.11269)
- [arXiv251215] DAPO: Design Structure-Aware Pass Ordering in High-Level Synthesis with Graph Contrastive and Reinforcement Learning [link](https://arxiv.org/pdf/2512.11342)
- [arXiv251215] Refining Graphical Neural Network Predictions Using Flow Matching for Optimal Power Flow with Constraint-Satisfaction Guarantee [link](https://arxiv.org/pdf/2512.11127)
- [arXiv251215] CIP: A Plug-and-Play Causal Prompting Framework for Mitigating Hallucinations under Long-Context Noise [link](https://arxiv.org/pdf/2512.11282)
- [arXiv251215] Deep Learning--Accelerated Multi-Start Large Neighborhood Search for Real-time Freight Bundling [link](https://arxiv.org/pdf/2512.11187)
- [arXiv251215] Gradient Descent as a Perceptron Algorithm: Understanding Dynamics and Implicit Acceleration [link](https://arxiv.org/pdf/2512.11587)

## 2025-12-16

**cs.DC total: 26**

- **[arXiv251216] Strategic Server Deployment under Uncertainty in Mobile Edge Computing**
  - **tags:** [sys], [mobile edge computing], [stochastic bilevel optimization, submodular maximization, greedy algorithm, server placement, server assignment]
  - **authors:** Duc A. Tran, Dung Truong, Duy Le
  - **institution:** University of Massachusetts Boston
  - **link:** https://arxiv.org/pdf/2512.12532
  - **Simple LLM Summary:** The paper formulates the strategic server deployment problem in mobile edge computing as a stochastic bilevel optimization and solves it by approximating the objective with submodular functions, enabling the use of greedy algorithms. Evaluation with real-world data shows the proposed method can outperform alternatives by up to 55%.

- **[arXiv251216] Beyond right or wrong : towards redefining adaptive learning indicators in virtual learning environments**
  - **tags:** [ai], [educational technology], [Systematic Literature Review, adaptive learning, learning indicators, motivation, emotions, physiological responses, brain imaging, prior knowledge]
  - **authors:** Andreia dos Santos Sachete, Alba Valeria de SantAnna de Freitas Loiola, Fabio Diniz Rossi, Jose Valdeni de Lima, Raquel Salcedo Gomes
  - **institution:** Federal Institute Farroupilha, Federal University of Rio Grande do Sul
  - **link:** https://arxiv.org/pdf/2512.12105
  - **Simple LLM Summary:** This paper conducts a Systematic Literature Review to identify learning indicators beyond correctness that can enhance adaptive learning in Virtual Learning Environments. It concludes that factors like motivation, emotions, physiological responses, brain imaging, and prior knowledge are crucial for a more comprehensive assessment. The findings aim to guide developers in creating more effective adaptive learning solutions tailored to student realities.

- **[arXiv251216] BOOST: BOttleneck-Optimized Scalable Training Framework for Low-Rank Large Language Models**
  - **tags:** [mlsys], [llm training], [bottleneck-aware tensor parallelism, online-RMSNorm, linear layer grouping, low-rank activation checkpointing, low-rank bottleneck architectures, 3D parallelism]
  - **authors:** Zhengyang Wang, Ziyue Liu, Ruijie Zhang, Avinash Maurya, Paul Hovland, Bogdan Nicolae, Franck Cappello, Zheng Zhang
  - **institution:** University of California, Santa Barbara, Argonne National Laboratory
  - **link:** https://arxiv.org/pdf/2512.12131
  - **Simple LLM Summary:** The paper proposes BOOST, a training framework for low-rank large language models that introduces Bottleneck-aware Tensor Parallelism and other optimizations to improve scalability. It demonstrates significant speedups over both full-rank baselines and naively parallelized low-rank models by reducing communication overhead and improving GPU utilization.

- **[arXiv251216] A Conflict-Aware Resource Management Framework for the Computing Continuum**
  - **tags:** [mlsys], [cluster infrastructure], [deep reinforcement learning, kubernetes, resource orchestration, conflict resolution, computing continuum]
  - **authors:** Vlad Popescu-Vifor, Ilir Murturi, Praveen Kumar Donta, Schahram Dustdar
  - **institution:** TU Wien, University of Prishtina, Stockholm University, ICREA
  - **link:** https://arxiv.org/pdf/2512.12299
  - **Simple LLM Summary:** The paper proposes a framework for adaptive conflict resolution in resource orchestration for the computing continuum using Deep Reinforcement Learning (DRL). It was prototyped and validated on a Kubernetes-based testbed. The results show the framework achieves efficient resource reallocation and adaptive learning, providing a scalable and resilient solution.

- **[arXiv251216] Near-Zero-Overhead Freshness for Recommendation Systems via Inference-Side Model Updates**
  - **tags:** [mlsys], [cluster infrastructure], [Low-Rank Adaptation (LoRA), dynamic rank adaptation, NUMA-aware scheduling, embedding tables (EMTs), delta-update, parameter synchronization]
  - **authors:** Wenjun Yu, Sitian Chen, Cheng Chen, Amelie Chi Zhou
  - **institution:** Hong Kong Baptist University, ByteDance
  - **link:** https://arxiv.org/pdf/2512.12295
  - **Simple LLM Summary:** This paper introduces LiveUpdate, a system that co-locates Low-Rank Adaptation (LoRA) trainers within inference nodes to perform near-zero-overhead model updates for recommendation systems. It uses dynamic rank adaptation and NUMA-aware resource scheduling to minimize memory overhead and latency impact. The system reduces update costs and improves recommendation accuracy compared to baseline delta-update methods.

- **[arXiv251216] MVP-ORAM: a Wait-free Concurrent ORAM for Confidential BFT Storage**
  - **tags:** [sys], [secure storage], [Oblivious RAM, Byzantine fault tolerance, wait-free concurrency, secret sharing, access pattern hiding]
  - **authors:** Robin Vassantlal, Hasan Heydari, Bernardo Ferreira, Alysson Bessani
  - **institution:** LASIGE, Faculdade de Ciências, Universidade de Lisboa
  - **link:** https://arxiv.org/pdf/2512.12006
  - **Simple LLM Summary:** The paper introduces MVP-ORAM, a wait-free concurrent Oblivious RAM protocol that allows clients to perform independent operations and merge conflicting updates without inter-client coordination. It achieves a weaker, practical notion of obliviousness for skewed workloads and integrates with confidential Byzantine fault-tolerant storage. The prototype demonstrates the ability to process hundreds of 4KB accesses per second in cloud environments.

- **[arXiv251216] HetRL: Efficient Reinforcement Learning for LLMs in Heterogeneous Environments**
  - **tags:** [mlsys], [post-training], [reinforcement learning, heterogeneous environments, scheduling algorithm, multi-level search, successive halving, Proximal Policy Optimization (PPO)]
  - **authors:** Yongjun He, Shuai Zhang, Jiading Gai, Xiyuan Zhang, Boran Han, Bernie Wang, Huzefa Rangwala, George Karypis
  - **institution:** ETH Zurich, Amazon Web Services (AWS)
  - **link:** https://arxiv.org/pdf/2512.12476
  - **Simple LLM Summary:** The paper presents HetRL, a distributed system for efficient reinforcement learning training of large language models in environments with heterogeneous GPUs and networks. It formulates the scheduling as a constrained optimization problem and introduces a novel algorithm using a multi-level search framework and successive halving. The evaluation shows HetRL achieves up to 9.17x higher throughput compared to state-of-the-art systems.

- **[arXiv251216] Evaluating Asynchronous Semantics in Trace-Discovered Resilience Models: A Case Study on the OpenTelemetry Demo**
  - **tags:** [sys], [fault-tolerance], [distributed tracing, Monte Carlo simulation, service dependency graph, chaos engineering, OpenTelemetry]
  - **authors:** Anatoly A. Krasnovsky
  - **institution:** Innopolis University, MB3R Lab
  - **link:** https://arxiv.org/pdf/2512.12314
  - **Simple LLM Summary:** This paper develops a trace-discovered resilience model that builds a service dependency graph from OpenTelemetry traces and uses Monte Carlo simulation to estimate endpoint availability under service failures. The study applies this model to the OpenTelemetry Demo and finds that adding asynchronous semantics for Kafka messaging has a negligible impact on predicted availability. The main conclusion is that for immediate HTTP availability in this case, a simpler connectivity-only model is sufficient, and explicit modeling of asynchronous dependencies is not necessary.

- **[arXiv251216] Reputation-Based Leader Election under Partial Synchrony: Towards a Protocol-Independent Abstraction with Enhanced Guarantees**
  - **tags:** [sys], [distributed consensus], [Sliding Window Leader Election (SWLE), Byzantine Fault Tolerance (BFT), partial synchrony, reputation-based, protocol-independent abstraction, Global Stabilization Time (GST)]
  - **authors:** Xuyang Liu, Zijian Zhang, Zhen Li, Jiahang Sun, Jiamou Liu, Peng Jiang
  - **institution:** Beijing Institute of Technology, The University of Auckland
  - **link:** https://arxiv.org/pdf/2512.12409
  - **Simple LLM Summary:** This paper introduces a protocol-independent abstraction for leader election in partially synchronous Byzantine Fault Tolerant systems and proposes the Sliding Window Leader Election (SWLE) mechanism, which uses reputation scores based on consensus behavior. The authors prove SWLE's correctness and effectiveness, and their experimental deployment shows it significantly outperforms the state-of-the-art in throughput, latency, and Byzantine leader frequency under common faults.

- **[arXiv251216] Accelerating Sparse Matrix-Matrix Multiplication on GPUs with Processing Near HBMs**
  - **tags:** [mlsys], [GPU kernels], [SpGEMM, near-memory processing, hardware-software co-design, hash-based multi-phase, acceleration of indirect memory access (AIA), graph neural networks (GNNs)]
  - **authors:** Shiju Li, Younghoon Min, Hane Yie, Hoshik Kim, Soohong Ahn, Joonseop Sim, Chul-Ho Lee, Jongryool Kim
  - **institution:** SK hynix, Texas State University
  - **link:** https://arxiv.org/pdf/2512.12036
  - **Simple LLM Summary:** This paper introduces a hardware-software co-designed framework for accelerating Sparse General Matrix-Matrix Multiplication (SpGEMM) on GPUs using a novel near-memory processing technique called Acceleration of Indirect Memory Access (AIA). The method employs a hash-based multi-phase approach to optimize irregular memory access patterns. It demonstrates significant performance improvements over state-of-the-art software libraries like cuSPARSE in graph analytics and GNN training workloads.

- **[arXiv251216] Ethical Risk Analysis of L2 Rollups**
  - **tags:** [sys], [blockchain], [ethical risk analysis, layer 2 rollups, governance design, upgrade timing, exit windows, proposer liveness, forced inclusion, data availability]
  - **authors:** Georgy Ishmaev, Emmanuelle Anceaume, Davide Frey, François Taïani
  - **institution:** Univ Rennes, Inria, CNRS, IRISA
  - **link:** https://arxiv.org/pdf/2512.12732
  - **Simple LLM Summary:** The paper adapts Ethical Risk Analysis to Layer 2 rollup architectures, using a role-based taxonomy and empirical data from 129 projects and incident reports. It concludes that ethically problematic risks, such as instant upgrades without exit windows and proposer controls that can freeze withdrawals, are widespread in current designs.

- **[arXiv251216] SPARK: Igniting Communication-Efficient Decentralized Learning via Stage-wise Projected NTK and Accelerated Regularization**
  - **tags:** [mlsys], [others], [decentralized federated learning, neural tangent kernel, random projection, Jacobian compression, stage-wise annealed distillation, Nesterov momentum]
  - **authors:** Li Xia
  - **institution:** Minzu University of China
  - **link:** https://arxiv.org/pdf/2512.12737
  - **Simple LLM Summary:** The paper proposes SPARK, a communication-efficient decentralized federated learning method that compresses Jacobian matrices using random projections and employs stage-wise annealed distillation and Nesterov momentum. It achieves a 98.7% communication reduction while maintaining convergence speed and superior accuracy, enabling practical deployment in bandwidth-limited edge environments.

- **[arXiv251216] Spectral Sentinel: Scalable Byzantine-Robust Decentralized Federated Learning via Sketched Random Matrix Theory on Blockchain**
  - **tags:** [mlsys], [fault-tolerance], [sketched random matrix theory, marchenko-pastur law, frequent directions sketching, byzantine-robust aggregation, decentralized federated learning]
  - **authors:** Animesh Mishra
  - **institution:** Department of Computer Science & Engineering (implied from email domain: snu.edu.in, likely Shiv Nadar University)
  - **link:** https://arxiv.org/pdf/2512.12617
  - **Simple LLM Summary:** The paper proposes Spectral Sentinel, a Byzantine-robust decentralized federated learning framework that detects malicious updates by analyzing the eigenspectra of gradient covariances against the Marchenko-Pastur law, using sketching for scalability. It achieves provably optimal convergence and demonstrates high accuracy in experiments, including deployment on a blockchain network.

- **[arXiv251216] Toward Self-Healing Networks-on-Chip: RL-Driven Routing in 2D Torus Architectures**
  - **tags:** [mlsys], [fault-tolerance], [reinforcement learning, adaptive routing, torus topology, networks-on-chip, packet delivery ratio, fault-adaptive score]
  - **authors:** Mohammad Walid Charrwi, Zaid Hussain
  - **institution:** Kuwait University
  - **link:** https://arxiv.org/pdf/2512.13096
  - **Simple LLM Summary:** This paper proposes a reinforcement learning (RL) method where each router acts as an agent to adaptively route packets in a 2D torus Network-on-Chip (NoC). Compared to a baseline adaptive routing scheme, the RL-based approach achieves significantly higher throughput and maintains better packet delivery under increasing node faults by exploiting path diversity.

- **[arXiv251216] PROSERVE: Unified Multi-Priority Request Scheduling for LLM Serving**
  - **tags:** [mlsys], [llm inference], [request scheduling, service gain maximization, two-tier scheduling, SlideBatching, GoRouting, SLO attainment, multi-priority]
  - **authors:** Weizhe Huang, Tao Peng, Tongxuan Liu, Donghe Jin, Xianzhe Dong, Ke Zhang
  - **institution:** JD.com, USTC
  - **link:** https://arxiv.org/pdf/2512.12928
  - **Simple LLM Summary:** The paper proposes PROSERVE, a two-tier scheduling framework for LLM serving that maximizes overall service gain by jointly optimizing for SLO attainment and client priorities. Its engine-level SlideBatching adapts batch formation, while service-level GoRouting performs gain-aware dispatching across instances. Evaluation shows PROSERVE improves system gain by up to 35% and SLO attainment by up to 52% compared to baselines.

- **[arXiv251216] Fine-Grained Energy Prediction For Parallellized LLM Inference With PIE-P**
  - **tags:** [mlsys], [llm inference], [fine-grained energy prediction, multi-GPU inference, tensor parallelism, pipeline parallelism, data parallelism, inter-GPU communication modeling]
  - **authors:** Anurag Dutt, Young Won Choi, Avirup Sil, Anshul Gandhi, Aruna Balasubramanian, Niranjan Balasubramanian
  - **institution:** Stony Brook University, IBM Research
  - **link:** https://arxiv.org/pdf/2512.12801
  - **Simple LLM Summary:** This paper introduces PIE-P, a framework for fine-grained energy prediction of LLM inference parallelized across multiple GPUs. It addresses challenges like non-deterministic communication and overheads through precise sampling and modeling. The evaluation shows PIE-P provides accurate energy predictions across different parallelism strategies, outperforming existing baselines.

- **[arXiv251216] FlashFuser: Expanding the Scale of Kernel Fusion for Compute-Intensive Operators via Inter-Core Connection**
  - **tags:** [mlsys], [GPU kernels], [kernel fusion, distributed shared memory (DSM), inter-core connection, dataflow analysis, cost modeling, tile selection]
  - **authors:** Ziyu Huang, Yangjie Zhou, Zihan Liu, Xinhao Luo, Yijia Diao, Minyi Guo, Jidong Zhai, Yu Feng, Chen Zhang, Anbang Wu, Jingwen Leng
  - **institution:** Shanghai Jiao Tong University, Shanghai Qi Zhi Institute, National University of Singapore, Tsinghua University
  - **link:** https://arxiv.org/pdf/2512.12949
  - **Simple LLM Summary:** FlashFuser is a compiler framework that leverages the inter-core Distributed Shared Memory (DSM) on modern GPUs to enable large-scale kernel fusion for memory-bound workloads. It introduces a DSM communication abstraction, a dataflow analyzer for distributed memory, and a unified search engine to find optimal execution plans. Evaluations on an NVIDIA H100 show it reduces memory access by 58% and achieves significant speedups over existing libraries and compilers.

- **[arXiv251216] Towards Secure Decentralized Applications and Consensus Protocols in Blockchains (on Selfish Mining, Undercutting Attacks, DAG-Based Blockchains, E-Voting, Cryptocurrency Wallets, Secure-Logging, and CBDC)**
  - **tags:** [sys], [blockchain security], [selfish mining, undercutting attacks, DAG-based blockchains, e-voting, cryptocurrency wallets, secure-logging, CBDC]
  - **authors:** Ivan Homoliak
  - **institution:** Brno University of Technology
  - **link:** https://arxiv.org/pdf/2512.13213
  - **Simple LLM Summary:** This thesis proposes a holistic security reference architecture for blockchains and decentralized applications, analyzing threats across consensus protocols, wallets, e-voting, and logging. It contributes specific methods like a two-factor wallet authentication and a scalable, privacy-preserving boardroom voting protocol. The main conclusion is that securing complex blockchain systems requires integrated approaches across multiple subsystems, as demonstrated by the proposed frameworks for consensus security, voting, and central bank digital currency interoperability.

- **[arXiv251216] Temporal parallelisation of continuous-time maximum-a-posteriori trajectory estimation**
  - **tags:** [ai], [control and estimation], [parallel-in-time, maximum-a-posteriori, stochastic differential equations, Onsager-Machlup, optimal control, parallel associative scan, Kalman-Bucy filter, Rauch-Tung-Striebel smoother]
  - **authors:** Hassan Razavi, Ángel F. García-Fernández, Simo Särkkä
  - **institution:** Aalto University, Universidad Politécnica de Madrid, ELLIS Institute Finland
  - **link:** https://arxiv.org/pdf/2512.13319
  - **Simple LLM Summary:** This paper proposes a parallel-in-time method for computing continuous-time MAP trajectory estimates by reformulating the problem as an optimal control problem based on the Onsager-Machlup functional. The method leverages parallel associative scan algorithms and extends to linear and nonlinear models, including parallel versions of the Kalman-Bucy filter and smoother. GPU experiments demonstrate the framework achieves significant computational speedup while maintaining the accuracy of sequential algorithms.

- **[arXiv251216] SPARS: A Reinforcement Learning-Enabled Simulator for Power Management in HPC Job Scheduling**
  - **tags:** [mlsys], [cluster infrastructure], [reinforcement learning, discrete-event simulation, job scheduling, power management, energy efficiency, EASY Backfilling, First Come First Served]
  - **authors:** Muhammad Alfian Amrizal, Raka Satya Prasasta, Santana Yuda Pradata, Kadek Gemilang Santiyuda, Reza Pulungan, Hiroyuki Takizawa
  - **institution:** Universitas Gadjah Mada, Universitas Ahmad Dahlan, Institut Bisnis dan Teknologi Indonesia, National Taiwan University of Science and Technology, Tohoku University
  - **link:** https://arxiv.org/pdf/2512.13268
  - **Simple LLM Summary:** The paper presents SPARS, a reinforcement learning-enabled simulator that integrates job scheduling and node power state management within a discrete-event framework to optimize energy efficiency in HPC clusters. It supports traditional policies and RL-enhanced variants to dynamically manage node power transitions. The main conclusion is that SPARS provides a lightweight, reproducible, and extensible platform for evaluating power-aware scheduling strategies, enabling better trade-offs between energy savings and performance.

- **[arXiv251216] Design in Tiles: Automating GEMM Deployment on Tile-Based Many-PE Accelerators**
  - **tags:** [mlsys], [GPU kernels], [tile-based architecture, automated deployment, network on chip, collective primitives, scratchpad memory]
  - **authors:** Aofeng Shen, Chi Zhang, Yakup Budanaz, Alexandru Calotoiu, Torsten Hoefler, Luca Benini
  - **institution:** ETH Zurich
  - **link:** https://arxiv.org/pdf/2512.13638
  - **Simple LLM Summary:** The paper proposes "Design in Tiles (DiT)", an automated framework for deploying GEMM on tile-based many-PE accelerators by connecting a deployment toolchain with a configurable executable model. It demonstrates that this approach achieves higher PE utilization than expert-tuned libraries on comparable hardware, resulting in a 1.2–2.0x speedup across diverse matrix shapes.

- **[arXiv251216] SEDULity: A Proof-of-Learning Framework for Distributed and Secure Blockchains with Efficient Useful Work**
  - **tags:** [mlsys], [others], [proof-of-learning, consensus mechanism, incentive mechanism, distributed training, blockchain security]
  - **authors:** Weihang Cao, Mustafa Doger, Sennur Ulukus
  - **institution:** University of Maryland, College Park
  - **link:** https://arxiv.org/pdf/2512.13666
  - **Simple LLM Summary:** The paper proposes SEDULity, a Proof-of-Learning framework that replaces the energy-wasting Proof-of-Work puzzle in blockchains with a useful machine learning training task. It demonstrates that this framework is secure, distributed, and efficiently trains models while incentivizing honest participation through a designed mechanism.

- **[arXiv251216] SIGMA: An AI-Empowered Training Stack on Early-Life Hardware**
  - **tags:** [mlsys], [cluster infrastructure], [early-life AI accelerators, fault tolerance, distributed training, MoE model, training stability, platform-framework separation]
  - **authors:** Lei Qu, Lianhai Ren, Peng Cheng, Rui Gao, Ruizhe Wang, Tianyu Chen, Xiao Liu, Xingjian Zhang, Yeyun Gong, Yifan Xiong, Yucheng Ding, Yuting Jiang, Zhenghao Lin, Zhongxin Guo, Ziyue Yang
  - **institution:** Microsoft Research
  - **link:** https://arxiv.org/pdf/2512.13488
  - **Simple LLM Summary:** SIGMA is an open-source training stack designed for large-scale distributed training on unreliable early-life AI hardware. It introduces a two-layer architecture (LUCIA TRAINING PLATFORM and LUCIA TRAINING FRAMEWORK) to centrally handle hardware reliability and fault mitigation while optimizing for numerical stability and training efficiency. The system demonstrated high reliability and efficiency, successfully training a 200B MoE model with state-of-the-art accuracy, establishing a robust and cost-effective alternative to established accelerator stacks.

- **[arXiv251216] TreeVQA: A Tree-Structured Execution Framework for Shot Reduction in Variational Quantum Algorithms**
  - **tags:** [mlsys], [cluster infrastructure], [variational quantum algorithms, tree-structured execution, shot reduction, quantum circuit execution, VQA wrapper]
  - **authors:** Yuewen Hou, Dhanvi Bharadwaj, Gokul Subramanian Ravi
  - **institution:** University of Michigan
  - **link:** https://arxiv.org/pdf/2512.12068
  - **Simple LLM Summary:** The paper proposes TreeVQA, a tree-structured execution framework that reduces the computational cost of Variational Quantum Algorithms by exploiting similarities across tasks. It begins with joint execution and branches only when quantum executions diverge. Evaluations show significant shot count reductions, averaging 25.9x, with benefits increasing for larger problems.

- **[arXiv251216] Janus: Disaggregating Attention and Experts for Scalable MoE Inference**
  - **tags:** [mlsys], [llm inference], [mixture-of-experts (MoE), disaggregated architecture, two-phase communication, GPU kernel scheduler, fine-grained resource management]
  - **authors:** Zhexiang Zhang, Ye Wang, Xiangyu Wang, Yumiao Zhao, Jingzhe Jiang, Qizhen Weng, Shaohuai Shi, Yin Chen, Minchen Yu
  - **institution:** The Chinese University of Hong Kong, Shenzhen; Institute of Artificial Intelligence (TeleAI), China Telecom; Shenzhen Loop Area Institute; Harbin Institute of Technology, Shenzhen
  - **link:** https://arxiv.org/pdf/2512.13525
  - **Simple LLM Summary:** The paper proposes Janus, a scalable inference system for large Mixture-of-Experts (MoE) models that disaggregates the attention and expert modules onto separate GPU sub-clusters for independent management and scaling. Its key designs include an adaptive two-phase communication scheme, a lightweight GPU-kernel scheduler for expert load balancing, and fine-grained resource management. The evaluation shows Janus achieves up to 3.9x higher per-GPU throughput than state-of-the-art systems while meeting latency requirements.

- **[arXiv251216] astroCAMP: A Community Benchmark and Co-Design Framework for Sustainable SKA-Scale Radio Imaging**
  - **tags:** [sys], [high-performance computing], [benchmarking, co-design, energy efficiency, radio interferometry, Pareto optimization, FPGA, GPU, CPU]
  - **authors:** Denisa-Andreea Constantinescu, Rubén Rodríguez Álvarez, Jacques Morin, Etienne Orliac, Mickaël Dardaillon, Sunrise Wang, Hugo Miomandre, Miguel Peón-Quirós, Jean-François Nezan, David Atienza
  - **institution:** EPFL, Univ Rennes, INSA Rennes, CNRS, Univ Côte d’Azur, OCA
  - **link:** https://arxiv.org/pdf/2512.13591
  - **Simple LLM Summary:** The paper introduces astroCAMP, a framework for hardware-software co-design and benchmarking to improve the computational and energy efficiency of radio astronomy imaging pipelines for the SKA telescope. It provides standardized metrics, datasets, and a multi-objective formulation to explore trade-offs between scientific fidelity and sustainability. The main conclusion is that such a framework is essential for identifying Pareto-optimal system designs that maximize scientific return within the SKA's strict operational and environmental constraints.


**cs.AI/cs.LG contains "reinforcement learning" total: 38**
- [arXiv251216] Reinforcement Learning for Latent-Space Thinking in LLMs [link](https://arxiv.org/pdf/2512.11816)
- [arXiv251216] Mirror Mode in Fire Emblem: Beating Players at their own Game with Imitation and Reinforcement Learning [link](https://arxiv.org/pdf/2512.11902)
- [arXiv251216] WAM-Diff: A Masked Diffusion VLA Framework with MoE and Online Reinforcement Learning for Autonomous Driving [link](https://arxiv.org/pdf/2512.11872)
- [arXiv251216] Policy Gradient Algorithms for Age-of-Information Cost Minimization [link](https://arxiv.org/pdf/2512.11990)
- [arXiv251216] ElasticVR: Elastic Task Computing in Multi-User Multi-Connectivity Wireless Virtual Reality (VR) Systems [link](https://arxiv.org/pdf/2512.12366)
- [arXiv251216] Hierarchical Task Offloading and Trajectory Optimization in Low-Altitude Intelligent Networks Via Auction and Diffusion-based MARL [link](https://arxiv.org/pdf/2512.11862)
- [arXiv251216] A Review of Learning-Based Motion Planning: Toward a Data-Driven Optimal Control Approach [link](https://arxiv.org/pdf/2512.11944)
- [arXiv251216] Learning to Get Up Across Morphologies: Zero-Shot Recovery with a Unified Humanoid Policy [link](https://arxiv.org/pdf/2512.12230)
- [arXiv251216] Evolutionary Reinforcement Learning based AI tutor for Socratic Interdisciplinary Instruction [link](https://arxiv.org/pdf/2512.11930)
- [arXiv251216] Learning to Extract Context for Context-Aware LLM Inference [link](https://arxiv.org/pdf/2512.11986)
- [arXiv251216] Goal Reaching with Eikonal-Constrained Hierarchical Quasimetric Reinforcement Learning [link](https://arxiv.org/pdf/2512.12046)
- [arXiv251216] World Models Unlock Optimal Foraging Strategies in Reinforcement Learning Agents [link](https://arxiv.org/pdf/2512.12548)
- [arXiv251216] Coupled Variational Reinforcement Learning for Language Model General Reasoning [link](https://arxiv.org/pdf/2512.12576)
- [arXiv251216] Reassessing the Role of Supervised Fine-Tuning: An Empirical Study in VLM Reasoning [link](https://arxiv.org/pdf/2512.12690)
- [arXiv251216] Synergizing Code Coverage and Gameplay Intent: Coverage-Aware Game Playtesting with LLM-Guided Reinforcement Learning [link](https://arxiv.org/pdf/2512.12706)
- [arXiv251216] Self-Motivated Growing Neural Network for Adaptive Architecture via Local Structural Plasticity [link](https://arxiv.org/pdf/2512.12713)
- [arXiv251216] Information-Consistent Language Model Recommendations through Group Relative Policy Optimization [link](https://arxiv.org/pdf/2512.12858)
- [arXiv251216] LLM-based Personalized Portfolio Recommender: Integrating Large Language Models and Reinforcement Learning for Intelligent Investment Strategy Optimization [link](https://arxiv.org/pdf/2512.12922)
- [arXiv251216] Tackling Snow-Induced Challenges: Safe Autonomous Lane-Keeping with Robust Reinforcement Learning [link](https://arxiv.org/pdf/2512.12987)
- [arXiv251216] GTR-Turbo: Merged Checkpoint is Secretly a Free Teacher for Agentic VLM Training [link](https://arxiv.org/pdf/2512.13043)
- [arXiv251216] Deep Q-Learning-Based Intelligent Scheduling for ETL Optimization in Heterogeneous Data Environments [link](https://arxiv.org/pdf/2512.13060)
- [arXiv251216] M-GRPO: Stabilizing Self-Supervised Reinforcement Learning for Large Language Models with Momentum-Anchored Policy Optimization [link](https://arxiv.org/pdf/2512.13070)
- [arXiv251216] PvP: Data-Efficient Humanoid Robot Learning with Proprioceptive-Privileged Contrastive Representations [link](https://arxiv.org/pdf/2512.13093)
- [arXiv251216] ADHint: Adaptive Hints with Difficulty Priors for Reinforcement Learning [link](https://arxiv.org/pdf/2512.13095)
- [arXiv251216] TraPO: A Semi-Supervised Reinforcement Learning Framework for Boosting LLM Reasoning [link](https://arxiv.org/pdf/2512.13106)
- [arXiv251216] SpeakRL: Synergizing Reasoning, Speaking, and Acting in Language Models with Reinforcement Learning [link](https://arxiv.org/pdf/2512.13159)
- [arXiv251216] SACn: Soft Actor-Critic with n-step Returns [link](https://arxiv.org/pdf/2512.13165)
- [arXiv251216] Reflective Preference Optimization (RPO): Enhancing On-Policy Alignment via Hint-Guided Reflection [link](https://arxiv.org/pdf/2512.13240)
- [arXiv251216] AutoTool: Dynamic Tool Selection and Integration for Agentic Reasoning [link](https://arxiv.org/pdf/2512.13278)
- [arXiv251216] Intrinsic-Motivation Multi-Robot Social Formation Navigation with Coordinated Exploration [link](https://arxiv.org/pdf/2512.13293)
- [arXiv251216] Control of a Twin Rotor using Twin Delayed Deep Deterministic Policy Gradient (TD3) [link](https://arxiv.org/pdf/2512.13356)
- [arXiv251216] Fast Policy Learning for 6-DOF Position Control of Underwater Vehicles [link](https://arxiv.org/pdf/2512.13359)
- [arXiv251216] Differentiable Evolutionary Reinforcement Learning [link](https://arxiv.org/pdf/2512.13399)
- [arXiv251216] MedCEG: Reinforcing Verifiable Medical Reasoning with Critical Evidence Graph [link](https://arxiv.org/pdf/2512.13510)
- [arXiv251216] Memory in the Age of AI Agents [link](https://arxiv.org/pdf/2512.13564)
- [arXiv251216] Image Diffusion Preview with Consistency Solver [link](https://arxiv.org/pdf/2512.13592)
- [arXiv251216] Nemotron-Cascade: Scaling Cascaded Reinforcement Learning for General-Purpose Reasoning Models [link](https://arxiv.org/pdf/2512.13607)
- [arXiv251216] A Scientific Reasoning Model for Organic Synthesis Procedure Generation [link](https://arxiv.org/pdf/2512.13668)

**cs.AI/cs.LG contains "accelerate" total: 20**
- [arXiv251216] KV Cache Recycling to Expand Usable Context Capacity in Low Parameter LLMs [link](https://arxiv.org/pdf/2512.11851)
- [arXiv251216] Beyond Automation: Rethinking Work, Creativity, and Governance in the Age of Generative AI [link](https://arxiv.org/pdf/2512.11893)
- [arXiv251216] Synthetic Swarm Mosquito Dataset for Acoustic Classification: A Proof of Concept [link](https://arxiv.org/pdf/2512.12365)
- [arXiv251216] Using Socio-economic Indicators, Smart Transit Systems, and Urban Simulator to Accelerate ZEV Adoption and Reduce VMT [link](https://arxiv.org/pdf/2512.11870)
- [arXiv251216] MeltwaterBench: Deep learning for spatiotemporal downscaling of surface meltwater [link](https://arxiv.org/pdf/2512.12142)
- [arXiv251216] CXL-SpecKV: A Disaggregated FPGA Speculative KV-Cache for Datacenter LLM Serving [link](https://arxiv.org/pdf/2512.11920)
- [arXiv251216] Neural CDEs as Correctors for Learned Time Series Models [link](https://arxiv.org/pdf/2512.12116)
- [arXiv251216] AGAPI-Agents: An Open-Access Agentic AI Platform for Accelerated Materials Design on AtomGPT.org [link](https://arxiv.org/pdf/2512.11935)
- [arXiv251216] Skillful Subseasonal-to-Seasonal Forecasting of Extreme Events with a Multi-Sphere Coupled Probabilistic Model [link](https://arxiv.org/pdf/2512.12545)
- [arXiv251216] Torch Geometric Pool: the Pytorch library for pooling in Graph Neural Networks [link](https://arxiv.org/pdf/2512.12642)
- [arXiv251216] Intelligent Scientific Literature Explorer using Machine Learning (ISLE) [link](https://arxiv.org/pdf/2512.12760)
- [arXiv251216] HaShiFlex: A High-Throughput Hardened Shifter DNN Accelerator with Fine-Tuning Flexibility [link](https://arxiv.org/pdf/2512.12847)
- [arXiv251216] Distillation of Discrete Diffusion by Exact Conditional Distribution Matching [link](https://arxiv.org/pdf/2512.12889)
- [arXiv251216] MADTempo: An Interactive System for Multi-Event Temporal Video Retrieval with Query Augmentation [link](https://arxiv.org/pdf/2512.12929)
- [arXiv251216] SeVeDo: A Heterogeneous Transformer Accelerator for Low-Bit Inference via Hierarchical Group Quantization and SVD-Guided Mixed Precision [link](https://arxiv.org/pdf/2512.12930)
- [arXiv251216] Efficient Adaptive Rejection Sampling for Accelerating Speculative Decoding in Large Language Models [link](https://arxiv.org/pdf/2512.13194)
- [arXiv251216] Fast Policy Learning for 6-DOF Position Control of Underwater Vehicles [link](https://arxiv.org/pdf/2512.13359)
- [arXiv251216] Image Diffusion Preview with Consistency Solver [link](https://arxiv.org/pdf/2512.13592)
- [arXiv251216] V-Rex: Real-Time Streaming Video LLM Acceleration via Dynamic KV Cache Retrieval [link](https://arxiv.org/pdf/2512.12284)
- [arXiv251216] Efficient Level-Crossing Probability Calculation for Gaussian Process Modeled Data [link](https://arxiv.org/pdf/2512.12442)
