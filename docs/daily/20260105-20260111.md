# 20260105-20260111

## 2026-01-05

**cs.DC total: 9**

- **[arXiv260105] Cost-Performance Analysis of Cloud-Based Retail Point-of-Sale Systems: A Comparative Study of Google Cloud Platform and Microsoft Azure**
  - **tags:** [sys], [cloud computing], [benchmarking, cost-performance analysis, scalability, response latency, throughput]
  - **authors:** Ravi Teja Pagidoju
  - **institution:** Campbellsville University
  - **link:** https://arxiv.org/pdf/2601.00530
  - **Simple LLM Summary:** This paper presents a systematic, code-driven benchmarking methodology to compare the performance and cost of deploying retail Point-of-Sale workloads on Google Cloud Platform and Microsoft Azure. The study finds that GCP offers faster response times, while Azure demonstrates higher cost efficiency for steady-state operations.

- **[arXiv260105] From Consensus to Chaos: A Vulnerability Assessment of the RAFT Algorithm**
  - **tags:** [sys], [distributed consensus], [RAFT, message replay attacks, message forgery attacks, cryptography, authenticated message verification, freshness check]
  - **authors:** Tamer Afifi, Abdelfatah Hegazy, Ehab Abousaif
  - **institution:** Arab Academy for Science, Technology & Maritime
  - **link:** https://arxiv.org/pdf/2601.00273
  - **Simple LLM Summary:** This paper conducts a security analysis of the RAFT consensus algorithm, identifying vulnerabilities to replay and forgery attacks. It proposes a solution using cryptography, authenticated message verification, and freshness checks to enhance security. The main conclusion is that these cryptographic enhancements can protect RAFT implementations from such attacks and improve the resilience of distributed systems.

- **[arXiv260105] Impact of Clustering on the Observability and Controllability of Complex Networks**
  - **tags:** [sys], [network theory], [structured systems theory, Monte-Carlo simulations, clustering, scale-free networks, observability, controllability, driver nodes, observer nodes]
  - **authors:** Mohammadreza Doostmohammadian, Hamid R. Rabiee
  - **institution:** Semnan University, Sharif University of Technology
  - **link:** https://arxiv.org/pdf/2601.00221
  - **Simple LLM Summary:** This paper uses structured systems theory and Monte-Carlo simulations to study how clustering affects observability and controllability in scale-free networks. It concludes that densely clustered networks require fewer driver and observer nodes for control and observation, offering insights for optimizing sensor/actuator placement in resource-constrained systems.

- **[arXiv260105] Secure, Verifiable, and Scalable Multi-Client Data Sharing via Consensus-Based Privacy-Preserving Data Distribution**
  - **tags:** [sys], [secure multi-party computation], [affine masking, consensus locking, step checksum, data checksum, unanimous-release confidentiality, CDIF]
  - **authors:** Prajwal Panth, Sahaj Raj Malla
  - **institution:** KIIT University, Kathmandu University
  - **link:** https://arxiv.org/pdf/2601.00418
  - **Simple LLM Summary:** The paper proposes the CPPDD framework, a lightweight protocol for secure multi-client data aggregation that uses per-client affine masking and sequential consensus locking for confidentiality, along with checksums for integrity verification. It demonstrates linear scalability, 100% deviation detection, and significantly lower computational overhead compared to MPC and HE baselines, making it suitable for resource-constrained environments.

- **[arXiv260105] Federated Customization of Large Models: Approaches, Experiments, and Insights**
  - **tags:** [mlsys], [llm training], [federated learning, prefix-tuning, fine-tuning, prompt engineering, retrieval-augmented generation, knowledge distillation]
  - **authors:** Yuchuan Ye, Ming Ding, Youjia Chen, Peng Cheng, Dusit Niyato
  - **institution:** Fuzhou University, Data61 CSIRO, La Trobe University, Nanyang Technological University
  - **link:** https://arxiv.org/pdf/2601.00526
  - **Simple LLM Summary:** This paper explores federated learning techniques for customizing large models, with a focus on implementing methods like prefix-tuning in a decentralized setting. It experimentally validates federated prefix-tuning, showing it achieves performance close to centralized approaches while maintaining competitive efficiency and robustness. The work demonstrates a practical solution for adapting large models using sensitive, distributed data without centralizing it.

- **[arXiv260105] Word Frequency Counting Based on Serverless MapReduce**
  - **tags:** [sys], [cloud computing], [serverless computing, MapReduce, Function as a Service (FaaS), word frequency counting]
  - **authors:** Hanzhe Li, Bingchen Lin, Mengyuan Xu
  - **institution:** Xi’an Jiaotong University, Chongqing University of Education, Qilu Institute of Technology
  - **link:** https://arxiv.org/pdf/2601.00380
  - **Simple LLM Summary:** This paper proposes using a serverless MapReduce model on a Function as a Service platform to optimize word frequency counting tasks. It experimentally determines the optimal number of map and reduce functions to minimize execution time and improve efficiency. The findings aim to help organizations and developers identify the most efficient configurations for such data processing workloads.

- **[arXiv260105] Revati: Transparent GPU-Free Time-Warp Emulation for LLM Serving**
  - **tags:** [mlsys], [llm inference], [time-warp emulation, CUDA API interception, discrete-event simulation, virtual time coordination]
  - **authors:** Amey Agrawal, Mayank Yadav, Sukrit Kumar, Anirudha Agrawal, Garv Ghai, Souradeep Bera, Elton Pinto, Sirish Gambhira, Mohammad Adain, Kasra Sohrab, Chus Antonanzas, Alexey Tumanov
  - **institution:** Georgia Institute of Technology
  - **link:** https://arxiv.org/pdf/2601.00397
  - **Simple LLM Summary:** The paper presents Revati, a time-warp emulator for LLM serving that runs real serving system code without physical GPUs by intercepting CUDA calls and fast-forwarding virtual time based on predicted kernel durations. It introduces a coordination protocol to synchronize time jumps across distributed processes. The system achieves less than 5% prediction error and runs 5-17x faster than real GPU execution on frameworks like vLLM and SGLang.

- **[arXiv260105] FlexSpec: Frozen Drafts Meet Evolving Targets in Edge-Cloud Collaborative LLM Speculative Decoding**
  - **tags:** [mlsys], [llm inference], [speculative decoding, edge-cloud collaboration, shared-backbone architecture, channel-aware adaptive speculation]
  - **authors:** Yuchen Li, Rui Kong, Zhonghao Lyu, Qiyang Li, Xinran Chen, Hengyi Cai, Lingyong Yan, Shuaiqiang Wang, Jiashu Zhao, Guangxu Zhu, Linghe Kong, Guihai Chen, Haoyi Xiong, Dawei Yin
  - **institution:** Baidu Inc., Shanghai Jiao Tong University, KTH Royal Institute of Technology, Wilfrid Laurier University, Shenzhen Research Institute of Big Data
  - **link:** https://arxiv.org/pdf/2601.00644
  - **Simple LLM Summary:** The paper proposes FlexSpec, a framework for edge-cloud collaborative LLM inference that uses a static, shared-backbone draft model at the edge to remain compatible with evolving cloud target models, eliminating frequent retraining and downloads. It also introduces a channel-aware mechanism to dynamically adjust the speculative draft length. Experiments show it achieves superior inference efficiency compared to conventional speculative decoding approaches.

- **[arXiv260105] Bio-inspired Agentic Self-healing Framework for Resilient Distributed Computing Continuum Systems**
  - **tags:** [mlsys], [fault-tolerance], [bio-inspired framework, multi-agent systems, language model agents, self-healing, distributed computing continuum]
  - **authors:** Alaa Saleh, Praveen Kumar Donta, Roberto Morabito, Sasu Tarkoma, Anders Lindgren, Qiyang Zhang, Schahram Dustdar Susanna Pirttikangas, Lauri Lovén
  - **institution:** University of Oulu, Stockholm University, EURECOM, University of Helsinki, RISE Research Institutes of Sweden, Luleå University of Technology, Peking University, TU Wien
  - **link:** https://arxiv.org/pdf/2601.00339
  - **Simple LLM Summary:** This paper proposes ReCiSt, a bio-inspired, agentic self-healing framework for Distributed Computing Continuum Systems. It uses Language Model-powered agents across four computational layers to autonomously isolate faults, diagnose causes, adaptively recover, and consolidate knowledge. The evaluation demonstrates the framework's capability to perform self-healing within tens of seconds with minimal resource overhead.


**cs.AI/cs.LG contains "reinforcement learning" total: 15**
- [arXiv260105] Modern Neuromorphic AI: From Intra-Token to Inter-Token Processing [link](https://arxiv.org/pdf/2601.00245)
- [arXiv260105] Reinforcement learning with timed constraints for robotics motion planning [link](https://arxiv.org/pdf/2601.00087)
- [arXiv260105] Precision Autotuning for Linear Solvers via Contextual Bandit-Based RL [link](https://arxiv.org/pdf/2601.00728)
- [arXiv260105] Reinforcement-Learned Unequal Error Protection for Quantized Semantic Embeddings [link](https://arxiv.org/pdf/2601.00186)
- [arXiv260105] Parametrized Sharing for Multi-Agent Hybrid DRL for Multiple Multi-Functional RISs-Aided Downlink NOMA Networks [link](https://arxiv.org/pdf/2601.00538)
- [arXiv260105] Next Generation Intelligent Low-Altitude Economy Deployments: The O-RAN Perspective [link](https://arxiv.org/pdf/2601.00257)
- [arXiv260105] Online Finetuning Decision Transformers with Pure RL Gradients [link](https://arxiv.org/pdf/2601.00167)
- [arXiv260105] Can Optimal Transport Improve Federated Inverse Reinforcement Learning? [link](https://arxiv.org/pdf/2601.00309)
- [arXiv260105] IRPO: Scaling the Bradley-Terry Model via Reinforcement Learning [link](https://arxiv.org/pdf/2601.00677)
- [arXiv260105] Reinforcement Learning with Function Approximation for Non-Markov Processes [link](https://arxiv.org/pdf/2601.00151)
- [arXiv260105] Stochastic Actor-Critic: Mitigating Overestimation via Temporal Aleatoric Uncertainty [link](https://arxiv.org/pdf/2601.00737)
- [arXiv260105] ARISE: Adaptive Reinforcement Integrated with Swarm Exploration [link](https://arxiv.org/pdf/2601.00693)
- [arXiv260105] Traffic-Aware Optimal Taxi Placement Using Graph Neural Network-Based Reinforcement Learning [link](https://arxiv.org/pdf/2601.00607)
- [arXiv260105] GRL-SNAM: Geometric Reinforcement Learning with Path Differential Hamiltonians for Simultaneous Navigation and Mapping in Unknown Environments [link](https://arxiv.org/pdf/2601.00116)
- [arXiv260105] E-GRPO: High Entropy Steps Drive Effective Reinforcement Learning for Flow Models [link](https://arxiv.org/pdf/2601.00423)

**cs.AI/cs.LG contains "accelerate" total: 1**
- [arXiv260105] Can Large Language Models Still Explain Themselves? Investigating the Impact of Quantization on Self-Explanations [link](https://arxiv.org/pdf/2601.00282)

## 2026-01-06

**cs.DC total: 19**

- **[arXiv260106] A Multi-Port Concurrent Communication Model for handling Compute Intensive Tasks on Distributed Satellite System Constellations**
  - **tags:** [sys], [distributed satellite systems], [divisible load theory, multi-port concurrent communication, optimal load allocation, admission control, inter-satellite links]
  - **authors:** Bharadwaj Veeravalli
  - **institution:** National University of Singapore
  - **link:** https://arxiv.org/pdf/2601.01031
  - **Simple LLM Summary:** This paper proposes a Multi-Port Concurrent Communication Divisible Load Theory (MPCC-DLT) framework for scheduling compute-intensive tasks across distributed satellite constellations. It provides closed-form solutions for optimal load distribution and analyzes the trade-offs between computation and communication overhead. The main conclusion is that the framework enables latency reduction for distributable tasks and offers design insights for scheduling and sizing satellite clusters to meet deadlines.

- **[arXiv260106] Communication-Efficient Federated AUC Maximization with Cyclic Client Participation**
  - **tags:** [mlsys], [others], [federated learning, AUC maximization, cyclic client participation, Polyak-Łojasiewicz condition, minimax optimization, communication complexity]
  - **authors:** Umesh Vangapally, Wenhan Wu, Chen Chen, Zhishuai Guo
  - **institution:** Northern Illinois University, University of North Carolina at Charlotte, University of Central Florida
  - **link:** https://arxiv.org/pdf/2601.01649
  - **Simple LLM Summary:** This paper develops communication-efficient federated learning algorithms for AUC maximization under realistic cyclic client participation. It achieves state-of-the-art communication complexity by reformulating the problem as a minimax optimization and leveraging the Polyak-Łojasiewicz condition. Experiments show the methods are efficient and effective for imbalanced data tasks like image classification and fraud detection.

- **[arXiv260106] Performance and Security Aware Distributed Service Placement in Fog Computing**
  - **tags:** [mlsys], [others], [Deep Reinforcement Learning, Long Short-Term Memory networks, Prioritized Experience Replay, off-policy correction, multi-objective optimization, three-tier security hierarchy]
  - **authors:** Mohammad Goudarzi, Arash Shaghaghi, Zhiyu Wang, Rajkumar Buyya
  - **institution:** Monash University, The University of New South Wales
  - **link:** https://arxiv.org/pdf/2601.01125
  - **Simple LLM Summary:** This paper proposes a Security and Performance-Aware Distributed Deep Reinforcement Learning (SPA-DDRL) framework for service placement in Fog computing. The method jointly optimizes latency and security using a distributed broker-learner architecture with LSTM and experience replay. The experiments show it improves response time by 16.3% and converges 33% faster than baseline approaches.

- **[arXiv260106] FFCz: Fast Fourier Correction for Spectrum-Preserving Lossy Compression of Scientific Data**
  - **tags:** [sys], [scientific data compression], [fast Fourier correction, error-bounded lossy compression, GPU parallelism, SZ3, ZFP, SPERR]
  - **authors:** Congrong Ren, Robert Underwood, Sheng Di, Emrecan Kutay, Zarija Lukic, Aylin Yener, Franck Cappello, Hanqi Guo
  - **institution:** The Ohio State University, Argonne National Laboratory, Lawrence Berkeley National Laboratory
  - **link:** https://arxiv.org/pdf/2601.01596
  - **Simple LLM Summary:** This paper proposes FFCz, a fast Fourier correction algorithm that modifies the error from existing lossy compressors to preserve both spatial and frequency domain accuracy. It iteratively projects spatial errors to satisfy user-defined bounds in both domains and uses GPU acceleration for performance. The method effectively maintains critical spectral features in scientific data from fields like cosmology and combustion.

- **[arXiv260106] Making MoE based LLM inference resilient with Tarragon**
  - **tags:** [mlsys], [fault-tolerance], [mixture-of-experts, KV cache checkpointing, shadow experts, reconfigurable datapath, asynchronous recovery]
  - **authors:** Songyu Zhang, Aaron Tam, Myungjin Lee, Shixiong Qi, K. K. Ramakrishnan
  - **institution:** UC Riverside, Cisco Research, University of Kentucky
  - **link:** https://arxiv.org/pdf/2601.01310
  - **Simple LLM Summary:** This paper presents Tarragon, a resilient inference framework for Mixture-of-Experts LLMs that confines failures to individual workers. It introduces a reconfigurable datapath to mask failures and self-healing mechanisms like asynchronous KV cache checkpointing and shadow experts to minimize recovery overhead. The evaluation shows Tarragon reduces failure-induced stalls by 160-213x compared to prior systems while maintaining performance during normal operation.

- **[arXiv260106] RelayGR: Scaling Long-Sequence Generative Recommendation via Cross-Stage Relay-Race Inference**
  - **tags:** [mlsys], [llm inference], [KV cache, cross-stage relay-race inference, sequence-aware trigger, affinity-aware router, memory-aware expander, HBM caching]
  - **authors:** Jiarui Wang, Huichao Chai, Yuanhang Zhang, Zongjin Zhou, Wei Guo, Xingkun Yang, Qiang Tang, Bo Pan, Jiawei Zhu, Ke Cheng, Yuting Yan, Shulan Wang, Yingjie Zhu, Zhengfan Yuan, Jiaqi Huang, Yuhan Zhang, Xiaosong Sun, Zhinan Zhang, Hong Zhu, Yongsheng Zhang, Tiantian Dong, Zhong Xiao, Deliang Liu, Chengzhou Lu, Yuan Sun, Zhiyuan Chen, Xinming Han, Zaizhu Liu, Yaoyuan Wang, Ziyang Zhang, Yong Liu, Jinxin Xu, Yajing Sun, Zhoujun Yu, Wenting Zhou, Qidong Zhang, Zhengyong Zhang, Zhonghai Gu, Yibo Jin, Yongxiang Feng, Pengfei Zuo
  - **institution:** Huawei Technologies Co., Ltd.
  - **link:** https://arxiv.org/pdf/2601.01712
  - **Simple LLM Summary:** RelayGR is a system that scales generative recommendation by pre-inferring and caching user-behavior sequence prefixes in HBM, then reusing them during ranking via coordinated routing and caching techniques. This approach allows for longer sequence lengths and higher throughput while meeting strict latency SLOs. The system was implemented on Huawei Ascend NPUs and demonstrated significant improvements in sequence length and throughput under production constraints.

- **[arXiv260106] OrchestrRL: Dynamic Compute and Network Orchestration for Disaggregated RL**
  - **tags:** [mlsys], [post-training], [disaggregated RL, adaptive compute scheduler, reconfigurable hybrid optical-electrical fabric, RFabric, RLSim, parallelism switching, workload-aware circuits]
  - **authors:** Xin Tan, Yicheng Feng, Yu Zhou, Yimin Jiang, Yibo Zhu, Hong Xu
  - **institution:** The Chinese University of Hong Kong, StepFun
  - **link:** https://arxiv.org/pdf/2601.01209
  - **Simple LLM Summary:** This paper introduces OrchestrRL, a framework that dynamically orchestrates compute and network resources for disaggregated reinforcement learning (RL) pipelines. It uses an adaptive compute scheduler to balance workloads and co-designs a reconfigurable network fabric (RFabric) to handle dynamic traffic. The system demonstrates up to 1.40x throughput improvement on a 48-GPU testbed and shows superior performance-cost efficiency compared to static networks.

- **[arXiv260106] DiT-HC: Enabling Efficient Training of Visual Generation Model DiT on HPC-oriented CPU Cluster**
  - **tags:** [mlsys], [diffusion training], [communication-free tensor parallelism, AutoMem, HCOps, custom MPI backend, weak scaling]
  - **authors:** Jinxiao Zhang, Yunpu Xu, Xiyong Wu, Runmin Dong, Shenggan Cheng, Yi Zhao, Mengxuan Chen, Qinrui Zheng, Jianting Liu, Haohuan Fu
  - **institution:** Tsinghua University, Sun Yat-sen University, National University of Singapore, National Supercomputing Center in Shenzhen
  - **link:** https://arxiv.org/pdf/2601.01500
  - **Simple LLM Summary:** DiT-HC introduces three techniques—communication-free tensor parallelism with AutoMem, optimized GEMM kernels (HCOps), and a custom MPI backend—to efficiently train the DiT generative model on HPC CPU clusters. The system achieves up to 87.7× speedups over baseline CPU libraries and 90.6% weak scaling efficiency on 256 nodes, demonstrating the feasibility of large-scale generative model training on CPU-based HPC infrastructure.

- **[arXiv260106] Warp-Cortex: An Asynchronous, Memory-Efficient Architecture for Million-Agent Cognitive Scaling on Consumer Hardware**
  - **tags:** [mlsys], [llm inference], [singleton weight sharing, topological synapse, kv-cache sparsification, witness complex, referential injection, topological data analysis]
  - **authors:** Jorge L. Ruiz Williams
  - **institution:** Warp Research
  - **link:** https://arxiv.org/pdf/2601.01298
  - **Simple LLM Summary:** The paper introduces Warp Cortex, an asynchronous architecture that enables massive multi-agent LLM scaling on consumer hardware by sharing a single model instance and using topological data analysis to sparsify the KV-cache. This reduces memory complexity from O(N*L) to O(1) for weights and O(N*k) for context. The authors demonstrate 100 concurrent agents on a single GPU and claim theoretical scaling to thousands of agents.

- **[arXiv260106] pMSz: A Distributed Parallel Algorithm for Correcting Extrema and Morse Smale Segmentations in Lossy Compression**
  - **tags:** [sys], [high-performance computing], [distributed parallel algorithm, Morse-Smale segmentation, lossy compression, topological feature correction, integral paths, GPU, Perlmutter]
  - **authors:** Yuxiao Li, Mingze Xia, Xin Liang, Bei Wang, Robert Underwood, Sheng Di, Hemant Sharma, Dishant Beniwal, Franck Cappello, Hanqi Guo
  - **institution:** The Ohio State University, Argonne National Laboratory, Oregon State University, University of Utah
  - **link:** https://arxiv.org/pdf/2601.01787
  - **Simple LLM Summary:** This paper introduces pMSz, a distributed parallel algorithm that corrects topological distortions in lossy-compressed scientific data by preserving steepest ascending and descending directions instead of explicitly computing integral paths. The method minimizes communication and achieves over 90% parallel efficiency on 128 GPUs, enabling scalable correction of Morse-Smale segmentations for extreme-scale datasets.

- **[arXiv260106] Cutting Quantum Circuits Beyond Qubits**
  - **tags:** [ai], [quantum computing], [circuit cutting, qudits, Gell-Mann matrices, distributed quantum computing, heterogeneous registers]
  - **authors:** Manav Seksaria, Anil Prabhakar
  - **institution:** Indian Institute of Technology Madras
  - **link:** https://arxiv.org/pdf/2601.02064
  - **Simple LLM Summary:** This paper extends quantum circuit cutting to mixed-dimensional qudit systems by decomposing non-local interactions using generalized Gell-Mann matrices, enabling simulation on disconnected hardware. The method is validated on qubit-qutrit interfaces with exact state reconstruction and demonstrates significant memory reduction for high-dimensional circuits.

- **[arXiv260106] Tackling Resource-Constrained and Data-Heterogeneity in Federated Learning with Double-Weight Sparse Pack**
  - **tags:** [mlsys], [others], [federated learning, personalized federated learning, cosine sparsification, parameter packing, dual-weighted aggregation, sparse updates, non-iid data]
  - **authors:** Qiantao Yang, Liquan Chen, Mingfu Xue, Songze Li
  - **institution:** Southeast University, Purple Mountain Laboratories, East China Normal University
  - **link:** https://arxiv.org/pdf/2601.01840
  - **Simple LLM Summary:** The paper proposes FedCSPACK, a personalized federated learning method that uses cosine similarity to sparsify and pack model parameters for efficient communication, and employs a dual-weighted aggregation mechanism to handle data heterogeneity. Experiments show that this approach improves communication and computational efficiency while maintaining high model accuracy in resource-constrained, non-IID environments.

- **[arXiv260106] Vouchsafe: A Zero-Infrastructure Capability Graph Model for Offline Identity and Trust**
  - **tags:** [sys], [identity and trust systems], [Ed25519, SHA-256, JSON Web Tokens, capability graph, offline verification]
  - **authors:** Jay Kuri
  - **institution:** Ionzero Inc.
  - **link:** https://arxiv.org/pdf/2601.02254
  - **Simple LLM Summary:** This paper introduces Vouchsafe, a system based on the Zero-Infrastructure Capability Graph (ZI-CG) model, which uses self-contained, signed statements (built with Ed25519, SHA-256, and JWTs) to represent identity, delegation, and revocation. It concludes that a practical, offline-verifiable trust substrate can be constructed without relying on any online infrastructure or new cryptographic primitives.

- **[arXiv260106] Deciding Serializability in Network Systems**
  - **tags:** [sys], [concurrent systems verification], [SER modeling language, Petri net reachability, semilinear-set compression, Presburger-formula manipulation, network-system abstraction]
  - **authors:** Guy Amir, Mark Barbone, Nicolas Amat, Jules Jacobs
  - **institution:** Cornell University, ONERA, Jane Street Capital
  - **link:** https://arxiv.org/pdf/2601.02251
  - **Simple LLM Summary:** This paper introduces the SER modeling language and an automated decision procedure for verifying serializability in concurrent programs by compiling them to a network-system abstraction and reducing the problem to Petri net reachability. The method uses optimizations like Petri net slicing and semilinear-set compression to scale. The authors demonstrate that their framework can successfully verify models of real-world systems like stateful firewalls and BGP routers.

- **[arXiv260106] BigSUMO: A Scalable Framework for Big Data Traffic Analytics and Parallel Simulation**
  - **tags:** [mlsys], [cluster infrastructure], [SUMO microsimulator, parallel simulation, descriptive analytics, prescriptive analytics, interruption detection, ATSPM data, probe trajectory data]
  - **authors:** Rahul Sengupta, Nooshin Yousefzadeh, Manav Sanghvi, Yash Ranjan, Anand Rangarajan, Sanjay Ranka, Yashaswi Karnati, Jeremy Dilmore, Tushar Patel, Ryan Casburn
  - **institution:** University of Florida, NVIDIA Corp., Florida Department of Transportation (FDOT)
  - **link:** https://arxiv.org/pdf/2601.02286
  - **Simple LLM Summary:** The paper presents BigSUMO, a scalable, open-source framework that ingests traffic sensor data, performs descriptive analytics and interruption detection, and uses parallel SUMO microsimulations for prescriptive what-if scenario testing. It concludes that this end-to-end system is a cost-effective and deployable tool for traffic management and smart city mobility solutions.

- **[arXiv260106] Placement Semantics for Distributed Deep Learning: A Systematic Framework for Analyzing Parallelism Strategies**
  - **tags:** [mlsys], [llm training], [placement semantics, data parallelism, tensor parallelism, pipeline parallelism, ZeRO, FSDP, memory consumption, communication volume]
  - **authors:** Deep Pankajbhai Mehta
  - **institution:** Adobe Inc.
  - **link:** https://arxiv.org/pdf/2601.02311
  - **Simple LLM Summary:** The paper introduces "placement semantics," a systematic framework that analyzes distributed deep learning parallelism strategies by specifying how training states (parameters, optimizer, gradients, activations) are placed across devices. From this specification alone, it derives memory consumption and communication volume, unifying strategies like ZeRO, FSDP, tensor, and pipeline parallelism. The framework's predictions match published results, and it provides necessary conditions and composition rules for correct distributed training.

- **[arXiv260106] Benchmarking Quantum Data Center Architectures: A Performance and Scalability Perspective**
  - **tags:** [sys], [quantum computing systems], [quantum data center, distributed quantum computing, entanglement generation, teleportation, Bell State Measurement, QFly, BCube, Clos, Fat-Tree]
  - **authors:** Shahrooz Pouryousef, Eneet Kaur, Hassan Shapourian, Don Towsley, Ramana Kompella, Reza Nejabati
  - **institution:** Cisco Research, University of Massachusetts Amherst
  - **link:** https://arxiv.org/pdf/2601.01353
  - **Simple LLM Summary:** This paper systematically benchmarks four quantum data center architectures (QFly, BCube, Clos, Fat-Tree) under realistic quantum hardware constraints like optical loss and coherence limits. It finds that distributed quantum performance is shaped by a complex interaction of topology, scheduling, and physical-layer parameters. These insights provide quantitative guidance for designing scalable, high-performance quantum data centers.

- **[arXiv260106] SuperSFL: Resource-Heterogeneous Federated Split Learning with Weight-Sharing Super-Networks**
  - **tags:** [mlsys], [fault-tolerance], [weight-sharing super-network, three-phase gradient fusion (TPGF), federated split learning, resource-aware subnetwork generation, client-server aggregation]
  - **authors:** Abdullah Al Asif, Sixing Yu, Juan Pablo Munoz, Arya Mazaheri, Ali Jannesari
  - **institution:** Iowa State University, Intel Corporation, Technical University of Darmstadt
  - **link:** https://arxiv.org/pdf/2601.02092
  - **Simple LLM Summary:** This paper proposes SuperSFL, a federated split learning framework that uses a weight-sharing super-network to generate client-specific subnetworks, addressing device heterogeneity. It introduces a Three-Phase Gradient Fusion mechanism and fault-tolerant components to accelerate convergence and handle communication failures. Experiments show SuperSFL converges 2-5x faster with up to 20x lower communication cost than baseline methods.

- **[arXiv260106] Bringing computation to the data: A MOEA-driven approach for optimising data processing in the context of the SKA and SRCNet**
  - **tags:** [mlsys], [cluster infrastructure], [Function-as-a-Service (FaaS), Multi-Objective Evolutionary Algorithms (MOEAs), distributed computing, in-situ processing, data-intensive workflows]
  - **authors:** Manuel Parra-Royón, Álvaro Rodríguez-Gallardo, Susana Sánchez-Expósito, Laura Darriba-Pol, Jesús Sánchez-Castañeda, M. Ángeles Mendoza, Julián Garrido, Javier Moldón, Lourdes Verdes-Montenegro
  - **institution:** Instituto de Astrofísica de Andalucía, IAA-CSIC
  - **link:** https://arxiv.org/pdf/2601.01980
  - **Simple LLM Summary:** This paper proposes a framework that integrates Function-as-a-Service (FaaS) with a decision-making entity based on Multi-Objective Evolutionary Algorithms (MOEAs) to optimize data processing for the SKA telescope. The approach moves computation closer to the data to mitigate network bottlenecks, aiming to find near-optimal execution plans that balance execution time and energy consumption. The work establishes a baseline for efficient, cost-aware computation-to-data strategies within the SKA Regional Centres Network (SRCNet).


**cs.AI/cs.LG contains "reinforcement learning" total: 22**
- [arXiv260106] SmartFlow Reinforcement Learning and Agentic AI for Bike-Sharing Optimisation [link](https://arxiv.org/pdf/2601.00868)
- [arXiv260106] Adversarial Instance Generation and Robust Training for Neural Combinatorial Optimization with Multiple Objectives [link](https://arxiv.org/pdf/2601.01665)
- [arXiv260106] Logics-STEM: Empowering LLM Reasoning via Failure-Driven Post-Training and Document Knowledge Enhancement [link](https://arxiv.org/pdf/2601.01562)
- [arXiv260106] Horizon Reduction as Information Loss in Offline Reinforcement Learning [link](https://arxiv.org/pdf/2601.00831)
- [arXiv260106] SRAS: A Lightweight Reinforcement Learning-based Document Selector for Edge-Native RAG Pipelines [link](https://arxiv.org/pdf/2601.01785)
- [arXiv260106] Dichotomous Diffusion Policy Optimization [link](https://arxiv.org/pdf/2601.00898)
- [arXiv260106] PyBatchRender: A Python Library for Batched 3D Rendering at Up to One Million FPS [link](https://arxiv.org/pdf/2601.01288)
- [arXiv260106] HanoiWorld : A Joint Embedding Predictive Architecture BasedWorld Model for Autonomous Vehicle Controller [link](https://arxiv.org/pdf/2601.01577)
- [arXiv260106] Sparse Threats, Focused Defense: Criticality-Aware Robust Reinforcement Learning for Safe Autonomous Driving [link](https://arxiv.org/pdf/2601.01800)
- [arXiv260106] PsychEval: A Multi-Session and Multi-Therapy Benchmark for High-Realism and Comprehensive AI Psychological Counselor [link](https://arxiv.org/pdf/2601.01802)
- [arXiv260106] Moments Matter:Stabilizing Policy Optimization using Return Distributions [link](https://arxiv.org/pdf/2601.01803)
- [arXiv260106] Evaluating Feature Dependent Noise in Preference-based Reinforcement Learning [link](https://arxiv.org/pdf/2601.01904)
- [arXiv260106] Distorted Distributional Policy Evaluation for Offline Reinforcement Learning [link](https://arxiv.org/pdf/2601.01917)
- [arXiv260106] GDRO: Group-level Reward Post-training Suitable for Diffusion Models [link](https://arxiv.org/pdf/2601.02036)
- [arXiv260106] Higher-Order Action Regularization in Deep Reinforcement Learning: From Continuous Control to Building Energy Management [link](https://arxiv.org/pdf/2601.02061)
- [arXiv260106] MDAgent2: Large Language Model for Code Generation and Knowledge Q&A in Molecular Dynamics [link](https://arxiv.org/pdf/2601.02075)
- [arXiv260106] Entropy-Adaptive Fine-Tuning: Resolving Confident Conflicts to Mitigate Forgetting [link](https://arxiv.org/pdf/2601.02151)
- [arXiv260106] ACDZero: Graph-Embedding-Based Tree Search for Mastering Automated Cyber Defense [link](https://arxiv.org/pdf/2601.02196)
- [arXiv260106] CORE: Code-based Inverse Self-Training Framework with Graph Expansion for Virtual Agents [link](https://arxiv.org/pdf/2601.02201)
- [arXiv260106] NextFlow: Unified Sequential Modeling Activates Multimodal Understanding and Generation [link](https://arxiv.org/pdf/2601.02204)
- [arXiv260106] VAR RL Done Right: Tackling Asynchronous Policy Conflicts in Visual Autoregressive Generation [link](https://arxiv.org/pdf/2601.02256)
- [arXiv260106] Reinforcement Learning for Option Hedging: Static Implied-Volatility Fit versus Shortfall-Aware Performance [link](https://arxiv.org/pdf/2601.01709)

**cs.AI/cs.LG contains "accelerate" total: 17**
- [arXiv260106] Promptable Foundation Models for SAR Remote Sensing: Adapting the Segment Anything Model for Snow Avalanche Segmentation [link](https://arxiv.org/pdf/2601.01213)
- [arXiv260106] Digital Twin-Driven Communication-Efficient Federated Anomaly Detection for Industrial IoT [link](https://arxiv.org/pdf/2601.01701)
- [arXiv260106] UltraEval-Audio: A Unified Framework for Comprehensive Evaluation of Audio Foundation Models [link](https://arxiv.org/pdf/2601.01373)
- [arXiv260106] Accelerated Full Waveform Inversion by Deep Compressed Learning [link](https://arxiv.org/pdf/2601.01268)
- [arXiv260106] Accelerating Decentralized Optimization via Overlapping Local Steps [link](https://arxiv.org/pdf/2601.01493)
- [arXiv260106] RovoDev Code Reviewer: A Large-Scale Online Evaluation of LLM-based Code Review Automation at Atlassian [link](https://arxiv.org/pdf/2601.01129)
- [arXiv260106] Efficient Cover Construction for Ball Mapper via Accelerated Range Queries [link](https://arxiv.org/pdf/2601.01405)
- [arXiv260106] Generating Diverse TSP Tours via a Combination of Graph Pointer Network and Dispersion [link](https://arxiv.org/pdf/2601.01132)
- [arXiv260106] FastV-RAG: Towards Fast and Fine-Grained Video QA with Retrieval-Augmented Generation [link](https://arxiv.org/pdf/2601.01513)
- [arXiv260106] Adaptive Hybrid Optimizer based Framework for Lumpy Skin Disease Identification [link](https://arxiv.org/pdf/2601.01807)
- [arXiv260106] Yukthi Opus: A Multi-Chain Hybrid Metaheuristic for Large-Scale NP-Hard Optimization [link](https://arxiv.org/pdf/2601.01832)
- [arXiv260106] FormuLLA: A Large Language Model Approach to Generating Novel 3D Printable Formulations [link](https://arxiv.org/pdf/2601.02071)
- [arXiv260106] Quantized SO(3)-Equivariant Graph Neural Networks for Efficient Molecular Property Prediction [link](https://arxiv.org/pdf/2601.02213)
- [arXiv260106] Neuro-Channel Networks: A Multiplication-Free Architecture by Biological Signal Transmission [link](https://arxiv.org/pdf/2601.02253)
- [arXiv260106] Physically-Constrained Autoencoder-Assisted Bayesian Optimization for Refinement of High-Dimensional Defect-Sensitive Single Crystalline Structure [link](https://arxiv.org/pdf/2601.00855)
- [arXiv260106] Learning Relationship between Quantum Walks and Underdamped Langevin Dynamics [link](https://arxiv.org/pdf/2601.01589)
- [arXiv260106] Predicting Early and Complete Drug Release from Long-Acting Injectables Using Explainable Machine Learning [link](https://arxiv.org/pdf/2601.02265)
