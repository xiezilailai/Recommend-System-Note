# 20260112-20260118

## 2026-01-12

**cs.DC total: 5**

- **[arXiv260112] LACIN: Linearly Arranged Complete Interconnection Networks**
  - **tags:** [sys], [interconnection networks], [complete graph, dragonfly, hyperx, isoport, wiring, routing]
  - **authors:** Ramón Beivide, Cristóbal Camarero, Carmen Martínez, Enrique Vallejo, Mateo Valero
  - **institution:** Universidad de Cantabria, Barcelona Supercomputing Center
  - **link:** https://arxiv.org/pdf/2601.05668
  - **Simple LLM Summary:** This paper introduces LACIN, a method for implementing complete interconnection networks by linking switches using identically indexed ports (isoport). This approach simplifies network cabling and routing complexity. It facilitates the deployment of scalable networks for parallel computers, from VLSI systems to large supercomputers.

- **[arXiv260112] MoEBlaze: Breaking the Memory Wall for Efficient MoE Training on Modern GPUs**
  - **tags:** [mlsys], [llm training], [Mixture-of-Experts (MoE), memory-efficient training, token dispatch, co-designed kernels, activation checkpointing, memory wall]
  - **authors:** Jiyuan Zhang, Yining Liu, Siqi Yan, Lisen Deng, Jennifer Cao, Shuqi Yang, Min Ni, Bi Xue, Shen Li
  - **institution:** Meta Platforms Inc, Thinking Machines Lab
  - **link:** https://arxiv.org/pdf/2601.05296
  - **Simple LLM Summary:** The paper presents MoEBlaze, a memory-efficient training framework for Mixture-of-Experts (MoE) models. It uses an end-to-end token dispatch method with optimized data structures and co-designed kernels with smart activation checkpointing to reduce memory overhead. The authors demonstrate that MoEBlaze achieves over 4x speedups and over 50% memory savings compared to existing frameworks.

- **[arXiv260112] Multi-Modal Style Transfer-based Prompt Tuning for Efficient Federated Domain Generalization**
  - **tags:** [mlsys], [multi-modal training], [multi-modal style transfer, prompt tuning, federated domain generalization, dual-prompt module, domain-aware prompt generation]
  - **authors:** Yuliang Chen, Xi Lin, Jun Wu, Xiangrui Cai, Qiaolun Zhang, Xichun Fan, Jiapeng Xu, Xiu Su
  - **institution:** Shanghai Jiao Tong University, Nankai University, Polytechnic Institute of Milan, New York University Shanghai, Central South University
  - **link:** https://arxiv.org/pdf/2601.05955
  - **Simple LLM Summary:** This paper proposes FaST-PT, a federated domain generalization framework that uses a lightweight multi-modal style transfer method for local feature augmentation and a dual-prompt module with domain-aware generation for efficient adaptation to unseen domains. Experiments on benchmark datasets show it outperforms state-of-the-art methods in performance and efficiency.

- **[arXiv260112] Self-Evolving Distributed Memory Architecture for Scalable AI Systems**
  - **tags:** [mlsys], [cluster infrastructure], [memory-guided matrix processing, memory-aware peer selection, runtime-adaptive deployment, dual-memory architecture, dynamic partitioning]
  - **authors:** Zixuan Li, Chuanzhen Wang, Haotian Sun
  - **institution:** Tongji University, Pacific Coast University, Northern Research Laboratory
  - **link:** https://arxiv.org/pdf/2601.05569
  - **Simple LLM Summary:** This paper introduces a three-layer framework for unified memory management across computation, communication, and deployment in distributed AI systems. The core method includes dynamic memory partitioning, topology-aware peer selection, and continuous runtime reconfiguration, supported by a dual-memory system. The experiments show it achieves higher memory utilization, throughput, and lower latency compared to a baseline like Ray Distributed.

- **[arXiv260112] Performance-Portable Optimization and Analysis of Multiple Right-Hand Sides in a Lattice QCD Solver**
  - **tags:** [sys], [high-performance computing], [multiple right-hand sides, SIMD, auto-vectorization, GMRES, DD-αAMG, performance portability, SME]
  - **authors:** Shiting Long, Gustavo Ramirez-Hidalgo, Stepan Nassyr, Jose Jimenez-Merchan, Andreas Frommer, Dirk Pleiter
  - **institution:** KTH Royal Institute of Technology, Forschungszentrum Jülich GmbH, University of Wuppertal, University of Groningen
  - **link:** https://arxiv.org/pdf/2601.05816
  - **Simple LLM Summary:** The paper extends the lattice QCD solver DD-αAMG by implementing multiple right-hand sides and optimizing data layouts for better SIMD utilization, aiming to improve performance portability across x86 and Arm architectures. It demonstrates that these optimizations yield similar speedups on different hardware platforms, while also providing an early assessment of the Arm SME instruction set. The performance analysis reveals the complexity introduced by architectural constraints and compiler behavior.


**cs.AI/cs.LG contains "reinforcement learning" total: 19**
- [arXiv260112] Sequential Bayesian Optimal Experimental Design in Infinite Dimensions via Policy Gradient Reinforcement Learning [link](https://arxiv.org/pdf/2601.05868)
- [arXiv260112] MaxCode: A Max-Reward Reinforcement Learning Framework for Automated Code Optimization [link](https://arxiv.org/pdf/2601.05475)
- [arXiv260112] Autonomous Discovery of the Ising Model's Critical Parameters with Reinforcement Learning [link](https://arxiv.org/pdf/2601.05577)
- [arXiv260112] WildSci: Advancing Scientific Reasoning from In-the-Wild Literature [link](https://arxiv.org/pdf/2601.05567)
- [arXiv260112] Intelligent Singularity Avoidance in UR10 Robotic Arm Path Planning Using Hybrid Fuzzy Logic and Reinforcement Learning [link](https://arxiv.org/pdf/2601.05836)
- [arXiv260112] IIB-LPO: Latent Policy Optimization via Iterative Information Bottleneck [link](https://arxiv.org/pdf/2601.05870)
- [arXiv260112] Thinking with Map: Reinforced Parallel Map-Augmented Agent for Geolocalization [link](https://arxiv.org/pdf/2601.05432)
- [arXiv260112] StackPlanner: A Centralized Hierarchical Multi-Agent System with Task-Experience Memory Management [link](https://arxiv.org/pdf/2601.05890)
- [arXiv260112] TowerMind: A Tower Defence Game Learning Environment and Benchmark for LLM as Agents [link](https://arxiv.org/pdf/2601.05899)
- [arXiv260112] Reinforcement Learning of Large Language Models for Interpretable Credit Card Fraud Detection [link](https://arxiv.org/pdf/2601.05578)
- [arXiv260112] PaCoRe: Learning to Scale Test-Time Compute with Parallel Coordinated Reasoning [link](https://arxiv.org/pdf/2601.05593)
- [arXiv260112] Orchestrating Tokens and Sequences: Dynamic Hybrid Policy Optimization for RLVR [link](https://arxiv.org/pdf/2601.05607)
- [arXiv260112] From Off-Policy to On-Policy: Enhancing GUI Agents via Bi-level Expert-to-Policy Assimilation [link](https://arxiv.org/pdf/2601.05787)
- [arXiv260112] Do LLMs Need Inherent Reasoning Before Reinforcement Learning? A Study in Korean Self-Correction [link](https://arxiv.org/pdf/2601.05459)
- [arXiv260112] EnvScaler: Scaling Tool-Interactive Environments for LLM Agent via Programmatic Synthesis [link](https://arxiv.org/pdf/2601.05808)
- [arXiv260112] On the Limits of Self-Improving in LLMs and Why AGI, ASI and the Singularity Are Not Near Without Symbolic Model Synthesis [link](https://arxiv.org/pdf/2601.05280)
- [arXiv260112] KP-Agent: Keyword Pruning in Sponsored Search Advertising via LLM-Powered Contextual Bandits [link](https://arxiv.org/pdf/2601.05257)
- [arXiv260112] Dual-Phase LLM Reasoning: Self-Evolved Mathematical Frameworks [link](https://arxiv.org/pdf/2601.05616)
- [arXiv260112] PRISMA: Reinforcement Learning Guided Two-Stage Policy Optimization in Multi-Agent Architecture for Open-Domain Multi-Hop Question Answering [link](https://arxiv.org/pdf/2601.05465)

**cs.AI/cs.LG contains "accelerate" total: 9**
- [arXiv260112] Tracing Stereotypes in Pre-trained Transformers: From Biased Neurons to Fairer Models [link](https://arxiv.org/pdf/2601.05663)
- [arXiv260112] Interactive Distillation for Cooperative Multi-Agent Reinforcement Learning [link](https://arxiv.org/pdf/2601.05407)
- [arXiv260112] DNATokenizer: A GPU-First Byte-to-Identifier Tokenizer for High-Throughput DNA Language Models [link](https://arxiv.org/pdf/2601.05531)
- [arXiv260112] Can We Predict Before Executing Machine Learning Agents? [link](https://arxiv.org/pdf/2601.05930)
- [arXiv260112] FLRQ: Faster LLM Quantization with Flexible Low-Rank Matrix Sketching [link](https://arxiv.org/pdf/2601.05684)
- [arXiv260112] A Survey of Agentic AI and Cybersecurity: Challenges, Opportunities and Use-case Prototypes [link](https://arxiv.org/pdf/2601.05293)
- [arXiv260112] PaCoRe: Learning to Scale Test-Time Compute with Parallel Coordinated Reasoning [link](https://arxiv.org/pdf/2601.05593)
- [arXiv260112] mHC-lite: You Don't Need 20 Sinkhorn-Knopp Iterations [link](https://arxiv.org/pdf/2601.05732)
- [arXiv260112] Influence of Parallelism in Vector-Multiplication Units on Correlation Power Analysis [link](https://arxiv.org/pdf/2601.05828)

## 2026-01-13

**cs.DC total: 18**

- **[arXiv260113] BlazeAIoT: A Modular Multi-Layer Platform for Real-Time Distributed Robotics Across Edge, Fog, and Cloud Infrastructures**
  - **tags:** [mlsys], [cluster infrastructure], [Kubernetes, DDS, Kafka, Redis, ROS2, dynamic data bridging, hierarchical rate limiting]
  - **authors:** Cedric Melancon, Julien Gascon-Samson, Maarouf Saad, Kuljeet Kaur, Simon Savard
  - **institution:** École de technologie supérieure
  - **link:** https://arxiv.org/pdf/2601.06344
  - **Simple LLM Summary:** This paper introduces BlazeAIoT, a modular platform that uses Kubernetes-based clusters and adaptive data distribution mechanisms to unify distributed robotics across edge, fog, and cloud layers. The platform's performance is validated in robotics scenarios, demonstrating its ability to dynamically allocate services and minimize latency under real-time constraints.

- **[arXiv260113] Privacy-Preserving Data Processing in Cloud : From Homomorphic Encryption to Federated Analytics**
  - **tags:** [mlsys], [others], [homomorphic encryption, secure multi-party computation, differential privacy, federated analytics, federated learning, hybrid privacy frameworks]
  - **authors:** Gaurav Sarraf, Vibhor Pal
  - **institution:** Independent Researcher
  - **link:** https://arxiv.org/pdf/2601.06710
  - **Simple LLM Summary:** This paper reviews privacy-preserving data processing methods for cloud computing, including cryptographic techniques like homomorphic encryption and statistical approaches like differential privacy, as well as distributed frameworks like federated learning. It concludes that while these methods enhance data security, they involve trade-offs in computational efficiency, accuracy, and scalability, and emerging hybrid frameworks offer promising solutions for better privacy protection.

- **[arXiv260113] Behavioral Analytics for Continuous Insider Threat Detection in Zero-Trust Architectures**
  - **tags:** [mlsys], [others], [behavioral analytics, AdaBoost, SMOTE, PCA, CERT dataset]
  - **authors:** Gaurav Sarraf
  - **institution:** Independent researcher
  - **link:** https://arxiv.org/pdf/2601.06708
  - **Simple LLM Summary:** The paper proposes a behavioral analytics framework using machine learning for continuous insider threat detection in zero-trust architectures. It employs data preprocessing (SMOTE, PCA) and benchmarks classifiers, finding that an AdaBoost model achieves the highest performance (98.0% accuracy). The results demonstrate the effectiveness of AdaBoost-based analytics for reinforcing security in zero-trust settings.

- **[arXiv260113] AIConfigurator: Lightning-Fast Configuration Optimization for Multi-Framework LLM Serving**
  - **tags:** [mlsys], [llm inference], [performance modeling, configuration search, kernel-level database, GEMM, attention, communication, memory operations]
  - **authors:** Tianhao Xu, Yiming Liu, Xianglong Lu, Yijia Zhao, Xuting Zhou, Aichen Feng, Yiyi Chen, Yi Shen, Qin Zhou, Xumeng Chen, Ilya Sherstyuk, Haorui Li, Rishi Thakkar, Ben Hamm, Yuanzhe Li, Xue Huang, Wenpeng Wu, Anish Shanbhag, Harry Kim, Chuan Chen, Junjie Lai
  - **institution:** NVIDIA
  - **link:** https://arxiv.org/pdf/2601.06288
  - **Simple LLM Summary:** AIConfigurator is a system that rapidly optimizes LLM serving configurations by decomposing inference into modelable primitives and using a pre-calibrated kernel performance database, without requiring GPU profiling. It identifies configurations that improve performance by up to 40-50% for various models and completes searches in under 30 seconds on average.

- **[arXiv260113] Resource-Aware Task Allocator Design: Insights and Recommendations for Distributed Satellite Constellations**
  - **tags:** [sys], [distributed satellite systems], [Single-Level Tree Network, resource-aware task allocation, blocking probability, response time, energy consumption, solar-aware scheduling]
  - **authors:** Bharadwaj Veeravalli
  - **institution:** National University of Singapore
  - **link:** https://arxiv.org/pdf/2601.06706
  - **Simple LLM Summary:** This paper designs a Resource-Aware Task Allocator (RATA) using a Single-Level Tree Network architecture for task allocation in distributed satellite constellations. The empirical analysis shows that while capacity increases with constellation size, blocking and delay grow non-linearly, with CPU availability identified as the primary bottleneck rather than energy. The findings provide quantitative thresholds for system performance degradation in satellite-based computing platforms.

- **[arXiv260113] Rethinking Inter-Process Communication with Memory Operation Offloading**
  - **tags:** [mlsys], [multi-modal inference], [memory operation offloading, asynchronous pipelining, selective cache injection, hybrid coordination, shared-memory communication]
  - **authors:** Misun Park, Richi Dubey, Yifan Yuan, Nam Sung Kim, Ada Gavrilovska
  - **institution:** Georgia Institute of Technology, Meta, University of Illinois–Urbana-Champaign
  - **link:** https://arxiv.org/pdf/2601.06331
  - **Simple LLM Summary:** The paper presents ROCKET, a unified IPC runtime suite that integrates hardware- and software-based memory offloading into shared-memory communication to reduce CPU overhead from data copies. It introduces techniques like asynchronous pipelining and selective cache injection to coordinate offloading strategies. Evaluations show the system significantly reduces instruction counts, improves throughput, and lowers latency for modern data-intensive workloads like multimodal AI services.

- **[arXiv260113] HiDVFS: A Hierarchical Multi-Agent DVFS Scheduler for OpenMP DAG Workloads**
  - **tags:** [mlsys], [others], [dynamic voltage and frequency scaling, multi-agent reinforcement learning, OpenMP DAG scheduling, hierarchical scheduler, temperature-aware scheduling]
  - **authors:** Mohammad Pivezhandi, Abusayeed Saifullah, Ali Jannesari
  - **institution:** Iowa State University, University of Texas at Dallas
  - **link:** https://arxiv.org/pdf/2601.06425
  - **Simple LLM Summary:** The paper proposes HiDVFS, a hierarchical multi-agent DVFS scheduler that uses profiling data, core temperatures, and makespan-first objectives to optimize task allocation for OpenMP DAG workloads on parallel embedded systems. It achieves significant improvements, with experiments on an NVIDIA Jetson TX2 showing an average 3.95x speedup and 47.1% energy reduction compared to state-of-the-art approaches.

- **[arXiv260113] SkyNomad: On Using Multi-Region Spot Instances to Minimize AI Batch Job Cost**
  - **tags:** [mlsys], [cluster infrastructure], [multi-region scheduling, spot instances, cost minimization, deadline guarantee, lightweight probing, lifetime prediction, migration cost]
  - **authors:** Zhifei Li, Tian Xia, Ziming Mao, Zihan Zhou, Ethan J. Jackson, Jamison Kerney, Zhanghao Wu, Pratik Mishra, Yi Xu, Yifan Qiao, Scott Shenker, Ion Stoica
  - **institution:** UC Berkeley, Shanghai Jiao Tong University, AMD, ICSI
  - **link:** https://arxiv.org/pdf/2601.06520
  - **Simple LLM Summary:** SkyNomad is a multi-region scheduling system that minimizes the cost of AI batch jobs by exploiting spatial and temporal heterogeneity in spot instance availability and prices, while guaranteeing deadlines. It uses a cost model that incorporates regional characteristics, migration overhead, and deadline pressure to guide scheduling decisions. The evaluation shows it achieves significant cost savings in real deployments and performs close to an optimal policy while consistently meeting deadlines.

- **[arXiv260113] Learning-Augmented Performance Model for Tensor Product Factorization in High-Order FEM**
  - **tags:** [mlsys], [GPU kernels], [performance modeling, XGBoost, sum-factorization, tensor n-mode product, dependency-chain analysis, loop-body splitting]
  - **authors:** Xuanzhengbo Ren, Yuta Kawai, Tetsuya Hoshino, Hirofumi Tomita, Takahiro Katagiri, Daichi Mukunoki, Seiya Nishizawa
  - **institution:** Nagoya University, RIKEN R-CCS
  - **link:** https://arxiv.org/pdf/2601.06886
  - **Simple LLM Summary:** This paper develops a learning-augmented performance model for tensor product factorization kernels in high-order FEM, combining a dependency-chain-based analytical formulation with XGBoost to estimate key parameters. The model is designed to predict instruction-level efficiency, particularly for loop-splitting strategies on processors like the Fujitsu A64FX. Evaluations show it significantly outperforms standard Roofline and ECM models in prediction accuracy across different polynomial orders and processors.

- **[arXiv260113] Employ SmartNICs' Data Path Accelerators for Ordered Key-Value Stores**
  - **tags:** [sys], [distributed systems], [SmartNIC, Data Path Accelerator (DPA), learned index, lock-free, PCIe, DMA, RDMA, stateless clients]
  - **authors:** Frederic Schimmelpfennig, Jan Sass, Reza Salkhordeh, Martin Kröning, Stefan Lankes, André Brinkmann
  - **institution:** Johannes Gutenberg University Mainz, RWTH Aachen University
  - **link:** https://arxiv.org/pdf/2601.06231
  - **Simple LLM Summary:** This paper introduces a key-value store that uses the Data Path Accelerators (DPAs) on a BlueField-3 SmartNIC to process requests directly on the NIC, employing a lock-free learned index in local memory to enable efficient range queries and stateless clients. It defers host memory access to minimize PCIe crossings and batches writes for performance. The system achieves high throughput for point and range queries, matching or exceeding state-of-the-art solutions while suggesting hardware improvements for further gains.

- **[arXiv260113] SC-MII: Infrastructure LiDAR-based 3D Object Detection on Edge Devices for Split Computing with Multiple Intermediate Outputs Integration**
  - **tags:** [mlsys], [others], [split computing, edge computing, intermediate output integration, 3D object detection, LiDAR, point cloud]
  - **authors:** Taisuke Noguchi, Takayuki Nishio, Takuya Azumi
  - **institution:** Saitama University, Institute of Science Tokyo
  - **link:** https://arxiv.org/pdf/2601.07119
  - **Simple LLM Summary:** This paper proposes SC-MII, a method for 3D object detection using multiple infrastructure LiDARs. It employs split computing where edge devices process initial DNN layers and send intermediate features to a server for integration and final inference, reducing device load and latency. Experiments show a significant speed-up and reduction in edge processing time with minimal accuracy loss.

- **[arXiv260113] MegaFlow: Large-Scale Distributed Orchestration System for the Agentic Era**
  - **tags:** [mlsys], [cluster infrastructure], [distributed orchestration, three-service architecture, agent-environment interaction, resource allocation, task scheduling]
  - **authors:** Lei Zhang, Mouxiang Chen, Ruisheng Cao, Jiawei Chen, Fan Zhou, Yiheng Xu, Jiaxi Yang, Liang Chen, Changwei Luo, Kai Zhang, Fan Yan, KaShun Shum, Jiajun Zhang, Zeyu Cui, Hu Feng, Junyang Lin, Binyuan Hui, Min Yang
  - **institution:** Shenzhen Institutes of Advanced Technology, Chinese Academy of Sciences; University of Chinese Academy of Sciences; Alibaba Group
  - **link:** https://arxiv.org/pdf/2601.07526
  - **Simple LLM Summary:** The paper presents MegaFlow, a large-scale distributed orchestration system designed for training AI agents. It abstracts the infrastructure into three independent services (Model, Agent, Environment) to enable flexible scaling and efficient management of tens of thousands of concurrent agent tasks. The system addresses a critical infrastructure gap for large-scale agent training in complex domains like software engineering.

- **[arXiv260113] Divergence-Based Adaptive Aggregation for Byzantine Robust Federated Learning**
  - **tags:** [mlsys], [fault-tolerance], [divergence of degree, linear calibration, vetted root dataset, Byzantine attacks, client drift, federated learning]
  - **authors:** Bingnan Xiao, Feng Zhu, Jingjing Zhang, Wei Ni, Xin Wang
  - **institution:** Fudan University, North Carolina State University, Edith Cowan University, University of New South Wales
  - **link:** https://arxiv.org/pdf/2601.06903
  - **Simple LLM Summary:** The paper proposes two federated learning frameworks, DRAG and BR-DRAG, which use a divergence metric and reference directions to calibrate local updates, mitigating client drift and resisting Byzantine attacks. The methods are proven to achieve fast convergence under data heterogeneity and attacks, with experiments showing superior performance in handling drifts and maintaining robustness.

- **[arXiv260113] Peformance Isolation for Inference Processes in Edge GPU Systems**
  - **tags:** [mlsys], [llm inference], [MPS, MIG, Green Contexts, temporal isolation, GPU partitioning, performance predictability]
  - **authors:** Juan José Martín, José Flich, Carles Hernández
  - **institution:** Universitat Politècnica de València
  - **link:** https://arxiv.org/pdf/2601.07600
  - **Simple LLM Summary:** This paper analyzes GPU isolation mechanisms (MPS, MIG, Green Contexts) to ensure predictable inference times for deep learning models in safety-critical edge systems. It finds that MIG offers high isolation, while Green Contexts provide fine-grained SM allocation with low overhead for edge devices, though lacking memory isolation.

- **[arXiv260113] Bringing Computation to the data: Interoperable serverless function execution for astrophysical data analysis in the SRCNet**
  - **tags:** [sys], [scientific computing], [serverless computing, Function-as-a-Service (FaaS), data-proximate computation, SKA Regional Centre Network (SRCNet), Gaussian convolution]
  - **authors:** Manuel Parra-Royón, Julián Garrido-Sánchez, Susana Sánchez-Expósito, María Ángeles Mendoza, Rob Barnsley, Anthony Moraghan, Jesús Sánchez, Laura Darriba, Carlos Ruíz-Monje, Edgar Joao, Javier Moldón, Jesús Salgado, Lourdes Verdes-Montenegro
  - **institution:** Instituto de Astrofísica de Andalucía, Square Kilometre Array Observatory (SKAO), University of Sevilla, University of Manchester
  - **link:** https://arxiv.org/pdf/2601.07308
  - **Simple LLM Summary:** This paper explores the application of serverless computing and Function-as-a-Service (FaaS) to enable data-proximate astrophysical analysis within the federated SKA Regional Centre Network. It develops and deploys representative analysis functions, such as a Gaussian convolution, directly at data storage sites. The results demonstrate that this approach provides a scalable and efficient pathway to handle the massive data volumes expected from the Square Kilometre Array.

- **[arXiv260113] Advanced computing for reproducibility of astronomy Big Data Science, with a showcase of AMIGA and the SKA Science prototype**
  - **tags:** [sys], [astronomy big data infrastructure], [semantic data models, federated infrastructures, reproducibility, open science, SKA Regional Centre Network]
  - **authors:** Julián Garrido, Susana Sánchez, Edgar Ribeiro João, Roger Ianjamasimanana, Manuel Parra, Lourdes Verdes-Montenegro
  - **institution:** Instituto de Astrofísica de Andalucía, CSIC
  - **link:** https://arxiv.org/pdf/2601.07439
  - **Simple LLM Summary:** The paper presents research by the AMIGA group addressing computing and reproducibility challenges for the SKA Observatory through advancements in semantic data models and analysis services integrated into federated infrastructures. It concludes that for the SKAO to succeed, the development of the SKA Regional Centre Network must explicitly incorporate reproducibility requirements into its fundamental architectural design to enable verifiable and sustainable research.

- **[arXiv260113] OpenTinker: Separating Concerns in Agentic Reinforcement Learning**
  - **tags:** [mlsys], [llm training], [reinforcement learning, large language model agents, separation of concerns, composable components, managed execution runtime, centralized scheduler, LoRA, full-parameter RL, supervised fine-tuning]
  - **authors:** Siqi Zhu, Jiaxuan You
  - **institution:** University of Illinois Urbana-Champaign
  - **link:** https://arxiv.org/pdf/2601.07376
  - **Simple LLM Summary:** The paper introduces OpenTinker, an infrastructure framework that separates concerns in agentic reinforcement learning by decomposing systems into lightweight, composable components for agents, environments, and interaction protocols, delegating inference and training to a managed runtime. It uses a centralized scheduler to manage diverse workloads like LoRA-based and full-parameter RL over shared resources. The main conclusion is that this design effectively addresses systems challenges in RL for LLM agents and demonstrates practical utility in agentic learning scenarios.

- **[arXiv260113] Beyond Single-GPU: Scaling PDLP to Distributed Multi-GPU Systems**
  - **tags:** [mlsys], [GPU kernels], [PDHG, distributed multi-GPU, two-dimensional grid partitioning, NCCL communication, block-wise random shuffling, nonzero-aware data distribution, fused CUDA kernels]
  - **authors:** Hongpei Li, Yicheng Huang, Huikang Liu, Dongdong Ge, Yinyu Ye
  - **institution:** Cardinal Operations, Shanghai University of Finance and Economics, Shanghai Jiao Tong University, Stanford University
  - **link:** https://arxiv.org/pdf/2601.07628
  - **Simple LLM Summary:** This paper presents a distributed multi-GPU implementation of the Primal-Dual Hybrid Gradient (PDHG) algorithm for solving large-scale linear programming problems. The method uses two-dimensional grid partitioning and optimized communication to scale across GPUs, overcoming memory bottlenecks. The results show strong scalability and performance improvements while maintaining numerical accuracy.


**cs.AI/cs.LG contains "reinforcement learning" total: 50**
- [arXiv260113] No More Stale Feedback: Co-Evolving Critics for Open-World Agent Learning [link](https://arxiv.org/pdf/2601.06794)
- [arXiv260113] From RLHF to Direct Alignment: A Theoretical Unification of Preference Learning for Large Language Models [link](https://arxiv.org/pdf/2601.06108)
- [arXiv260113] GDEPO: Group Dual-dynamic and Equal-right-advantage Policy Optimization with Enhanced Training Data Utilization for Sample-Constrained Reinforcement Learning [link](https://arxiv.org/pdf/2601.06795)
- [arXiv260113] A Brain-like Synergistic Core in LLMs Drives Behaviour and Learning [link](https://arxiv.org/pdf/2601.06851)
- [arXiv260113] Characterising Toxicity in Generative Large Language Models [link](https://arxiv.org/pdf/2601.06700)
- [arXiv260113] Thinking with Deltas: Incentivizing Reinforcement Learning via Differential Visual Reasoning Policy [link](https://arxiv.org/pdf/2601.06801)
- [arXiv260113] GanitLLM: Difficulty-Aware Bengali Mathematical Reasoning through Curriculum-GRPO [link](https://arxiv.org/pdf/2601.06767)
- [arXiv260113] HiMeS: Hippocampus-inspired Memory System for Personalized AI Assistants [link](https://arxiv.org/pdf/2601.06152)
- [arXiv260113] Plasticity vs. Rigidity: The Impact of Low-Rank Adapters on Reasoning on a Micro-Budget [link](https://arxiv.org/pdf/2601.06677)
- [arXiv260113] A Review of Online Diffusion Policy RL Algorithms for Scalable Robotic Control [link](https://arxiv.org/pdf/2601.06133)
- [arXiv260113] The Impact of Post-training on Data Contamination [link](https://arxiv.org/pdf/2601.06103)
- [arXiv260113] KASER: Knowledge-Aligned Student Error Simulator for Open-Ended Coding Tasks [link](https://arxiv.org/pdf/2601.06633)
- [arXiv260113] Deep Q-Network Based Resilient Drone Communication:Neutralizing First-Order Markov Jammers [link](https://arxiv.org/pdf/2601.06095)
- [arXiv260113] Toward Safe and Responsible AI Agents: A Three-Pillar Model for Transparency, Accountability, and Trustworthiness [link](https://arxiv.org/pdf/2601.06223)
- [arXiv260113] TimeGNN-Augmented Hybrid-Action MARL for Fine-Grained Task Partitioning and Energy-Aware Offloading in MEC [link](https://arxiv.org/pdf/2601.06191)
- [arXiv260113] Personality-Aware Reinforcement Learning for Persuasive Dialogue with LLM-Driven Simulation [link](https://arxiv.org/pdf/2601.06877)
- [arXiv260113] Future-as-Label: Scalable Supervision from Real-World Outcomes [link](https://arxiv.org/pdf/2601.06336)
- [arXiv260113] ArenaRL: Scaling RL for Open-Ended Agents via Tournament-based Relative Ranking [link](https://arxiv.org/pdf/2601.06487)
- [arXiv260113] Reinforcement Learning for Chain of Thought Compression with One-Domain-to-All Generalization [link](https://arxiv.org/pdf/2601.06052)
- [arXiv260113] Code Evolution for Control: Synthesizing Policies via LLM-Driven Evolutionary Search [link](https://arxiv.org/pdf/2601.06845)
- [arXiv260113] How well can off-the-shelf LLMs elucidate molecular structures from mass spectra using chain-of-thought reasoning? [link](https://arxiv.org/pdf/2601.06289)
- [arXiv260113] Object-Centric World Models Meet Monte Carlo Tree Search [link](https://arxiv.org/pdf/2601.06604)
- [arXiv260113] Reinforcement Learning-Guided Dynamic Multi-Graph Fusion for Evacuation Traffic Prediction [link](https://arxiv.org/pdf/2601.06664)
- [arXiv260113] COVR:Collaborative Optimization of VLMs and RL Agent for Visual-Based Control [link](https://arxiv.org/pdf/2601.06122)
- [arXiv260113] Distributional Clarity: The Hidden Driver of RL-Friendliness in Large Language Models [link](https://arxiv.org/pdf/2601.06911)
- [arXiv260113] X-Coder: Advancing Competitive Programming with Fully Synthetic Tasks, Solutions, and Tests [link](https://arxiv.org/pdf/2601.06953)
- [arXiv260113] MEDVISTAGYM: A Scalable Training Environment for Thinking with Medical Images via Tool-Integrated Reinforcement Learning [link](https://arxiv.org/pdf/2601.07107)
- [arXiv260113] Enhancing Cloud Network Resilience via a Robust LLM-Empowered Multi-Agent Reinforcement Learning Framework [link](https://arxiv.org/pdf/2601.07122)
- [arXiv260113] ENTRA: Entropy-Based Redundancy Avoidance in Large Language Model Reasoning [link](https://arxiv.org/pdf/2601.07123)
- [arXiv260113] Generating readily synthesizable small molecule fluorophore scaffolds with reinforcement learning [link](https://arxiv.org/pdf/2601.07145)
- [arXiv260113] Rewarding Creativity: A Human-Aligned Generative Reward Model for Reinforcement Learning in Storytelling [link](https://arxiv.org/pdf/2601.07149)
- [arXiv260113] AscendKernelGen: A Systematic Study of LLM-Based Kernel Generation for Neural Processing Units [link](https://arxiv.org/pdf/2601.07160)
- [arXiv260113] Offline Meta-Reinforcement Learning with Flow-Based Task Inference and Adaptive Correction of Feature Overgeneralization [link](https://arxiv.org/pdf/2601.07164)
- [arXiv260113] Consolidation or Adaptation? PRISM: Disentangling SFT and RL Data via Gradient Concentration [link](https://arxiv.org/pdf/2601.07224)
- [arXiv260113] Group Pattern Selection Optimization: Let LRMs Pick the Right Pattern for Reasoning [link](https://arxiv.org/pdf/2601.07238)
- [arXiv260113] LRAS: Advanced Legal Reasoning with Agentic Search [link](https://arxiv.org/pdf/2601.07296)
- [arXiv260113] Heterogeneous Multi-Expert Reinforcement Learning for Long-Horizon Multi-Goal Tasks in Autonomous Forklifts [link](https://arxiv.org/pdf/2601.07304)
- [arXiv260113] Segmental Advantage Estimation: Enhancing PPO for Long-Context LLM Training [link](https://arxiv.org/pdf/2601.07320)
- [arXiv260113] On the Non-decoupling of Supervised Fine-tuning and Reinforcement Learning in Post-training [link](https://arxiv.org/pdf/2601.07389)
- [arXiv260113] Outcome-Grounded Advantage Reshaping for Fine-Grained Credit Assignment in Mathematical Reasoning [link](https://arxiv.org/pdf/2601.07408)
- [arXiv260113] Puzzle it Out: Local-to-Global World Model for Offline Multi-Agent Reinforcement Learning [link](https://arxiv.org/pdf/2601.07463)
- [arXiv260113] Graph Inference Towards ICD Coding [link](https://arxiv.org/pdf/2601.07496)
- [arXiv260113] Controlling Multimodal Conversational Agents with Coverage-Enhanced Latent Actions [link](https://arxiv.org/pdf/2601.07516)
- [arXiv260113] Stagewise Reinforcement Learning and the Geometry of the Regret Landscape [link](https://arxiv.org/pdf/2601.07524)
- [arXiv260113] GRPO with State Mutations: Improving LLM-Based Hardware Test Plan Generation [link](https://arxiv.org/pdf/2601.07593)
- [arXiv260113] Hiking in the Wild: A Scalable Perceptive Parkour Framework for Humanoids [link](https://arxiv.org/pdf/2601.07718)
- [arXiv260113] Beyond Single-Shot: Multi-step Tool Retrieval via Query Planning [link](https://arxiv.org/pdf/2601.07782)
- [arXiv260113] Failure-Aware RL: Reliable Offline-to-Online Reinforcement Learning with Self-Recovery for Real-World Manipulation [link](https://arxiv.org/pdf/2601.07821)
- [arXiv260113] Large Language Models for Physics Instrument Design [link](https://arxiv.org/pdf/2601.07580)
- [arXiv260113] Reinforcement Learning for Micro-Level Claims Reserving [link](https://arxiv.org/pdf/2601.07637)

**cs.AI/cs.LG contains "accelerate" total: 18**
- [arXiv260113] Bridging the AI divide in sub-Saharan Africa: Challenges and opportunities for inclusivity [link](https://arxiv.org/pdf/2601.06145)
- [arXiv260113] GDEPO: Group Dual-dynamic and Equal-right-advantage Policy Optimization with Enhanced Training Data Utilization for Sample-Constrained Reinforcement Learning [link](https://arxiv.org/pdf/2601.06795)
- [arXiv260113] Channel Knowledge Map Construction via Guided Flow Matching [link](https://arxiv.org/pdf/2601.06156)
- [arXiv260113] Attention in Geometry: Scalable Spatial Modeling via Adaptive Density Fields and FAISS-Accelerated Kernels [link](https://arxiv.org/pdf/2601.06135)
- [arXiv260113] Pareto-Optimal Model Selection for Low-Cost, Single-Lead EMG Control in Embedded Systems [link](https://arxiv.org/pdf/2601.06516)
- [arXiv260113] Logic-Driven Semantic Communication for Resilient Multi-Agent Systems [link](https://arxiv.org/pdf/2601.06733)
- [arXiv260113] TeleMem: Building Long-Term and Multimodal Memory for Agentic AI [link](https://arxiv.org/pdf/2601.06037)
- [arXiv260113] Lower Bounds for the Algorithmic Complexity of Learned Indexes [link](https://arxiv.org/pdf/2601.06629)
- [arXiv260113] MicLog: Towards Accurate and Efficient LLM-based Log Parsing via Progressive Meta In-Context Learning [link](https://arxiv.org/pdf/2601.07005)
- [arXiv260113] Jasper: ANNS Quantized for Speed, Built for Change on GPU [link](https://arxiv.org/pdf/2601.07048)
- [arXiv260113] AscendKernelGen: A Systematic Study of LLM-Based Kernel Generation for Neural Processing Units [link](https://arxiv.org/pdf/2601.07160)
- [arXiv260113] When Bots Take the Bait: Exposing and Mitigating the Emerging Social Engineering Attack in Web Automation Agent [link](https://arxiv.org/pdf/2601.07263)
- [arXiv260113] Software-Hardware Co-optimization for Modular E2E AV Paradigm: A Unified Framework of Optimization Approaches, Simulation Environment and Evaluation Metrics [link](https://arxiv.org/pdf/2601.07393)
- [arXiv260113] PLANET v2.0: A comprehensive Protein-Ligand Affinity Prediction Model Based on Mixture Density Network [link](https://arxiv.org/pdf/2601.07415)
- [arXiv260113] Pheromone-Focused Ant Colony Optimization algorithm for path planning [link](https://arxiv.org/pdf/2601.07597)
- [arXiv260113] Learning to accelerate Krasnosel'skii-Mann fixed-point iterations with guarantees [link](https://arxiv.org/pdf/2601.07665)
- [arXiv260113] Match Made with Matrix Completion: Efficient Learning under Matching Interference [link](https://arxiv.org/pdf/2601.06982)
- [arXiv260113] A Model of Artificial Jagged Intelligence [link](https://arxiv.org/pdf/2601.07573)
