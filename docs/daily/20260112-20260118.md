# 20260112-20260118

## 2026-01-12

**cs.DC total: 5**

- **[arXiv260112] LACIN: Linearly Arranged Complete Interconnection Networks**
  - **tags:** [sys], [interconnection networks], [complete graph, dragonfly, hyperx, isoport, wiring, routing]
  - **authors:** Ramón Beivide, Cristóbal Camarero, Carmen Martínez, Enrique Vallejo, Mateo Valero
  - **institution:** Universidad de Cantabria, Barcelona Supercomputing Center
  - **link:** https://arxiv.org/pdf/2601.05668
  - **Simple LLM Summary:** This paper introduces LACIN, a method for implementing complete interconnection networks by linking switches using identically indexed ports (isoport). This approach simplifies network cabling and routing complexity. It facilitates the deployment of scalable networks for parallel computers, from VLSI systems to large supercomputers.

- **[arXiv260112] MoEBlaze: Breaking the Memory Wall for Efficient MoE Training on Modern GPUs**
  - **tags:** [mlsys], [llm training], [Mixture-of-Experts (MoE), memory-efficient training, token dispatch, co-designed kernels, activation checkpointing, memory wall]
  - **authors:** Jiyuan Zhang, Yining Liu, Siqi Yan, Lisen Deng, Jennifer Cao, Shuqi Yang, Min Ni, Bi Xue, Shen Li
  - **institution:** Meta Platforms Inc, Thinking Machines Lab
  - **link:** https://arxiv.org/pdf/2601.05296
  - **Simple LLM Summary:** The paper presents MoEBlaze, a memory-efficient training framework for Mixture-of-Experts (MoE) models. It uses an end-to-end token dispatch method with optimized data structures and co-designed kernels with smart activation checkpointing to reduce memory overhead. The authors demonstrate that MoEBlaze achieves over 4x speedups and over 50% memory savings compared to existing frameworks.

- **[arXiv260112] Multi-Modal Style Transfer-based Prompt Tuning for Efficient Federated Domain Generalization**
  - **tags:** [mlsys], [multi-modal training], [multi-modal style transfer, prompt tuning, federated domain generalization, dual-prompt module, domain-aware prompt generation]
  - **authors:** Yuliang Chen, Xi Lin, Jun Wu, Xiangrui Cai, Qiaolun Zhang, Xichun Fan, Jiapeng Xu, Xiu Su
  - **institution:** Shanghai Jiao Tong University, Nankai University, Polytechnic Institute of Milan, New York University Shanghai, Central South University
  - **link:** https://arxiv.org/pdf/2601.05955
  - **Simple LLM Summary:** This paper proposes FaST-PT, a federated domain generalization framework that uses a lightweight multi-modal style transfer method for local feature augmentation and a dual-prompt module with domain-aware generation for efficient adaptation to unseen domains. Experiments on benchmark datasets show it outperforms state-of-the-art methods in performance and efficiency.

- **[arXiv260112] Self-Evolving Distributed Memory Architecture for Scalable AI Systems**
  - **tags:** [mlsys], [cluster infrastructure], [memory-guided matrix processing, memory-aware peer selection, runtime-adaptive deployment, dual-memory architecture, dynamic partitioning]
  - **authors:** Zixuan Li, Chuanzhen Wang, Haotian Sun
  - **institution:** Tongji University, Pacific Coast University, Northern Research Laboratory
  - **link:** https://arxiv.org/pdf/2601.05569
  - **Simple LLM Summary:** This paper introduces a three-layer framework for unified memory management across computation, communication, and deployment in distributed AI systems. The core method includes dynamic memory partitioning, topology-aware peer selection, and continuous runtime reconfiguration, supported by a dual-memory system. The experiments show it achieves higher memory utilization, throughput, and lower latency compared to a baseline like Ray Distributed.

- **[arXiv260112] Performance-Portable Optimization and Analysis of Multiple Right-Hand Sides in a Lattice QCD Solver**
  - **tags:** [sys], [high-performance computing], [multiple right-hand sides, SIMD, auto-vectorization, GMRES, DD-αAMG, performance portability, SME]
  - **authors:** Shiting Long, Gustavo Ramirez-Hidalgo, Stepan Nassyr, Jose Jimenez-Merchan, Andreas Frommer, Dirk Pleiter
  - **institution:** KTH Royal Institute of Technology, Forschungszentrum Jülich GmbH, University of Wuppertal, University of Groningen
  - **link:** https://arxiv.org/pdf/2601.05816
  - **Simple LLM Summary:** The paper extends the lattice QCD solver DD-αAMG by implementing multiple right-hand sides and optimizing data layouts for better SIMD utilization, aiming to improve performance portability across x86 and Arm architectures. It demonstrates that these optimizations yield similar speedups on different hardware platforms, while also providing an early assessment of the Arm SME instruction set. The performance analysis reveals the complexity introduced by architectural constraints and compiler behavior.


**cs.AI/cs.LG contains "reinforcement learning" total: 19**
- [arXiv260112] Sequential Bayesian Optimal Experimental Design in Infinite Dimensions via Policy Gradient Reinforcement Learning [link](https://arxiv.org/pdf/2601.05868)
- [arXiv260112] MaxCode: A Max-Reward Reinforcement Learning Framework for Automated Code Optimization [link](https://arxiv.org/pdf/2601.05475)
- [arXiv260112] Autonomous Discovery of the Ising Model's Critical Parameters with Reinforcement Learning [link](https://arxiv.org/pdf/2601.05577)
- [arXiv260112] WildSci: Advancing Scientific Reasoning from In-the-Wild Literature [link](https://arxiv.org/pdf/2601.05567)
- [arXiv260112] Intelligent Singularity Avoidance in UR10 Robotic Arm Path Planning Using Hybrid Fuzzy Logic and Reinforcement Learning [link](https://arxiv.org/pdf/2601.05836)
- [arXiv260112] IIB-LPO: Latent Policy Optimization via Iterative Information Bottleneck [link](https://arxiv.org/pdf/2601.05870)
- [arXiv260112] Thinking with Map: Reinforced Parallel Map-Augmented Agent for Geolocalization [link](https://arxiv.org/pdf/2601.05432)
- [arXiv260112] StackPlanner: A Centralized Hierarchical Multi-Agent System with Task-Experience Memory Management [link](https://arxiv.org/pdf/2601.05890)
- [arXiv260112] TowerMind: A Tower Defence Game Learning Environment and Benchmark for LLM as Agents [link](https://arxiv.org/pdf/2601.05899)
- [arXiv260112] Reinforcement Learning of Large Language Models for Interpretable Credit Card Fraud Detection [link](https://arxiv.org/pdf/2601.05578)
- [arXiv260112] PaCoRe: Learning to Scale Test-Time Compute with Parallel Coordinated Reasoning [link](https://arxiv.org/pdf/2601.05593)
- [arXiv260112] Orchestrating Tokens and Sequences: Dynamic Hybrid Policy Optimization for RLVR [link](https://arxiv.org/pdf/2601.05607)
- [arXiv260112] From Off-Policy to On-Policy: Enhancing GUI Agents via Bi-level Expert-to-Policy Assimilation [link](https://arxiv.org/pdf/2601.05787)
- [arXiv260112] Do LLMs Need Inherent Reasoning Before Reinforcement Learning? A Study in Korean Self-Correction [link](https://arxiv.org/pdf/2601.05459)
- [arXiv260112] EnvScaler: Scaling Tool-Interactive Environments for LLM Agent via Programmatic Synthesis [link](https://arxiv.org/pdf/2601.05808)
- [arXiv260112] On the Limits of Self-Improving in LLMs and Why AGI, ASI and the Singularity Are Not Near Without Symbolic Model Synthesis [link](https://arxiv.org/pdf/2601.05280)
- [arXiv260112] KP-Agent: Keyword Pruning in Sponsored Search Advertising via LLM-Powered Contextual Bandits [link](https://arxiv.org/pdf/2601.05257)
- [arXiv260112] Dual-Phase LLM Reasoning: Self-Evolved Mathematical Frameworks [link](https://arxiv.org/pdf/2601.05616)
- [arXiv260112] PRISMA: Reinforcement Learning Guided Two-Stage Policy Optimization in Multi-Agent Architecture for Open-Domain Multi-Hop Question Answering [link](https://arxiv.org/pdf/2601.05465)

**cs.AI/cs.LG contains "accelerate" total: 9**
- [arXiv260112] Tracing Stereotypes in Pre-trained Transformers: From Biased Neurons to Fairer Models [link](https://arxiv.org/pdf/2601.05663)
- [arXiv260112] Interactive Distillation for Cooperative Multi-Agent Reinforcement Learning [link](https://arxiv.org/pdf/2601.05407)
- [arXiv260112] DNATokenizer: A GPU-First Byte-to-Identifier Tokenizer for High-Throughput DNA Language Models [link](https://arxiv.org/pdf/2601.05531)
- [arXiv260112] Can We Predict Before Executing Machine Learning Agents? [link](https://arxiv.org/pdf/2601.05930)
- [arXiv260112] FLRQ: Faster LLM Quantization with Flexible Low-Rank Matrix Sketching [link](https://arxiv.org/pdf/2601.05684)
- [arXiv260112] A Survey of Agentic AI and Cybersecurity: Challenges, Opportunities and Use-case Prototypes [link](https://arxiv.org/pdf/2601.05293)
- [arXiv260112] PaCoRe: Learning to Scale Test-Time Compute with Parallel Coordinated Reasoning [link](https://arxiv.org/pdf/2601.05593)
- [arXiv260112] mHC-lite: You Don't Need 20 Sinkhorn-Knopp Iterations [link](https://arxiv.org/pdf/2601.05732)
- [arXiv260112] Influence of Parallelism in Vector-Multiplication Units on Correlation Power Analysis [link](https://arxiv.org/pdf/2601.05828)
