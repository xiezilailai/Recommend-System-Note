# 20260112-20260118

## 2026-01-12

**cs.DC total: 5**

- **[arXiv260112] LACIN: Linearly Arranged Complete Interconnection Networks**
  - **tags:** [sys], [interconnection networks], [complete graph, dragonfly, hyperx, isoport, wiring, routing]
  - **authors:** Ramón Beivide, Cristóbal Camarero, Carmen Martínez, Enrique Vallejo, Mateo Valero
  - **institution:** Universidad de Cantabria, Barcelona Supercomputing Center
  - **link:** https://arxiv.org/pdf/2601.05668
  - **Simple LLM Summary:** This paper introduces LACIN, a method for implementing complete interconnection networks by linking switches using identically indexed ports (isoport). This approach simplifies network cabling and routing complexity. It facilitates the deployment of scalable networks for parallel computers, from VLSI systems to large supercomputers.

- **[arXiv260112] MoEBlaze: Breaking the Memory Wall for Efficient MoE Training on Modern GPUs**
  - **tags:** [mlsys], [llm training], [Mixture-of-Experts (MoE), memory-efficient training, token dispatch, co-designed kernels, activation checkpointing, memory wall]
  - **authors:** Jiyuan Zhang, Yining Liu, Siqi Yan, Lisen Deng, Jennifer Cao, Shuqi Yang, Min Ni, Bi Xue, Shen Li
  - **institution:** Meta Platforms Inc, Thinking Machines Lab
  - **link:** https://arxiv.org/pdf/2601.05296
  - **Simple LLM Summary:** The paper presents MoEBlaze, a memory-efficient training framework for Mixture-of-Experts (MoE) models. It uses an end-to-end token dispatch method with optimized data structures and co-designed kernels with smart activation checkpointing to reduce memory overhead. The authors demonstrate that MoEBlaze achieves over 4x speedups and over 50% memory savings compared to existing frameworks.

- **[arXiv260112] Multi-Modal Style Transfer-based Prompt Tuning for Efficient Federated Domain Generalization**
  - **tags:** [mlsys], [multi-modal training], [multi-modal style transfer, prompt tuning, federated domain generalization, dual-prompt module, domain-aware prompt generation]
  - **authors:** Yuliang Chen, Xi Lin, Jun Wu, Xiangrui Cai, Qiaolun Zhang, Xichun Fan, Jiapeng Xu, Xiu Su
  - **institution:** Shanghai Jiao Tong University, Nankai University, Polytechnic Institute of Milan, New York University Shanghai, Central South University
  - **link:** https://arxiv.org/pdf/2601.05955
  - **Simple LLM Summary:** This paper proposes FaST-PT, a federated domain generalization framework that uses a lightweight multi-modal style transfer method for local feature augmentation and a dual-prompt module with domain-aware generation for efficient adaptation to unseen domains. Experiments on benchmark datasets show it outperforms state-of-the-art methods in performance and efficiency.

- **[arXiv260112] Self-Evolving Distributed Memory Architecture for Scalable AI Systems**
  - **tags:** [mlsys], [cluster infrastructure], [memory-guided matrix processing, memory-aware peer selection, runtime-adaptive deployment, dual-memory architecture, dynamic partitioning]
  - **authors:** Zixuan Li, Chuanzhen Wang, Haotian Sun
  - **institution:** Tongji University, Pacific Coast University, Northern Research Laboratory
  - **link:** https://arxiv.org/pdf/2601.05569
  - **Simple LLM Summary:** This paper introduces a three-layer framework for unified memory management across computation, communication, and deployment in distributed AI systems. The core method includes dynamic memory partitioning, topology-aware peer selection, and continuous runtime reconfiguration, supported by a dual-memory system. The experiments show it achieves higher memory utilization, throughput, and lower latency compared to a baseline like Ray Distributed.

- **[arXiv260112] Performance-Portable Optimization and Analysis of Multiple Right-Hand Sides in a Lattice QCD Solver**
  - **tags:** [sys], [high-performance computing], [multiple right-hand sides, SIMD, auto-vectorization, GMRES, DD-αAMG, performance portability, SME]
  - **authors:** Shiting Long, Gustavo Ramirez-Hidalgo, Stepan Nassyr, Jose Jimenez-Merchan, Andreas Frommer, Dirk Pleiter
  - **institution:** KTH Royal Institute of Technology, Forschungszentrum Jülich GmbH, University of Wuppertal, University of Groningen
  - **link:** https://arxiv.org/pdf/2601.05816
  - **Simple LLM Summary:** The paper extends the lattice QCD solver DD-αAMG by implementing multiple right-hand sides and optimizing data layouts for better SIMD utilization, aiming to improve performance portability across x86 and Arm architectures. It demonstrates that these optimizations yield similar speedups on different hardware platforms, while also providing an early assessment of the Arm SME instruction set. The performance analysis reveals the complexity introduced by architectural constraints and compiler behavior.


**cs.AI/cs.LG contains "reinforcement learning" total: 19**
- [arXiv260112] Sequential Bayesian Optimal Experimental Design in Infinite Dimensions via Policy Gradient Reinforcement Learning [link](https://arxiv.org/pdf/2601.05868)
- [arXiv260112] MaxCode: A Max-Reward Reinforcement Learning Framework for Automated Code Optimization [link](https://arxiv.org/pdf/2601.05475)
- [arXiv260112] Autonomous Discovery of the Ising Model's Critical Parameters with Reinforcement Learning [link](https://arxiv.org/pdf/2601.05577)
- [arXiv260112] WildSci: Advancing Scientific Reasoning from In-the-Wild Literature [link](https://arxiv.org/pdf/2601.05567)
- [arXiv260112] Intelligent Singularity Avoidance in UR10 Robotic Arm Path Planning Using Hybrid Fuzzy Logic and Reinforcement Learning [link](https://arxiv.org/pdf/2601.05836)
- [arXiv260112] IIB-LPO: Latent Policy Optimization via Iterative Information Bottleneck [link](https://arxiv.org/pdf/2601.05870)
- [arXiv260112] Thinking with Map: Reinforced Parallel Map-Augmented Agent for Geolocalization [link](https://arxiv.org/pdf/2601.05432)
- [arXiv260112] StackPlanner: A Centralized Hierarchical Multi-Agent System with Task-Experience Memory Management [link](https://arxiv.org/pdf/2601.05890)
- [arXiv260112] TowerMind: A Tower Defence Game Learning Environment and Benchmark for LLM as Agents [link](https://arxiv.org/pdf/2601.05899)
- [arXiv260112] Reinforcement Learning of Large Language Models for Interpretable Credit Card Fraud Detection [link](https://arxiv.org/pdf/2601.05578)
- [arXiv260112] PaCoRe: Learning to Scale Test-Time Compute with Parallel Coordinated Reasoning [link](https://arxiv.org/pdf/2601.05593)
- [arXiv260112] Orchestrating Tokens and Sequences: Dynamic Hybrid Policy Optimization for RLVR [link](https://arxiv.org/pdf/2601.05607)
- [arXiv260112] From Off-Policy to On-Policy: Enhancing GUI Agents via Bi-level Expert-to-Policy Assimilation [link](https://arxiv.org/pdf/2601.05787)
- [arXiv260112] Do LLMs Need Inherent Reasoning Before Reinforcement Learning? A Study in Korean Self-Correction [link](https://arxiv.org/pdf/2601.05459)
- [arXiv260112] EnvScaler: Scaling Tool-Interactive Environments for LLM Agent via Programmatic Synthesis [link](https://arxiv.org/pdf/2601.05808)
- [arXiv260112] On the Limits of Self-Improving in LLMs and Why AGI, ASI and the Singularity Are Not Near Without Symbolic Model Synthesis [link](https://arxiv.org/pdf/2601.05280)
- [arXiv260112] KP-Agent: Keyword Pruning in Sponsored Search Advertising via LLM-Powered Contextual Bandits [link](https://arxiv.org/pdf/2601.05257)
- [arXiv260112] Dual-Phase LLM Reasoning: Self-Evolved Mathematical Frameworks [link](https://arxiv.org/pdf/2601.05616)
- [arXiv260112] PRISMA: Reinforcement Learning Guided Two-Stage Policy Optimization in Multi-Agent Architecture for Open-Domain Multi-Hop Question Answering [link](https://arxiv.org/pdf/2601.05465)

**cs.AI/cs.LG contains "accelerate" total: 9**
- [arXiv260112] Tracing Stereotypes in Pre-trained Transformers: From Biased Neurons to Fairer Models [link](https://arxiv.org/pdf/2601.05663)
- [arXiv260112] Interactive Distillation for Cooperative Multi-Agent Reinforcement Learning [link](https://arxiv.org/pdf/2601.05407)
- [arXiv260112] DNATokenizer: A GPU-First Byte-to-Identifier Tokenizer for High-Throughput DNA Language Models [link](https://arxiv.org/pdf/2601.05531)
- [arXiv260112] Can We Predict Before Executing Machine Learning Agents? [link](https://arxiv.org/pdf/2601.05930)
- [arXiv260112] FLRQ: Faster LLM Quantization with Flexible Low-Rank Matrix Sketching [link](https://arxiv.org/pdf/2601.05684)
- [arXiv260112] A Survey of Agentic AI and Cybersecurity: Challenges, Opportunities and Use-case Prototypes [link](https://arxiv.org/pdf/2601.05293)
- [arXiv260112] PaCoRe: Learning to Scale Test-Time Compute with Parallel Coordinated Reasoning [link](https://arxiv.org/pdf/2601.05593)
- [arXiv260112] mHC-lite: You Don't Need 20 Sinkhorn-Knopp Iterations [link](https://arxiv.org/pdf/2601.05732)
- [arXiv260112] Influence of Parallelism in Vector-Multiplication Units on Correlation Power Analysis [link](https://arxiv.org/pdf/2601.05828)

## 2026-01-13

**cs.DC total: 18**

- **[arXiv260113] BlazeAIoT: A Modular Multi-Layer Platform for Real-Time Distributed Robotics Across Edge, Fog, and Cloud Infrastructures**
  - **tags:** [mlsys], [cluster infrastructure], [Kubernetes, DDS, Kafka, Redis, ROS2, dynamic data bridging, hierarchical rate limiting]
  - **authors:** Cedric Melancon, Julien Gascon-Samson, Maarouf Saad, Kuljeet Kaur, Simon Savard
  - **institution:** École de technologie supérieure
  - **link:** https://arxiv.org/pdf/2601.06344
  - **Simple LLM Summary:** This paper introduces BlazeAIoT, a modular platform that uses Kubernetes-based clusters and adaptive data distribution mechanisms to unify distributed robotics across edge, fog, and cloud layers. The platform's performance is validated in robotics scenarios, demonstrating its ability to dynamically allocate services and minimize latency under real-time constraints.

- **[arXiv260113] Privacy-Preserving Data Processing in Cloud : From Homomorphic Encryption to Federated Analytics**
  - **tags:** [mlsys], [others], [homomorphic encryption, secure multi-party computation, differential privacy, federated analytics, federated learning, hybrid privacy frameworks]
  - **authors:** Gaurav Sarraf, Vibhor Pal
  - **institution:** Independent Researcher
  - **link:** https://arxiv.org/pdf/2601.06710
  - **Simple LLM Summary:** This paper reviews privacy-preserving data processing methods for cloud computing, including cryptographic techniques like homomorphic encryption and statistical approaches like differential privacy, as well as distributed frameworks like federated learning. It concludes that while these methods enhance data security, they involve trade-offs in computational efficiency, accuracy, and scalability, and emerging hybrid frameworks offer promising solutions for better privacy protection.

- **[arXiv260113] Behavioral Analytics for Continuous Insider Threat Detection in Zero-Trust Architectures**
  - **tags:** [mlsys], [others], [behavioral analytics, AdaBoost, SMOTE, PCA, CERT dataset]
  - **authors:** Gaurav Sarraf
  - **institution:** Independent researcher
  - **link:** https://arxiv.org/pdf/2601.06708
  - **Simple LLM Summary:** The paper proposes a behavioral analytics framework using machine learning for continuous insider threat detection in zero-trust architectures. It employs data preprocessing (SMOTE, PCA) and benchmarks classifiers, finding that an AdaBoost model achieves the highest performance (98.0% accuracy). The results demonstrate the effectiveness of AdaBoost-based analytics for reinforcing security in zero-trust settings.

- **[arXiv260113] AIConfigurator: Lightning-Fast Configuration Optimization for Multi-Framework LLM Serving**
  - **tags:** [mlsys], [llm inference], [performance modeling, configuration search, kernel-level database, GEMM, attention, communication, memory operations]
  - **authors:** Tianhao Xu, Yiming Liu, Xianglong Lu, Yijia Zhao, Xuting Zhou, Aichen Feng, Yiyi Chen, Yi Shen, Qin Zhou, Xumeng Chen, Ilya Sherstyuk, Haorui Li, Rishi Thakkar, Ben Hamm, Yuanzhe Li, Xue Huang, Wenpeng Wu, Anish Shanbhag, Harry Kim, Chuan Chen, Junjie Lai
  - **institution:** NVIDIA
  - **link:** https://arxiv.org/pdf/2601.06288
  - **Simple LLM Summary:** AIConfigurator is a system that rapidly optimizes LLM serving configurations by decomposing inference into modelable primitives and using a pre-calibrated kernel performance database, without requiring GPU profiling. It identifies configurations that improve performance by up to 40-50% for various models and completes searches in under 30 seconds on average.

- **[arXiv260113] Resource-Aware Task Allocator Design: Insights and Recommendations for Distributed Satellite Constellations**
  - **tags:** [sys], [distributed satellite systems], [Single-Level Tree Network, resource-aware task allocation, blocking probability, response time, energy consumption, solar-aware scheduling]
  - **authors:** Bharadwaj Veeravalli
  - **institution:** National University of Singapore
  - **link:** https://arxiv.org/pdf/2601.06706
  - **Simple LLM Summary:** This paper designs a Resource-Aware Task Allocator (RATA) using a Single-Level Tree Network architecture for task allocation in distributed satellite constellations. The empirical analysis shows that while capacity increases with constellation size, blocking and delay grow non-linearly, with CPU availability identified as the primary bottleneck rather than energy. The findings provide quantitative thresholds for system performance degradation in satellite-based computing platforms.

- **[arXiv260113] Rethinking Inter-Process Communication with Memory Operation Offloading**
  - **tags:** [mlsys], [multi-modal inference], [memory operation offloading, asynchronous pipelining, selective cache injection, hybrid coordination, shared-memory communication]
  - **authors:** Misun Park, Richi Dubey, Yifan Yuan, Nam Sung Kim, Ada Gavrilovska
  - **institution:** Georgia Institute of Technology, Meta, University of Illinois–Urbana-Champaign
  - **link:** https://arxiv.org/pdf/2601.06331
  - **Simple LLM Summary:** The paper presents ROCKET, a unified IPC runtime suite that integrates hardware- and software-based memory offloading into shared-memory communication to reduce CPU overhead from data copies. It introduces techniques like asynchronous pipelining and selective cache injection to coordinate offloading strategies. Evaluations show the system significantly reduces instruction counts, improves throughput, and lowers latency for modern data-intensive workloads like multimodal AI services.

- **[arXiv260113] HiDVFS: A Hierarchical Multi-Agent DVFS Scheduler for OpenMP DAG Workloads**
  - **tags:** [mlsys], [others], [dynamic voltage and frequency scaling, multi-agent reinforcement learning, OpenMP DAG scheduling, hierarchical scheduler, temperature-aware scheduling]
  - **authors:** Mohammad Pivezhandi, Abusayeed Saifullah, Ali Jannesari
  - **institution:** Iowa State University, University of Texas at Dallas
  - **link:** https://arxiv.org/pdf/2601.06425
  - **Simple LLM Summary:** The paper proposes HiDVFS, a hierarchical multi-agent DVFS scheduler that uses profiling data, core temperatures, and makespan-first objectives to optimize task allocation for OpenMP DAG workloads on parallel embedded systems. It achieves significant improvements, with experiments on an NVIDIA Jetson TX2 showing an average 3.95x speedup and 47.1% energy reduction compared to state-of-the-art approaches.

- **[arXiv260113] SkyNomad: On Using Multi-Region Spot Instances to Minimize AI Batch Job Cost**
  - **tags:** [mlsys], [cluster infrastructure], [multi-region scheduling, spot instances, cost minimization, deadline guarantee, lightweight probing, lifetime prediction, migration cost]
  - **authors:** Zhifei Li, Tian Xia, Ziming Mao, Zihan Zhou, Ethan J. Jackson, Jamison Kerney, Zhanghao Wu, Pratik Mishra, Yi Xu, Yifan Qiao, Scott Shenker, Ion Stoica
  - **institution:** UC Berkeley, Shanghai Jiao Tong University, AMD, ICSI
  - **link:** https://arxiv.org/pdf/2601.06520
  - **Simple LLM Summary:** SkyNomad is a multi-region scheduling system that minimizes the cost of AI batch jobs by exploiting spatial and temporal heterogeneity in spot instance availability and prices, while guaranteeing deadlines. It uses a cost model that incorporates regional characteristics, migration overhead, and deadline pressure to guide scheduling decisions. The evaluation shows it achieves significant cost savings in real deployments and performs close to an optimal policy while consistently meeting deadlines.

- **[arXiv260113] Learning-Augmented Performance Model for Tensor Product Factorization in High-Order FEM**
  - **tags:** [mlsys], [GPU kernels], [performance modeling, XGBoost, sum-factorization, tensor n-mode product, dependency-chain analysis, loop-body splitting]
  - **authors:** Xuanzhengbo Ren, Yuta Kawai, Tetsuya Hoshino, Hirofumi Tomita, Takahiro Katagiri, Daichi Mukunoki, Seiya Nishizawa
  - **institution:** Nagoya University, RIKEN R-CCS
  - **link:** https://arxiv.org/pdf/2601.06886
  - **Simple LLM Summary:** This paper develops a learning-augmented performance model for tensor product factorization kernels in high-order FEM, combining a dependency-chain-based analytical formulation with XGBoost to estimate key parameters. The model is designed to predict instruction-level efficiency, particularly for loop-splitting strategies on processors like the Fujitsu A64FX. Evaluations show it significantly outperforms standard Roofline and ECM models in prediction accuracy across different polynomial orders and processors.

- **[arXiv260113] Employ SmartNICs' Data Path Accelerators for Ordered Key-Value Stores**
  - **tags:** [sys], [distributed systems], [SmartNIC, Data Path Accelerator (DPA), learned index, lock-free, PCIe, DMA, RDMA, stateless clients]
  - **authors:** Frederic Schimmelpfennig, Jan Sass, Reza Salkhordeh, Martin Kröning, Stefan Lankes, André Brinkmann
  - **institution:** Johannes Gutenberg University Mainz, RWTH Aachen University
  - **link:** https://arxiv.org/pdf/2601.06231
  - **Simple LLM Summary:** This paper introduces a key-value store that uses the Data Path Accelerators (DPAs) on a BlueField-3 SmartNIC to process requests directly on the NIC, employing a lock-free learned index in local memory to enable efficient range queries and stateless clients. It defers host memory access to minimize PCIe crossings and batches writes for performance. The system achieves high throughput for point and range queries, matching or exceeding state-of-the-art solutions while suggesting hardware improvements for further gains.

- **[arXiv260113] SC-MII: Infrastructure LiDAR-based 3D Object Detection on Edge Devices for Split Computing with Multiple Intermediate Outputs Integration**
  - **tags:** [mlsys], [others], [split computing, edge computing, intermediate output integration, 3D object detection, LiDAR, point cloud]
  - **authors:** Taisuke Noguchi, Takayuki Nishio, Takuya Azumi
  - **institution:** Saitama University, Institute of Science Tokyo
  - **link:** https://arxiv.org/pdf/2601.07119
  - **Simple LLM Summary:** This paper proposes SC-MII, a method for 3D object detection using multiple infrastructure LiDARs. It employs split computing where edge devices process initial DNN layers and send intermediate features to a server for integration and final inference, reducing device load and latency. Experiments show a significant speed-up and reduction in edge processing time with minimal accuracy loss.

- **[arXiv260113] MegaFlow: Large-Scale Distributed Orchestration System for the Agentic Era**
  - **tags:** [mlsys], [cluster infrastructure], [distributed orchestration, three-service architecture, agent-environment interaction, resource allocation, task scheduling]
  - **authors:** Lei Zhang, Mouxiang Chen, Ruisheng Cao, Jiawei Chen, Fan Zhou, Yiheng Xu, Jiaxi Yang, Liang Chen, Changwei Luo, Kai Zhang, Fan Yan, KaShun Shum, Jiajun Zhang, Zeyu Cui, Hu Feng, Junyang Lin, Binyuan Hui, Min Yang
  - **institution:** Shenzhen Institutes of Advanced Technology, Chinese Academy of Sciences; University of Chinese Academy of Sciences; Alibaba Group
  - **link:** https://arxiv.org/pdf/2601.07526
  - **Simple LLM Summary:** The paper presents MegaFlow, a large-scale distributed orchestration system designed for training AI agents. It abstracts the infrastructure into three independent services (Model, Agent, Environment) to enable flexible scaling and efficient management of tens of thousands of concurrent agent tasks. The system addresses a critical infrastructure gap for large-scale agent training in complex domains like software engineering.

- **[arXiv260113] Divergence-Based Adaptive Aggregation for Byzantine Robust Federated Learning**
  - **tags:** [mlsys], [fault-tolerance], [divergence of degree, linear calibration, vetted root dataset, Byzantine attacks, client drift, federated learning]
  - **authors:** Bingnan Xiao, Feng Zhu, Jingjing Zhang, Wei Ni, Xin Wang
  - **institution:** Fudan University, North Carolina State University, Edith Cowan University, University of New South Wales
  - **link:** https://arxiv.org/pdf/2601.06903
  - **Simple LLM Summary:** The paper proposes two federated learning frameworks, DRAG and BR-DRAG, which use a divergence metric and reference directions to calibrate local updates, mitigating client drift and resisting Byzantine attacks. The methods are proven to achieve fast convergence under data heterogeneity and attacks, with experiments showing superior performance in handling drifts and maintaining robustness.

- **[arXiv260113] Peformance Isolation for Inference Processes in Edge GPU Systems**
  - **tags:** [mlsys], [llm inference], [MPS, MIG, Green Contexts, temporal isolation, GPU partitioning, performance predictability]
  - **authors:** Juan José Martín, José Flich, Carles Hernández
  - **institution:** Universitat Politècnica de València
  - **link:** https://arxiv.org/pdf/2601.07600
  - **Simple LLM Summary:** This paper analyzes GPU isolation mechanisms (MPS, MIG, Green Contexts) to ensure predictable inference times for deep learning models in safety-critical edge systems. It finds that MIG offers high isolation, while Green Contexts provide fine-grained SM allocation with low overhead for edge devices, though lacking memory isolation.

- **[arXiv260113] Bringing Computation to the data: Interoperable serverless function execution for astrophysical data analysis in the SRCNet**
  - **tags:** [sys], [scientific computing], [serverless computing, Function-as-a-Service (FaaS), data-proximate computation, SKA Regional Centre Network (SRCNet), Gaussian convolution]
  - **authors:** Manuel Parra-Royón, Julián Garrido-Sánchez, Susana Sánchez-Expósito, María Ángeles Mendoza, Rob Barnsley, Anthony Moraghan, Jesús Sánchez, Laura Darriba, Carlos Ruíz-Monje, Edgar Joao, Javier Moldón, Jesús Salgado, Lourdes Verdes-Montenegro
  - **institution:** Instituto de Astrofísica de Andalucía, Square Kilometre Array Observatory (SKAO), University of Sevilla, University of Manchester
  - **link:** https://arxiv.org/pdf/2601.07308
  - **Simple LLM Summary:** This paper explores the application of serverless computing and Function-as-a-Service (FaaS) to enable data-proximate astrophysical analysis within the federated SKA Regional Centre Network. It develops and deploys representative analysis functions, such as a Gaussian convolution, directly at data storage sites. The results demonstrate that this approach provides a scalable and efficient pathway to handle the massive data volumes expected from the Square Kilometre Array.

- **[arXiv260113] Advanced computing for reproducibility of astronomy Big Data Science, with a showcase of AMIGA and the SKA Science prototype**
  - **tags:** [sys], [astronomy big data infrastructure], [semantic data models, federated infrastructures, reproducibility, open science, SKA Regional Centre Network]
  - **authors:** Julián Garrido, Susana Sánchez, Edgar Ribeiro João, Roger Ianjamasimanana, Manuel Parra, Lourdes Verdes-Montenegro
  - **institution:** Instituto de Astrofísica de Andalucía, CSIC
  - **link:** https://arxiv.org/pdf/2601.07439
  - **Simple LLM Summary:** The paper presents research by the AMIGA group addressing computing and reproducibility challenges for the SKA Observatory through advancements in semantic data models and analysis services integrated into federated infrastructures. It concludes that for the SKAO to succeed, the development of the SKA Regional Centre Network must explicitly incorporate reproducibility requirements into its fundamental architectural design to enable verifiable and sustainable research.

- **[arXiv260113] OpenTinker: Separating Concerns in Agentic Reinforcement Learning**
  - **tags:** [mlsys], [llm training], [reinforcement learning, large language model agents, separation of concerns, composable components, managed execution runtime, centralized scheduler, LoRA, full-parameter RL, supervised fine-tuning]
  - **authors:** Siqi Zhu, Jiaxuan You
  - **institution:** University of Illinois Urbana-Champaign
  - **link:** https://arxiv.org/pdf/2601.07376
  - **Simple LLM Summary:** The paper introduces OpenTinker, an infrastructure framework that separates concerns in agentic reinforcement learning by decomposing systems into lightweight, composable components for agents, environments, and interaction protocols, delegating inference and training to a managed runtime. It uses a centralized scheduler to manage diverse workloads like LoRA-based and full-parameter RL over shared resources. The main conclusion is that this design effectively addresses systems challenges in RL for LLM agents and demonstrates practical utility in agentic learning scenarios.

- **[arXiv260113] Beyond Single-GPU: Scaling PDLP to Distributed Multi-GPU Systems**
  - **tags:** [mlsys], [GPU kernels], [PDHG, distributed multi-GPU, two-dimensional grid partitioning, NCCL communication, block-wise random shuffling, nonzero-aware data distribution, fused CUDA kernels]
  - **authors:** Hongpei Li, Yicheng Huang, Huikang Liu, Dongdong Ge, Yinyu Ye
  - **institution:** Cardinal Operations, Shanghai University of Finance and Economics, Shanghai Jiao Tong University, Stanford University
  - **link:** https://arxiv.org/pdf/2601.07628
  - **Simple LLM Summary:** This paper presents a distributed multi-GPU implementation of the Primal-Dual Hybrid Gradient (PDHG) algorithm for solving large-scale linear programming problems. The method uses two-dimensional grid partitioning and optimized communication to scale across GPUs, overcoming memory bottlenecks. The results show strong scalability and performance improvements while maintaining numerical accuracy.


**cs.AI/cs.LG contains "reinforcement learning" total: 50**
- [arXiv260113] No More Stale Feedback: Co-Evolving Critics for Open-World Agent Learning [link](https://arxiv.org/pdf/2601.06794)
- [arXiv260113] From RLHF to Direct Alignment: A Theoretical Unification of Preference Learning for Large Language Models [link](https://arxiv.org/pdf/2601.06108)
- [arXiv260113] GDEPO: Group Dual-dynamic and Equal-right-advantage Policy Optimization with Enhanced Training Data Utilization for Sample-Constrained Reinforcement Learning [link](https://arxiv.org/pdf/2601.06795)
- [arXiv260113] A Brain-like Synergistic Core in LLMs Drives Behaviour and Learning [link](https://arxiv.org/pdf/2601.06851)
- [arXiv260113] Characterising Toxicity in Generative Large Language Models [link](https://arxiv.org/pdf/2601.06700)
- [arXiv260113] Thinking with Deltas: Incentivizing Reinforcement Learning via Differential Visual Reasoning Policy [link](https://arxiv.org/pdf/2601.06801)
- [arXiv260113] GanitLLM: Difficulty-Aware Bengali Mathematical Reasoning through Curriculum-GRPO [link](https://arxiv.org/pdf/2601.06767)
- [arXiv260113] HiMeS: Hippocampus-inspired Memory System for Personalized AI Assistants [link](https://arxiv.org/pdf/2601.06152)
- [arXiv260113] Plasticity vs. Rigidity: The Impact of Low-Rank Adapters on Reasoning on a Micro-Budget [link](https://arxiv.org/pdf/2601.06677)
- [arXiv260113] A Review of Online Diffusion Policy RL Algorithms for Scalable Robotic Control [link](https://arxiv.org/pdf/2601.06133)
- [arXiv260113] The Impact of Post-training on Data Contamination [link](https://arxiv.org/pdf/2601.06103)
- [arXiv260113] KASER: Knowledge-Aligned Student Error Simulator for Open-Ended Coding Tasks [link](https://arxiv.org/pdf/2601.06633)
- [arXiv260113] Deep Q-Network Based Resilient Drone Communication:Neutralizing First-Order Markov Jammers [link](https://arxiv.org/pdf/2601.06095)
- [arXiv260113] Toward Safe and Responsible AI Agents: A Three-Pillar Model for Transparency, Accountability, and Trustworthiness [link](https://arxiv.org/pdf/2601.06223)
- [arXiv260113] TimeGNN-Augmented Hybrid-Action MARL for Fine-Grained Task Partitioning and Energy-Aware Offloading in MEC [link](https://arxiv.org/pdf/2601.06191)
- [arXiv260113] Personality-Aware Reinforcement Learning for Persuasive Dialogue with LLM-Driven Simulation [link](https://arxiv.org/pdf/2601.06877)
- [arXiv260113] Future-as-Label: Scalable Supervision from Real-World Outcomes [link](https://arxiv.org/pdf/2601.06336)
- [arXiv260113] ArenaRL: Scaling RL for Open-Ended Agents via Tournament-based Relative Ranking [link](https://arxiv.org/pdf/2601.06487)
- [arXiv260113] Reinforcement Learning for Chain of Thought Compression with One-Domain-to-All Generalization [link](https://arxiv.org/pdf/2601.06052)
- [arXiv260113] Code Evolution for Control: Synthesizing Policies via LLM-Driven Evolutionary Search [link](https://arxiv.org/pdf/2601.06845)
- [arXiv260113] How well can off-the-shelf LLMs elucidate molecular structures from mass spectra using chain-of-thought reasoning? [link](https://arxiv.org/pdf/2601.06289)
- [arXiv260113] Object-Centric World Models Meet Monte Carlo Tree Search [link](https://arxiv.org/pdf/2601.06604)
- [arXiv260113] Reinforcement Learning-Guided Dynamic Multi-Graph Fusion for Evacuation Traffic Prediction [link](https://arxiv.org/pdf/2601.06664)
- [arXiv260113] COVR:Collaborative Optimization of VLMs and RL Agent for Visual-Based Control [link](https://arxiv.org/pdf/2601.06122)
- [arXiv260113] Distributional Clarity: The Hidden Driver of RL-Friendliness in Large Language Models [link](https://arxiv.org/pdf/2601.06911)
- [arXiv260113] X-Coder: Advancing Competitive Programming with Fully Synthetic Tasks, Solutions, and Tests [link](https://arxiv.org/pdf/2601.06953)
- [arXiv260113] MEDVISTAGYM: A Scalable Training Environment for Thinking with Medical Images via Tool-Integrated Reinforcement Learning [link](https://arxiv.org/pdf/2601.07107)
- [arXiv260113] Enhancing Cloud Network Resilience via a Robust LLM-Empowered Multi-Agent Reinforcement Learning Framework [link](https://arxiv.org/pdf/2601.07122)
- [arXiv260113] ENTRA: Entropy-Based Redundancy Avoidance in Large Language Model Reasoning [link](https://arxiv.org/pdf/2601.07123)
- [arXiv260113] Generating readily synthesizable small molecule fluorophore scaffolds with reinforcement learning [link](https://arxiv.org/pdf/2601.07145)
- [arXiv260113] Rewarding Creativity: A Human-Aligned Generative Reward Model for Reinforcement Learning in Storytelling [link](https://arxiv.org/pdf/2601.07149)
- [arXiv260113] AscendKernelGen: A Systematic Study of LLM-Based Kernel Generation for Neural Processing Units [link](https://arxiv.org/pdf/2601.07160)
- [arXiv260113] Offline Meta-Reinforcement Learning with Flow-Based Task Inference and Adaptive Correction of Feature Overgeneralization [link](https://arxiv.org/pdf/2601.07164)
- [arXiv260113] Consolidation or Adaptation? PRISM: Disentangling SFT and RL Data via Gradient Concentration [link](https://arxiv.org/pdf/2601.07224)
- [arXiv260113] Group Pattern Selection Optimization: Let LRMs Pick the Right Pattern for Reasoning [link](https://arxiv.org/pdf/2601.07238)
- [arXiv260113] LRAS: Advanced Legal Reasoning with Agentic Search [link](https://arxiv.org/pdf/2601.07296)
- [arXiv260113] Heterogeneous Multi-Expert Reinforcement Learning for Long-Horizon Multi-Goal Tasks in Autonomous Forklifts [link](https://arxiv.org/pdf/2601.07304)
- [arXiv260113] Segmental Advantage Estimation: Enhancing PPO for Long-Context LLM Training [link](https://arxiv.org/pdf/2601.07320)
- [arXiv260113] On the Non-decoupling of Supervised Fine-tuning and Reinforcement Learning in Post-training [link](https://arxiv.org/pdf/2601.07389)
- [arXiv260113] Outcome-Grounded Advantage Reshaping for Fine-Grained Credit Assignment in Mathematical Reasoning [link](https://arxiv.org/pdf/2601.07408)
- [arXiv260113] Puzzle it Out: Local-to-Global World Model for Offline Multi-Agent Reinforcement Learning [link](https://arxiv.org/pdf/2601.07463)
- [arXiv260113] Graph Inference Towards ICD Coding [link](https://arxiv.org/pdf/2601.07496)
- [arXiv260113] Controlling Multimodal Conversational Agents with Coverage-Enhanced Latent Actions [link](https://arxiv.org/pdf/2601.07516)
- [arXiv260113] Stagewise Reinforcement Learning and the Geometry of the Regret Landscape [link](https://arxiv.org/pdf/2601.07524)
- [arXiv260113] GRPO with State Mutations: Improving LLM-Based Hardware Test Plan Generation [link](https://arxiv.org/pdf/2601.07593)
- [arXiv260113] Hiking in the Wild: A Scalable Perceptive Parkour Framework for Humanoids [link](https://arxiv.org/pdf/2601.07718)
- [arXiv260113] Beyond Single-Shot: Multi-step Tool Retrieval via Query Planning [link](https://arxiv.org/pdf/2601.07782)
- [arXiv260113] Failure-Aware RL: Reliable Offline-to-Online Reinforcement Learning with Self-Recovery for Real-World Manipulation [link](https://arxiv.org/pdf/2601.07821)
- [arXiv260113] Large Language Models for Physics Instrument Design [link](https://arxiv.org/pdf/2601.07580)
- [arXiv260113] Reinforcement Learning for Micro-Level Claims Reserving [link](https://arxiv.org/pdf/2601.07637)

**cs.AI/cs.LG contains "accelerate" total: 18**
- [arXiv260113] Bridging the AI divide in sub-Saharan Africa: Challenges and opportunities for inclusivity [link](https://arxiv.org/pdf/2601.06145)
- [arXiv260113] GDEPO: Group Dual-dynamic and Equal-right-advantage Policy Optimization with Enhanced Training Data Utilization for Sample-Constrained Reinforcement Learning [link](https://arxiv.org/pdf/2601.06795)
- [arXiv260113] Channel Knowledge Map Construction via Guided Flow Matching [link](https://arxiv.org/pdf/2601.06156)
- [arXiv260113] Attention in Geometry: Scalable Spatial Modeling via Adaptive Density Fields and FAISS-Accelerated Kernels [link](https://arxiv.org/pdf/2601.06135)
- [arXiv260113] Pareto-Optimal Model Selection for Low-Cost, Single-Lead EMG Control in Embedded Systems [link](https://arxiv.org/pdf/2601.06516)
- [arXiv260113] Logic-Driven Semantic Communication for Resilient Multi-Agent Systems [link](https://arxiv.org/pdf/2601.06733)
- [arXiv260113] TeleMem: Building Long-Term and Multimodal Memory for Agentic AI [link](https://arxiv.org/pdf/2601.06037)
- [arXiv260113] Lower Bounds for the Algorithmic Complexity of Learned Indexes [link](https://arxiv.org/pdf/2601.06629)
- [arXiv260113] MicLog: Towards Accurate and Efficient LLM-based Log Parsing via Progressive Meta In-Context Learning [link](https://arxiv.org/pdf/2601.07005)
- [arXiv260113] Jasper: ANNS Quantized for Speed, Built for Change on GPU [link](https://arxiv.org/pdf/2601.07048)
- [arXiv260113] AscendKernelGen: A Systematic Study of LLM-Based Kernel Generation for Neural Processing Units [link](https://arxiv.org/pdf/2601.07160)
- [arXiv260113] When Bots Take the Bait: Exposing and Mitigating the Emerging Social Engineering Attack in Web Automation Agent [link](https://arxiv.org/pdf/2601.07263)
- [arXiv260113] Software-Hardware Co-optimization for Modular E2E AV Paradigm: A Unified Framework of Optimization Approaches, Simulation Environment and Evaluation Metrics [link](https://arxiv.org/pdf/2601.07393)
- [arXiv260113] PLANET v2.0: A comprehensive Protein-Ligand Affinity Prediction Model Based on Mixture Density Network [link](https://arxiv.org/pdf/2601.07415)
- [arXiv260113] Pheromone-Focused Ant Colony Optimization algorithm for path planning [link](https://arxiv.org/pdf/2601.07597)
- [arXiv260113] Learning to accelerate Krasnosel'skii-Mann fixed-point iterations with guarantees [link](https://arxiv.org/pdf/2601.07665)
- [arXiv260113] Match Made with Matrix Completion: Efficient Learning under Matching Interference [link](https://arxiv.org/pdf/2601.06982)
- [arXiv260113] A Model of Artificial Jagged Intelligence [link](https://arxiv.org/pdf/2601.07573)

## 2026-01-14

**cs.DC total: 9**

- **[arXiv260114] Improving Zero-shot ADL Recognition with Large Language Models through Event-based Context and Confidence**
  - **tags:** [mlsys], [llm inference], [zero-shot learning, event-based segmentation, confidence estimation, prompting strategies]
  - **authors:** Michele Fiori, Gabriele Civitarese, Marco Colussi, Claudio Bettini
  - **institution:** University of Milan
  - **link:** https://arxiv.org/pdf/2601.08241
  - **Simple LLM Summary:** This paper proposes a zero-shot method for Activity of Daily Living (ADL) recognition using Large Language Models (LLMs) with event-based segmentation and a novel confidence estimation technique. It shows that event-based segmentation outperforms traditional time-based LLM approaches and even surpasses supervised methods on complex datasets. The proposed confidence measure effectively identifies correct predictions.

- **[arXiv260114] Multivariate Polynomial Codes for Efficient Matrix Chain Multiplication in Distributed Systems**
  - **tags:** [mlsys], [fault-tolerance], [multivariate polynomial coding, coded distributed computing, matrix chain multiplication, straggler mitigation, storage-computation trade-off]
  - **authors:** Jesús Gómez-Vilardebò
  - **institution:** Centre Tecnològic de Telecomunicacions de Catalunya (CTTC/CERCA)
  - **link:** https://arxiv.org/pdf/2601.08708
  - **Simple LLM Summary:** This paper proposes two novel multivariate polynomial coding schemes for distributed matrix chain multiplication to mitigate the straggler problem. The results show that these codes introduce additional computational cost but dramatically reduce storage overhead compared to univariate polynomial codes, revealing a fundamental trade-off between computation and storage efficiency.

- **[arXiv260114] MixServe: An Automatic Distributed Serving System for MoE Models with Hybrid Parallelism Based on Fused Communication Algorithm**
  - **tags:** [mlsys], [llm inference], [tensor parallelism, expert parallelism, hybrid parallelism, fused communication, all-reduce, all-to-all]
  - **authors:** Bowen Zhou, Jinrui Jia, Wenhao He, Yong Zhang, Fang Dong
  - **institution:** Southeast University, The Chinese University of Hong Kong
  - **link:** https://arxiv.org/pdf/2601.08800
  - **Simple LLM Summary:** MixServe is an automatic distributed serving system for MoE models that introduces a novel TP-EP hybrid parallelism strategy based on a fused AR-A2A communication algorithm to overlap intra- and inter-node communication. It automatically selects the most efficient parallel strategy by evaluating communication overhead. Experiments show it significantly accelerates inference latency and improves throughput compared to existing approaches.

- **[arXiv260114] Coordinated Cooling and Compute Management for AI Datacenters**
  - **tags:** [mlsys], [llm inference], [hierarchical control, DVFS, GPU profiling, thermal modeling, cooling management]
  - **authors:** Nardos Belay Abera, Yize Chen
  - **institution:** University of Alberta
  - **link:** https://arxiv.org/pdf/2601.08113
  - **Simple LLM Summary:** The paper proposes a hierarchical control framework that co-optimizes computing and thermal management in AI datacenters by jointly modeling workload and thermal dynamics to control GPU parallelism, frequency (DVFS), and cooling. Using real Azure traces and GPU profiling, the method balances serving latency and thermal constraints. It concludes that this coordinated approach significantly improves the energy efficiency of AI datacenters.

- **[arXiv260114] Hierarchical Online-Scheduling for Energy-Efficient Split Inference with Progressive Transmission**
  - **tags:** [mlsys], [others], [split inference, Lyapunov optimization, hierarchical scheduling, progressive transmission, device-edge collaboration, energy efficiency]
  - **authors:** Zengzipeng Tang, Yuxuan Sun, Wei Chen, Jianwen Ding, Bo Ai, Yulin Shao
  - **institution:** Beijing Jiaotong University, The University of Hong Kong
  - **link:** https://arxiv.org/pdf/2601.08135
  - **Simple LLM Summary:** This paper proposes ENACHI, a hierarchical online-scheduling framework for split inference that jointly optimizes task- and packet-level decisions using a two-tier Lyapunov-based approach and progressive transmission. It aims to maximize inference accuracy under energy and delay constraints. Experiments show ENACHI significantly improves accuracy and reduces energy consumption compared to benchmarks, demonstrating high scalability in multi-user scenarios.

- **[arXiv260114] Matrix-PIC: Harnessing Matrix Outer-product for High-Performance Particle-in-Cell Simulations**
  - **tags:** [sys], [high-performance computing], [matrix processing units, particle-in-cell, outer-product, hybrid MPU-VPU pipeline, incremental sorting]
  - **authors:** Yizhuo Rao, Xingjian Cui, Jiabin Xie, Shangzhi Pang, Guangnan Feng, Jinhui Wei, Zhiguang Chen, Yutong Lu
  - **institution:** Sun Yat-Sen University
  - **link:** https://arxiv.org/pdf/2601.08277
  - **Simple LLM Summary:** This paper introduces Matrix-PIC, a framework that redesigns Particle-in-Cell simulations to use a block-matrix formulation for current deposition, leveraging CPU Matrix Processing Units for outer-product operations. It employs a hybrid MPU-VPU execution pipeline and an incremental particle sorter to maintain data locality. The method achieves significant speedups, demonstrating the effectiveness of matrix-oriented co-design on modern CPU architectures.

- **[arXiv260114] Where to Split? A Pareto-Front Analysis of DNN Partitioning for Edge Inference**
  - **tags:** [mlsys], [others], [DNN partitioning, pipeline partitioning, Pareto front analysis, multi-objective optimization, edge inference, PyTorch RPC, latency-throughput trade-off]
  - **authors:** Adiba Masud, Nicholas Foley, Pragathi Durga Rajarajan, Palden Lama
  - **institution:** The University of Texas at San Antonio
  - **link:** https://arxiv.org/pdf/2601.08025
  - **Simple LLM Summary:** This paper introduces ParetoPipe, a framework that reframes DNN partitioning as a multi-objective optimization problem, using Pareto front analysis to identify optimal strategies balancing latency and throughput for edge inference. The main conclusion is that real-world deployments require navigating a complex trade-off space, and the framework's benchmarking on a heterogeneous testbed reveals these Pareto-optimal points under varying network conditions.

- **[arXiv260114] Hierarchical Precision and Recursion for Accelerating Symmetric Linear Solves on MXUs**
  - **tags:** [mlsys], [GPU kernels], [mixed-precision, recursive algorithms, Cholesky decomposition, triangular solve (TRSM), symmetric rank-k update (SYRK), hierarchical recursion, Julia language, tensor cores, matrix processing units (MXUs)]
  - **authors:** Vicki Carrica, Rabab Alomairy, Evelyne Ringoot, Alan Edelman
  - **institution:** Massachusetts Institute of Technology
  - **link:** https://arxiv.org/pdf/2601.08082
  - **Simple LLM Summary:** The paper presents a portable, mixed-precision solver for symmetric linear systems on Matrix Processing Units (MXUs) using a nested recursive algorithm that assigns low-precision arithmetic to off-diagonal blocks and high precision to diagonal blocks for stability. Implemented in Julia, it achieves significant speedups over standard libraries on NVIDIA and AMD hardware while maintaining high numerical accuracy.

- **[arXiv260114] Shifting the Sweet Spot: High-Performance Matrix-Free Method for High-Order Elasticity**
  - **tags:** [sys], [high-performance computing], [matrix-free method, sum-factorization, tensor factorization, Voigt symmetry, macro-kernel fusion, geometric multigrid]
  - **authors:** Dali Chang, Chong Zhang, Kaiqi Zhang, Mingguan Yang, Huiyuan Li, Weiqiang Kong
  - **institution:** Dalian University of Technology, Institute of Software Chinese Academy of Sciences, National Technology Innovation Center of Guangdong-Hong Kong-Macao Greater Bay Area
  - **link:** https://arxiv.org/pdf/2601.08374
  - **Simple LLM Summary:** The paper presents an optimized matrix-free operator for high-order finite element elasticity simulations, using tensor factorization, Voigt symmetry, and macro-kernel fusion to improve computational efficiency. This approach successfully shifts the performance sweet spot to higher polynomial orders (p ≥ 6), achieving significant speedups over the baseline MFEM implementation. The work provides a practical path for large-scale, high-order elasticity simulations on mainstream CPU hardware.


**cs.AI/cs.LG contains "reinforcement learning" total: 28**
- [arXiv260114] Scalable Multiagent Reinforcement Learning with Collective Influence Estimation [link](https://arxiv.org/pdf/2601.08210)
- [arXiv260114] TerraFormer: Automated Infrastructure-as-Code with LLMs Fine-Tuned via Policy-Guided Verifier Feedback [link](https://arxiv.org/pdf/2601.08734)
- [arXiv260114] The End of Reward Engineering: How LLMs Are Redefining Multi-Agent Coordination [link](https://arxiv.org/pdf/2601.08237)
- [arXiv260114] Rewarding the Rare: Uniqueness-Aware RL for Creative Problem Solving in LLMs [link](https://arxiv.org/pdf/2601.08763)
- [arXiv260114] AUV Trajectory Learning for Underwater Acoustic Energy Transfer and Age Minimization [link](https://arxiv.org/pdf/2601.08491)
- [arXiv260114] RubricHub: A Comprehensive and Highly Discriminative Rubric Dataset via Automated Coarse-to-Fine Generation [link](https://arxiv.org/pdf/2601.08430)
- [arXiv260114] STO-RL: Offline RL under Sparse Rewards via LLM-Guided Subgoal Temporal Order [link](https://arxiv.org/pdf/2601.08107)
- [arXiv260114] Large Multimodal Models for Embodied Intelligent Driving: The Next Frontier in Self-Driving? [link](https://arxiv.org/pdf/2601.08434)
- [arXiv260114] Your Group-Relative Advantage Is Biased [link](https://arxiv.org/pdf/2601.08521)
- [arXiv260114] JudgeRLVR: Judge First, Generate Second for Efficient Reasoning [link](https://arxiv.org/pdf/2601.08468)
- [arXiv260114] Reasoning over Precedents Alongside Statutes: Case-Augmented Deliberative Alignment for LLM Safety [link](https://arxiv.org/pdf/2601.08000)
- [arXiv260114] Large Artificial Intelligence Model Guided Deep Reinforcement Learning for Resource Allocation in Non Terrestrial Networks [link](https://arxiv.org/pdf/2601.08254)
- [arXiv260114] ORBIT: On-policy Exploration-Exploitation for Controllable Multi-Budget Reasoning [link](https://arxiv.org/pdf/2601.08310)
- [arXiv260114] Provably Safe Reinforcement Learning using Entropy Regularizer [link](https://arxiv.org/pdf/2601.08646)
- [arXiv260114] Reverse Flow Matching: A Unified Framework for Online Reinforcement Learning with Diffusion and Flow Policies [link](https://arxiv.org/pdf/2601.08136)
- [arXiv260114] Owen-Shapley Policy Optimization (OSPO): A Principled RL Algorithm for Generative Search LLMs [link](https://arxiv.org/pdf/2601.08403)
- [arXiv260114] AtomMem : Learnable Dynamic Agentic Memory with Atomic Memory Operation [link](https://arxiv.org/pdf/2601.08323)
- [arXiv260114] From Classical to Quantum Reinforcement Learning and Its Applications in Quantum Control: A Beginner's Tutorial [link](https://arxiv.org/pdf/2601.08662)
- [arXiv260114] Incorporating Cognitive Biases into Reinforcement Learning for Financial Decision-Making [link](https://arxiv.org/pdf/2601.08247)
- [arXiv260114] Safe Heterogeneous Multi-Agent RL with Communication Regularization for Coordinated Target Acquisition [link](https://arxiv.org/pdf/2601.08327)
- [arXiv260114] ZeroDVFS: Zero-Shot LLM-Guided Core and Frequency Allocation for Embedded Platforms [link](https://arxiv.org/pdf/2601.08166)
- [arXiv260114] PersonaDual: Balancing Personalization and Objectivity via Adaptive Reasoning [link](https://arxiv.org/pdf/2601.08679)
- [arXiv260114] Reinforcement Learning Methods for Neighborhood Selection in Local Search [link](https://arxiv.org/pdf/2601.07948)
- [arXiv260114] Multiplex Thinking: Reasoning via Token-wise Branch-and-Merge [link](https://arxiv.org/pdf/2601.08808)
- [arXiv260114] Structure Detection for Contextual Reinforcement Learning [link](https://arxiv.org/pdf/2601.08120)
- [arXiv260114] Forecast Aware Deep Reinforcement Learning for Efficient Electricity Load Scheduling in Dairy Farms [link](https://arxiv.org/pdf/2601.08052)
- [arXiv260114] Model-Agnostic Solutions for Deep Reinforcement Learning in Non-Ergodic Contexts [link](https://arxiv.org/pdf/2601.08726)
- [arXiv260114] FigEx2: Visual-Conditioned Panel Detection and Captioning for Scientific Compound Figures [link](https://arxiv.org/pdf/2601.08026)

**cs.AI/cs.LG contains "accelerate" total: 7**
- [arXiv260114] Pervasive Annotation Errors Break Text-to-SQL Benchmarks and Leaderboards [link](https://arxiv.org/pdf/2601.08778)
- [arXiv260114] Internal Deployment Gaps in AI Regulation [link](https://arxiv.org/pdf/2601.08005)
- [arXiv260114] Reducing Compute Waste in LLMs through Kernel-Level DVFS [link](https://arxiv.org/pdf/2601.08539)
- [arXiv260114] Dynamic Graph Structure Learning via Resistance Curvature Flow [link](https://arxiv.org/pdf/2601.08149)
- [arXiv260114] HIPPO: Accelerating Video Large Language Models Inference via Holistic-aware Parallel Speculative Decoding [link](https://arxiv.org/pdf/2601.08273)
- [arXiv260114] DataScribe: An AI-Native, Policy-Aligned Web Platform for Multi-Objective Materials Design and Discovery [link](https://arxiv.org/pdf/2601.07966)
- [arXiv260114] Autonomous Materials Exploration by Integrating Automated Phase Identification and AI-Assisted Human Reasoning [link](https://arxiv.org/pdf/2601.08185)

## 2026-01-15

**cs.DC total: 13**

- **[arXiv260115] Transaction-Driven Dynamic Reconfiguration for Certificate-Based Payment Systems**
  - **tags:** [sys], [distributed systems], [Byzantine Consistent Broadcast, dynamic reconfiguration, certificate-based payment, PDCC, PBFT, FastPay]
  - **authors:** Lingkang Shangguan
  - **institution:** The University of Sydney
  - **link:** https://arxiv.org/pdf/2601.09146
  - **Simple LLM Summary:** This paper proposes PDCC, a transaction-driven dynamic reconfiguration protocol for certificate-based payment systems. It builds upon Byzantine Consistent Broadcast to enable smooth membership changes without impacting system performance. The core method combines user nonce-based ordering with periodic consensus to manage configuration updates securely.

- **[arXiv260115] Lean Clients, Full Accuracy: Hybrid Zeroth- and First-Order Split Federated Learning**
  - **tags:** [mlsys], [others], [split federated learning, zeroth-order optimization, first-order optimization, hybrid optimization, auxiliary networks, low effective rank]
  - **authors:** Zhoubin Kou, Zihan Chen, Jing Yang, Cong Shen
  - **institution:** University of Virginia
  - **link:** https://arxiv.org/pdf/2601.09076
  - **Simple LLM Summary:** The paper proposes HERON-SFL, a hybrid split federated learning framework that uses zeroth-order optimization on resource-constrained clients to avoid back-propagation and first-order optimization on the server. This method reduces client memory and computation costs while maintaining model accuracy, as demonstrated on ResNet training and language model fine-tuning tasks.

- **[arXiv260115] Optimizing View Change for Byzantine Fault Tolerance in Parallel Consensus**
  - **tags:** [sys], [distributed systems], [mixed integer programming, Benders decomposition, parallel BFT, view change optimization, leader selection]
  - **authors:** Yifei Xie, Btissam Er-Rahmadi, Xiao Chen, Tiejun Ma, Jane Hillston
  - **institution:** University of Edinburgh, Huawei Technologies R&D, University of Leicester
  - **link:** https://arxiv.org/pdf/2601.09184
  - **Simple LLM Summary:** This paper proposes a View Change Optimization (VCO) model using mixed integer programming and an improved Benders decomposition method to optimize leader selection and follower reassignment in parallel Byzantine Fault Tolerant consensus. The method aims to minimize latency during leader failures by considering communication delays and failure scenarios. Experiments on Microsoft Azure show the VCO-driven approach outperforms existing methods, especially as network size increases.

- **[arXiv260115] LatencyPrism: Online Non-intrusive Latency Sculpting for SLO-Guaranteed LLM Inference**
  - **tags:** [mlsys], [llm inference], [latency sculpting, anomaly detection, root cause analysis, SLO guarantee, non-intrusive monitoring]
  - **authors:** Du Yin, Jiayi Ren, Xiayu Sun, Tianyao Zhou, Haizhu Zhou, Ruiyan Ma, Danyang Zhang
  - **institution:** Alibaba Cloud Computing, Xi'an Jiaotong University
  - **link:** https://arxiv.org/pdf/2601.09258
  - **Simple LLM Summary:** LatencyPrism is a zero-intrusion, multi-platform system for monitoring and sculpting LLM inference latency to guarantee Service Level Objectives (SLOs). It performs real-time anomaly detection and root cause analysis without requiring code changes or service restarts. The system has been deployed at scale, achieving high accuracy in distinguishing workload variations from true anomalies.

- **[arXiv260115] Revisiting Disaggregated Large Language Model Serving for Performance and Energy Implications**
  - **tags:** [mlsys], [llm inference], [KV cache transfer, dynamic voltage and frequency scaling (DVFS), Pareto frontier, disaggregated serving, colocated serving]
  - **authors:** Jiaxi Li, Yue Zhu, Eun Kyung Lee, Klara Nahrstedt
  - **institution:** UIUC, IBM Research
  - **link:** https://arxiv.org/pdf/2601.08833
  - **Simple LLM Summary:** This paper systematically benchmarks disaggregated LLM serving, where prefill and decode stages run on separate GPUs, by evaluating different KV cache transfer paths and optimization strategies like frequency scaling. It finds that performance benefits are not guaranteed and depend on request load and transfer mediums, and that disaggregation does not lead to energy savings due to its inherently higher energy consumption.

- **[arXiv260115] Cluster Workload Allocation: Semantic Soft Affinity Using Natural Language Processing**
  - **tags:** [mlsys], [cluster infrastructure], [kubernetes scheduler extender, natural language processing, large language model, semantic soft affinity, aws bedrock, intent analyzer]
  - **authors:** Leszek Sliwko, Jolanta Mizeria-Pietraszko
  - **institution:** Standard Chartered Bank, Opole University of Technology
  - **link:** https://arxiv.org/pdf/2601.09282
  - **Simple LLM Summary:** This paper introduces a semantic scheduling system that uses a Large Language Model (LLM) to interpret natural language hints for workload placement in a Kubernetes cluster. The prototype demonstrated high parsing accuracy and superior scheduling quality in complex scenarios compared to standard configurations. The results validate the viability of using LLMs for accessible, intent-driven cluster orchestration, though latency remains a challenge for production use.

- **[arXiv260115] Bridging the Gap: Empowering Small Models in Reliable OpenACC-based Parallelization via GEPA-Optimized Prompting**
  - **tags:** [mlsys], [llm inference], [GEPA framework, prompt optimization, genetic algorithm, OpenACC, PolyBench]
  - **authors:** Samyak Jhaveri, Cristina V. Lopes
  - **institution:** University of California, Irvine
  - **link:** https://arxiv.org/pdf/2601.08884
  - **Simple LLM Summary:** This paper introduces a systematic prompt optimization approach using the GEPA (GEnetic-PAreto) framework to enhance the generation of OpenACC pragmas by smaller, cheaper LLMs. The method evolves prompts through a feedback loop guided by expert-curated examples and clause-level mismatches. The results show that optimized prompts significantly improve compilation success rates and functional GPU speedups for small models, enabling cost-effective automated parallelization in HPC workflows.

- **[arXiv260115] DP-FEDSOFIM: Differentially Private Federated Stochastic Optimization using Regularized Fisher Information Matrix**
  - **tags:** [mlsys], [others], [differential privacy, federated learning, second-order optimization, Fisher Information Matrix, Sherman-Morrison formula, gradient preconditioning]
  - **authors:** Sidhant R. Nair, Tanmay Sen, Mrinmay Sen
  - **institution:** Indian Institute of Technology Delhi, Indian Statistical Institute Kolkata, Indian Institute of Technology Hyderabad
  - **link:** https://arxiv.org/pdf/2601.09166
  - **Simple LLM Summary:** The paper proposes DP-FedSOFIM, a differentially private federated learning method that uses a server-side second-order optimization framework with the Fisher Information Matrix as a preconditioner to accelerate convergence. It achieves O(d) memory and computational complexity per client, making it scalable for high-dimensional models while preserving privacy. Empirical results on CIFAR-10 show it achieves higher test accuracy than first-order baselines across various privacy budgets.

- **[arXiv260115] A Machine Learning Approach Towards Runtime Optimisation of Matrix Multiplication**
  - **tags:** [mlsys], [GPU kernels], [machine learning, autotuning, BLAS, GEMM, multi-threading, runtime optimisation]
  - **authors:** Yufan Xia, Marco De La Pierre, Amanda S. Barnard, Giuseppe Maria Junior Barca
  - **institution:** Australian National University, Pawsey Supercomputing Research Centre
  - **link:** https://arxiv.org/pdf/2601.09114
  - **Simple LLM Summary:** This paper proposes a machine learning-based approach to automatically select the optimal number of threads for multi-threaded GEMM (matrix multiplication) operations, implemented in a proof-of-concept library called ADSALA. The method uses on-the-fly ML models trained on collected data to optimize runtime performance. Testing on two HPC architectures showed a 25-40% speedup compared to traditional BLAS implementations for GEMM tasks with memory usage under 100 MB.

- **[arXiv260115] Probabilistic Computers for MIMO Detection: From Sparsification to 2D Parallel Tempering**
  - **tags:** [sys], [hardware acceleration for combinatorial optimization], [probabilistic computers, p-bits, graph sparsification, parallel tempering, FPGA, MIMO detection, Ising Hamiltonian, Two-Dimensional Parallel Tempering (2D-PT)]
  - **authors:** M Mahmudul Hasan Sajeeb, Corentin Delacour, Kevin Callahan-Coray, Sanjay Seshan, Tathagata Srimani, Kerem Y. Camsari
  - **institution:** University of California, Santa Barbara, Carnegie Mellon University
  - **link:** https://arxiv.org/pdf/2601.09037
  - **Simple LLM Summary:** This paper proposes a hardware-accelerated approach for combinatorial optimization using probabilistic computers (p-bits). The core method involves graph sparsification with copy variables to manage dense connectivity and a fully on-chip Two-Dimensional Parallel Tempering (2D-PT) solver implemented on an FPGA, targeting the NP-hard MIMO detection problem. The main conclusion is that this architecture achieves faster convergence and lower bit error rates than conventional detectors, demonstrating a scalable framework for dense optimization problems with promising performance and power projections for ASIC implementations.

- **[arXiv260115] High-Performance Serverless Computing: A Systematic Literature Review on Serverless for HPC, AI, and Big Data**
  - **tags:** [mlsys], [cluster infrastructure], [serverless computing, high-performance computing, systematic literature review, cloud computing, parallel programming]
  - **authors:** Valerio Besozzi, Matteo Della Bartola, Patrizio Dazzi, Marco Danelutto
  - **institution:** University of Pisa, ISTI – National Research Council
  - **link:** https://arxiv.org/pdf/2601.09334
  - **Simple LLM Summary:** This paper conducts a systematic literature review of 122 articles to explore the use of serverless computing for high-performance, AI, and big data workloads. It proposes a taxonomy of research directions and use cases, concluding that serverless is a promising model for improving scalability and resource utilization in compute-intensive applications.

- **[arXiv260115] Network-Based Quantum Computing: an efficient design framework for many-small-node distributed fault-tolerant quantum computing**
  - **tags:** [sys], [quantum computing], [distributed fault-tolerant quantum computing, network-based quantum computation, logical qubit, algorithmic qubit, Bell-state distillation]
  - **authors:** Soshun Naito, Yasunari Suzuki, Yuuki Tokunaga
  - **institution:** The University of Tokyo, NTT Inc., RIKEN
  - **link:** https://arxiv.org/pdf/2601.09374
  - **Simple LLM Summary:** The paper proposes Network-Based Quantum Computation (NBQC), a design framework for distributed fault-tolerant quantum computing using many small nodes. The core method involves continuously moving computational data through the network while maintaining node connectivity. The authors conclude that NBQC achieves shorter execution times than circuit-based strategies and is more node-efficient than measurement-based quantum computing for benchmark tasks.

- **[arXiv260115] AI-NativeBench: An Open-Source White-Box Agentic Benchmark Suite for AI-Native Systems**
  - **tags:** [mlsys], [others], [Model Context Protocol, Agent-to-Agent standards, distributed tracing, white-box benchmarking, agentic spans]
  - **authors:** Zirui Wang, Guangba Yu, Michael R.Lyu
  - **institution:** Sun Yat-sen University, The Chinese University of Hong Kong
  - **link:** https://arxiv.org/pdf/2601.09393
  - **Simple LLM Summary:** This paper introduces AI-NativeBench, an open-source, white-box benchmark suite for evaluating AI-Native systems using Model Context Protocol and Agent-to-Agent standards with distributed tracing. It reveals key engineering insights, such as a parameter paradox where lightweight models outperform larger ones in protocol adherence, and shows that self-healing mechanisms can become cost multipliers in unviable workflows.


**cs.AI/cs.LG contains "reinforcement learning" total: 16**
- [arXiv260115] RISER: Orchestrating Latent Reasoning Skills for Adaptive Activation Steering [link](https://arxiv.org/pdf/2601.09269)
- [arXiv260115] GIFT: Unlocking Global Optimality in Post-Training via Finite-Temperature Gibbs Initialization [link](https://arxiv.org/pdf/2601.09233)
- [arXiv260115] Reward Learning through Ranking Mean Squared Error [link](https://arxiv.org/pdf/2601.09236)
- [arXiv260115] Learning to Trust Experience: A Monitor-Trust-Regulator Framework for Learning under Unobservable Feedback Reliability [link](https://arxiv.org/pdf/2601.09261)
- [arXiv260115] Efficient Paths and Dense Rewards: Probabilistic Flow Reasoning for Large Language Models [link](https://arxiv.org/pdf/2601.09260)
- [arXiv260115] SRT: Accelerating Reinforcement Learning via Speculative Rollout with Tree-Structured Cache [link](https://arxiv.org/pdf/2601.09083)
- [arXiv260115] SkinFlow: Efficient Information Transmission for Open Dermatological Diagnosis via Dynamic Visual Encoding and Staged RL [link](https://arxiv.org/pdf/2601.09136)
- [arXiv260115] Reading or Reasoning? Format Decoupled Reinforcement Learning for Document OCR [link](https://arxiv.org/pdf/2601.08834)
- [arXiv260115] TranslateGemma Technical Report [link](https://arxiv.org/pdf/2601.09012)
- [arXiv260115] Enhancing Spatial Reasoning in Large Language Models for Metal-Organic Frameworks Structure Prediction [link](https://arxiv.org/pdf/2601.09285)
- [arXiv260115] Policy-Based Reinforcement Learning with Action Masking for Dynamic Job Shop Scheduling under Uncertainty: Handling Random Arrivals and Machine Failures [link](https://arxiv.org/pdf/2601.09293)
- [arXiv260115] Monte-Carlo Tree Search with Neural Network Guidance for Lane-Free Autonomous Driving [link](https://arxiv.org/pdf/2601.09353)
- [arXiv260115] GeoRA: Geometry-Aware Low-Rank Adaptation for RLVR [link](https://arxiv.org/pdf/2601.09361)
- [arXiv260115] Draw it like Euclid: Teaching transformer models to generate CAD profiles using ruler and compass construction steps [link](https://arxiv.org/pdf/2601.09428)
- [arXiv260115] DPWriter: Reinforcement Learning with Diverse Planning Branching for Creative Writing [link](https://arxiv.org/pdf/2601.09609)
- [arXiv260115] Collaborative Multi-Agent Test-Time Reinforcement Learning for Reasoning [link](https://arxiv.org/pdf/2601.09667)

**cs.AI/cs.LG contains "accelerate" total: 11**
- [arXiv260115] Navigating Ideation Space: Decomposed Conceptual Representations for Positioning Scientific Ideas [link](https://arxiv.org/pdf/2601.08901)
- [arXiv260115] Layer-Parallel Training for Transformers [link](https://arxiv.org/pdf/2601.09026)
- [arXiv260115] Discrete Solution Operator Learning for Geometry-Dependent PDEs [link](https://arxiv.org/pdf/2601.09143)
- [arXiv260115] SRT: Accelerating Reinforcement Learning via Speculative Rollout with Tree-Structured Cache [link](https://arxiv.org/pdf/2601.09083)
- [arXiv260115] Human-AI Co-design for Clinical Prediction Models [link](https://arxiv.org/pdf/2601.09072)
- [arXiv260115] Hidden States as Early Signals: Step-level Trace Evaluation and Pruning for Efficient Test-Time Scaling [link](https://arxiv.org/pdf/2601.09093)
- [arXiv260115] MMR-GRPO: Accelerating GRPO-Style Training through Diversity-Aware Reward Reweighting [link](https://arxiv.org/pdf/2601.09085)
- [arXiv260115] Mi:dm 2.0 Korea-centric Bilingual Language Models [link](https://arxiv.org/pdf/2601.09066)
- [arXiv260115] Monte-Carlo Tree Search with Neural Network Guidance for Lane-Free Autonomous Driving [link](https://arxiv.org/pdf/2601.09353)
- [arXiv260115] Preliminary Tests of the Anticipatory Classifier System with Hindsight Experience Replay [link](https://arxiv.org/pdf/2601.09400)
- [arXiv260115] Deep Operator Networks for Surrogate Modeling of Cyclic Adsorption Processes with Varying Initial Conditions [link](https://arxiv.org/pdf/2601.09491)

## 2026-01-16

**cs.DC total: 10**

- **[arXiv260116] SCRamble: Adaptive Decentralized Overlay Construction for Blockchain Networks**
  - **tags:** [sys], [blockchain networking], [overlay construction, peer-to-peer, scoring mechanism, network latency, block dissemination]
  - **authors:** Evangelos Kolyvas, Alexandros Antonov, Spyros Voulgaris
  - **institution:** Athens University of Economics and Business
  - **link:** https://arxiv.org/pdf/2601.10277
  - **Simple LLM Summary:** The paper introduces SCRamble, a decentralized protocol that reduces block dissemination time in blockchain networks. It uses a link selection strategy combining a scoring mechanism based on block arrival times and a network latency heuristic. The main conclusion is that this approach significantly accelerates block propagation, improving transaction throughput and system security.

- **[arXiv260116] Fuzzychain-edge: A novel Fuzzy logic-based adaptive Access control model for Blockchain in Edge Computing**
  - **tags:** [sys], [blockchain security], [zero-knowledge proofs, fuzzy logic, smart contracts, access control, blockchain, edge computing]
  - **authors:** Khushbakht Farooq, Muhammad Ibrahim, Irsa Manzoor, Mukhtaj Khan, Wei Song
  - **institution:** IEEE
  - **link:** https://arxiv.org/pdf/2601.10105
  - **Simple LLM Summary:** The paper proposes Fuzzychain-edge, a framework that integrates Zero-Knowledge Proofs, fuzzy logic, and blockchain smart contracts to create an adaptive, context-aware access control model for IoT and edge computing. It concludes that this approach enhances security, privacy, and traceability, providing a more robust solution for sensitive domains like healthcare compared to traditional centralized systems.

- **[arXiv260116] QFed: Parameter-Compact Quantum-Classical Federated Learning**
  - **tags:** [mlsys], [others], [quantum-classical federated learning, variational quantum circuits, parameter reduction, VGG-like model, FashionMNIST]
  - **authors:** Samar Abdelghani, Soumaya Cherkaoui
  - **institution:** Polytechnique Montreal
  - **link:** https://arxiv.org/pdf/2601.09809
  - **Simple LLM Summary:** The paper introduces QFed, a quantum-classical federated learning framework that uses variational quantum circuits to generate parameters for a classical model, achieving a significant reduction in parameter count. It demonstrates a 77.6% parameter reduction in a VGG-like model on the FashionMNIST dataset while maintaining comparable accuracy, showing the potential of quantum computing to enhance federated learning efficiency for edge devices.

- **[arXiv260116] Fundamental Limits of Coded Polynomial Aggregation**
  - **tags:** [sys], [distributed computing], [coded polynomial aggregation, polynomial coded computing, straggler-aware, exact recovery, intersection structure, non-straggler patterns]
  - **authors:** Xi Zhong, Jörg Kliewer, Mingyue Ji
  - **institution:** University of Florida, New Jersey Institute of Technology
  - **link:** https://arxiv.org/pdf/2601.10028
  - **Simple LLM Summary:** This paper introduces a straggler-aware coded polynomial aggregation (CPA) framework for distributed computing, which directly recovers a weighted sum of polynomial evaluations without decoding each term individually. It establishes necessary and sufficient conditions for exact recovery, showing CPA requires fewer worker responses than individual decoding, and provides explicit constructions that achieve the derived fundamental limit.

- **[arXiv260116] Federated Unlearning in Edge Networks: A Survey of Fundamentals, Challenges, Practical Applications and Future Directions**
  - **tags:** [mlsys], [others], [federated learning, federated unlearning, machine unlearning, communication cost, resource allocation, security, privacy]
  - **authors:** Jer Shyuan Ng, Wathsara Daluwatta, Shehan Edirimannage, Charitha Elvitigala, Asitha Kottahachchi Kankanamge Don, Ibrahim Khalil, Heng Zhang, Dusit Niyato
  - **institution:** Nanyang Technological University
  - **link:** https://arxiv.org/pdf/2601.09978
  - **Simple LLM Summary:** This survey paper introduces Federated Unlearning (FUL), a method for removing a client's data influence from a federated learning model to comply with data deletion regulations. It reviews FUL frameworks addressing challenges like communication cost and security, and discusses applications in distributed networks. The paper concludes by highlighting open challenges and future research directions to build trustworthy, regulation-compliant federated systems.

- **[arXiv260116] Clustering-Based User Selection in Federated Learning: Metadata Exploitation for 3GPP Networks**
  - **tags:** [mlsys], [others], [federated learning, user selection, clustering, metadata, homogeneous Poisson point process, non-IID data]
  - **authors:** Ce Zheng, Shiyao Ma, Ke Zhang, Chen Sun, Wenqi Zhang
  - **institution:** Pengcheng Laboratory, Southwest University, Waseda University, SONY(China) Ltd
  - **link:** https://arxiv.org/pdf/2601.10013
  - **Simple LLM Summary:** This paper proposes a metadata-driven federated learning framework that uses a clustering-based user selection strategy, leveraging metadata like location to reduce data correlation. The method employs a novel data partition model based on a homogeneous Poisson point process to realistically simulate user datasets. Experiments show it improves model performance and convergence in non-IID scenarios, especially when selecting few users per round.

- **[arXiv260116] Breaking the Storage-Bandwidth Tradeoff in Distributed Storage with Quantum Entanglement**
  - **tags:** [sys], [distributed storage systems], [quantum entanglement, superdense coding, storage-bandwidth tradeoff, minimum-storage regenerating point, (n, k, d) distributed storage]
  - **authors:** Lei Hu, Mohamed Nomeir, Alptug Aytekin, Sennur Ulukus
  - **institution:** University of Maryland, College Park
  - **link:** https://arxiv.org/pdf/2601.10676
  - **Simple LLM Summary:** This paper investigates using quantum communication and entanglement among helper nodes in distributed storage systems to improve the fundamental tradeoff between per-node storage and repair bandwidth. It shows that, unlike classical systems, when d ≥ 2k-2, quantum resources enable an operating point where both storage and repair bandwidth are simultaneously minimized, breaking the classical tradeoff.

- **[arXiv260116] Distributed Linearly Separable Computation with Arbitrary Heterogeneous Data Assignment**
  - **tags:** [sys], [distributed computation], [distributed linearly separable computation, heterogeneous data assignment, communication cost, computable dimension, universal computing scheme, converse bound]
  - **authors:** Ziting Zhang, Kai Wan, Minquan Cheng, Shuo Shao, Giuseppe Caire
  - **institution:** Huazhong University of Science and Technology, Guangxi Normal University, University of Shanghai for Science and Technology, Technische Universität Berlin
  - **link:** https://arxiv.org/pdf/2601.10177
  - **Simple LLM Summary:** This paper proposes a universal computing scheme and a converse bound to characterize the tradeoff between computable dimension and communication cost for distributed linearly separable computation under arbitrary heterogeneous data assignment. The results are derived for both integer and fractional communication costs, and the scheme and bound are shown to coincide in certain parameter regimes.

- **[arXiv260116] Chebyshev Accelerated Subspsace Eigensolver for Pseudo-hermitian Hamiltonians**
  - **tags:** [sys], [numerical linear algebra], [Chebyshev filter, oblique Rayleigh-Ritz, pseudo-hermitian eigensolver, Bethe-Salpeter equation, quadratic convergence]
  - **authors:** Edoardo Di Napoli, Clément Richefort, Xinzhe Wu
  - **institution:** Jülich Supercomputing Centre, Forschungszentrum Jülich
  - **link:** https://arxiv.org/pdf/2601.10557
  - **Simple LLM Summary:** This paper extends the Chebyshev Accelerated Subspace iteration Eigensolver (ChASE) to compute eigenpairs for pseudo-hermitian Hamiltonians arising from the Bethe-Salpeter equation. It introduces an oblique Rayleigh-Ritz projection for quadratic convergence and a parallel implementation of the Chebyshev filter with limited global communication. The new solver achieves performance and convergence similar to the original Hermitian version.

- **[arXiv260116] Mitigating GIL Bottlenecks in Edge AI Systems**
  - **tags:** [mlsys], [others], [adaptive thread pool, blocking ratio (β), GIL contention, runtime profiling, edge AI, saturation cliff]
  - **authors:** Mridankan Mandal, Smit Sanjay Shende
  - **institution:** Indian Institute of Information Technology, Allahabad
  - **link:** https://arxiv.org/pdf/2601.10582
  - **Simple LLM Summary:** The paper introduces a library-based adaptive runtime system that uses a novel Blocking Ratio (β) metric to distinguish between I/O wait and GIL contention, enabling automatic thread pool scaling to avoid performance degradation. It demonstrates that this approach achieves near-optimal performance on resource-constrained edge devices, outperforming alternatives like multiprocessing and asyncio. The method remains effective even in future Python environments without the GIL, as the core issue of thread saturation persists on single-core devices.


**cs.AI/cs.LG contains "reinforcement learning" total: 18**
- [arXiv260116] History Is Not Enough: An Adaptive Dataflow System for Financial Time-Series Synthesis [link](https://arxiv.org/pdf/2601.10143)
- [arXiv260116] Sparse-RL: Breaking the Memory Wall in LLM Reinforcement Learning via Stable Sparse Rollouts [link](https://arxiv.org/pdf/2601.10079)
- [arXiv260116] Combinatorial Optimization Augmented Machine Learning [link](https://arxiv.org/pdf/2601.10583)
- [arXiv260116] DecisionLLM: Large Language Models for Long Sequence Decision Exploration [link](https://arxiv.org/pdf/2601.10148)
- [arXiv260116] Urban Socio-Semantic Segmentation with Vision-Language Reasoning [link](https://arxiv.org/pdf/2601.10477)
- [arXiv260116] MatchTIR: Fine-Grained Supervision for Tool-Integrated Reasoning via Bipartite Matching [link](https://arxiv.org/pdf/2601.10712)
- [arXiv260116] CS-GBA: A Critical Sample-based Gradient-guided Backdoor Attack for Offline Reinforcement Learning [link](https://arxiv.org/pdf/2601.10407)
- [arXiv260116] Reinforcement Learning with Multi-Step Lookahead Information Via Adaptive Batching [link](https://arxiv.org/pdf/2601.10418)
- [arXiv260116] Eluder dimension: localise it! [link](https://arxiv.org/pdf/2601.09825)
- [arXiv260116] PRL: Process Reward Learning Improves LLMs' Reasoning Ability and Broadens the Reasoning Boundary [link](https://arxiv.org/pdf/2601.10201)
- [arXiv260116] HOMURA: Taming the Sand-Glass for Time-Constrained LLM Translation via Reinforcement Learning [link](https://arxiv.org/pdf/2601.10187)
- [arXiv260116] SuS: Strategy-aware Surprise for Intrinsic Exploration [link](https://arxiv.org/pdf/2601.10349)
- [arXiv260116] Reinforcement Learning to Discover a NorthEast Monsoon Index for Monthly Rainfall Prediction in Thailand [link](https://arxiv.org/pdf/2601.10181)
- [arXiv260116] GUI-Eyes: Tool-Augmented Perception for Visual Grounding in GUI Agents [link](https://arxiv.org/pdf/2601.09770)
- [arXiv260116] StatLLaMA: A multi-stage training framework for building a domain-optimized statistical language model [link](https://arxiv.org/pdf/2601.09718)
- [arXiv260116] Evidence-Augmented Policy Optimization with Reward Co-Evolution for Long-Context Reasoning [link](https://arxiv.org/pdf/2601.10306)
- [arXiv260116] OUTLINEFORGE: Hierarchical Reinforcement Learning with Explicit States for Scientific Writing [link](https://arxiv.org/pdf/2601.09858)
- [arXiv260116] PaperScout: An Autonomous Agent for Academic Paper Search with Process-Aware Sequence-Level Policy Optimization [link](https://arxiv.org/pdf/2601.10029)

**cs.AI/cs.LG contains "accelerate" total: 12**
- [arXiv260116] Single-Stage Huffman Encoder for ML Compression [link](https://arxiv.org/pdf/2601.10673)
- [arXiv260116] MHub.ai: A Simple, Standardized, and Reproducible Platform for AI Models in Medical Imaging [link](https://arxiv.org/pdf/2601.10154)
- [arXiv260116] RAG-3DSG: Enhancing 3D Scene Graphs with Re-Shot Guided Retrieval-Augmented Generation [link](https://arxiv.org/pdf/2601.10168)
- [arXiv260116] Towards Efficient Low-rate Image Compression with Frequency-aware Diffusion Prior Refinement [link](https://arxiv.org/pdf/2601.10373)
- [arXiv260116] Kinematic Tokenization: Optimization-Based Continuous-Time Tokens for Learnable Decision Policies in Noisy Time Series [link](https://arxiv.org/pdf/2601.09949)
- [arXiv260116] Accelerated Regularized Wasserstein Proximal Sampling Algorithms [link](https://arxiv.org/pdf/2601.09848)
- [arXiv260116] Development of Ontological Knowledge Bases by Leveraging Large Language Models [link](https://arxiv.org/pdf/2601.10436)
- [arXiv260116] FaTRQ: Tiered Residual Quantization for LLM Vector Search in Far-Memory-Aware ANNS Systems [link](https://arxiv.org/pdf/2601.09985)
- [arXiv260116] State of AI: An Empirical 100 Trillion Token Study with OpenRouter [link](https://arxiv.org/pdf/2601.10088)
- [arXiv260116] OctoBench: Benchmarking Scaffold-Aware Instruction Following in Repository-Grounded Agentic Coding [link](https://arxiv.org/pdf/2601.10343)
- [arXiv260116] Advancing Model Refinement: Muon-Optimized Distillation and Quantization for LLM Deployment [link](https://arxiv.org/pdf/2601.09865)
- [arXiv260116] What Understanding Means in AI-Laden Astronomy [link](https://arxiv.org/pdf/2601.10038)
