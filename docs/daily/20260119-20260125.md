# 20260119-20260125

## 2026-01-19

**cs.DC total: 4**

- **[arXiv260119] Konflux: Optimized Function Fusion for Serverless Applications**
  - **tags:** [sys], [serverless computing], [function fusion, FaaS, cost optimization, latency optimization, emulation, brute-force analysis]
  - **authors:** Niklas Kowallik, Trever Schirmer, David Bermbach
  - **institution:** TU Berlin
  - **link:** https://arxiv.org/pdf/2601.11156
  - **Simple LLM Summary:** The paper presents Konflux, a system that emulates FaaS platforms to locally analyze all possible function fusion configurations for serverless applications. It finds that only a limited set of these configurations are optimal for balancing cost and latency, and this optimal set is heavily dependent on the specific cloud pricing model.

- **[arXiv260119] AFLL: Real-time Load Stabilization for MMO Game Servers Based on Circular Causality Learning**
  - **tags:** [mlsys], [others], [backpropagation, gradient descent, real-time adaptive control, circular causality learning, feedback loop, message throttling]
  - **authors:** Shinsuk Kang, Youngjae Kim
  - **institution:** Sogang University
  - **link:** https://arxiv.org/pdf/2601.10998
  - **Simple LLM Summary:** The paper proposes AFLL, a real-time load stabilization system for MMO game servers that uses backpropagation to learn the causal relationship between outgoing messages and incoming client requests. By dynamically adjusting message transmission weights, it proactively throttles low-priority traffic to prevent server overload. The system significantly reduced CPU time and thread contention in experiments, demonstrating that circular causality learning enables effective real-time adaptation for latency-critical systems.

- **[arXiv260119] A Survey of Real-Time Support, Analysis, and Advancements in ROS 2**
  - **tags:** [sys], [real-time systems], [DDS, executors, publish-subscribe, timing analysis, micro-ROS]
  - **authors:** Daniel Casini, Jian-Jia Chen, Jing Li, Federico Reghenzani, Harun Teper
  - **institution:** Scuola Superiore Sant’Anna, TU Dortmund University, New Jersey Institute of Technology, Politecnico di Milano
  - **link:** https://arxiv.org/pdf/2601.10722
  - **Simple LLM Summary:** This survey provides a comprehensive overview of research efforts to analyze and enhance the real-time capabilities of ROS 2, focusing on its scheduling mechanisms, communication middleware, and timing analysis. It reviews key contributions, including new executor designs and techniques for bounding communication delays, and introduces taxonomies to classify the work. The paper aims to guide researchers and practitioners in understanding and improving the timing predictability of ROS 2 for real-time robotic applications.

- **[arXiv260119] Space-Optimal, Computation-Optimal, Topology-Agnostic, Throughput-Scalable Causal Delivery through Hybrid Buffering**
  - **tags:** [sys], [distributed systems], [causal delivery, SPS+FIFO, hybrid buffering, topology-agnostic, metadata overhead]
  - **authors:** Paulo Sérgio Almeida
  - **institution:** INESC TEC, University of Minho
  - **link:** https://arxiv.org/pdf/2601.11487
  - **Simple LLM Summary:** The paper introduces a novel algorithm for causal message delivery in distributed systems by combining sender-buffering to enforce Sender Permission to Send (SPS) and receiver-buffering to enforce FIFO order. This hybrid approach achieves effectively constant metadata size per message and amortized constant processing overhead, overcoming the scalability and liveness limitations of prior sender-only buffering methods. The authors conclude it is the first topology-agnostic causal delivery algorithm with these space-optimal and computation-optimal properties.


**cs.AI/cs.LG contains "reinforcement learning" total: 17**
- [arXiv260119] Spurious Rewards Paradox: Mechanistically Understanding How RLVR Activates Memorization Shortcuts in LLMs [link](https://arxiv.org/pdf/2601.11061)
- [arXiv260119] Policy-Based Deep Reinforcement Learning Hyperheuristics for Job-Shop Scheduling Problems [link](https://arxiv.org/pdf/2601.11189)
- [arXiv260119] Do explanations generalize across large reasoning models? [link](https://arxiv.org/pdf/2601.11517)
- [arXiv260119] Knowledge is Not Enough: Injecting RL Skills for Continual Adaptation [link](https://arxiv.org/pdf/2601.11258)
- [arXiv260119] Model-free policy gradient for discrete-time mean-field control [link](https://arxiv.org/pdf/2601.11217)
- [arXiv260119] Explore with Long-term Memory: A Benchmark and Multimodal LLM-based Reinforcement Learning Framework for Embodied Exploration [link](https://arxiv.org/pdf/2601.10744)
- [arXiv260119] Reasoning Models Generate Societies of Thought [link](https://arxiv.org/pdf/2601.10825)
- [arXiv260119] Deep GraphRAG: A Balanced Approach to Hierarchical Retrieval and Adaptive Integration [link](https://arxiv.org/pdf/2601.11144)
- [arXiv260119] Toward Adaptive Grid Resilience: A Gradient-Free Meta-RL Framework for Critical Load Restoration [link](https://arxiv.org/pdf/2601.10973)
- [arXiv260119] Learning Quadrupedal Locomotion for a Heavy Hydraulic Robot Using an Actuator Model [link](https://arxiv.org/pdf/2601.11143)
- [arXiv260119] BAPO: Boundary-Aware Policy Optimization for Reliable Agentic Search [link](https://arxiv.org/pdf/2601.11037)
- [arXiv260119] Offline Reinforcement-Learning-Based Power Control for Application-Agnostic Energy Efficiency [link](https://arxiv.org/pdf/2601.11352)
- [arXiv260119] Realistic Curriculum Reinforcement Learning for Autonomous and Sustainable Marine Vessel Navigation [link](https://arxiv.org/pdf/2601.10911)
- [arXiv260119] Factored Value Functions for Graph-Based Multi-Agent Reinforcement Learning [link](https://arxiv.org/pdf/2601.11401)
- [arXiv260119] Action Shapley: A Training Data Selection Metric for World Model in Reinforcement Learning [link](https://arxiv.org/pdf/2601.10905)
- [arXiv260119] Visual Marker Search for Autonomous Drone Landing in Diverse Urban Environments [link](https://arxiv.org/pdf/2601.11078)
- [arXiv260119] TANDEM: Temporal-Aware Neural Detection for Multimodal Hate Speech [link](https://arxiv.org/pdf/2601.11178)

**cs.AI/cs.LG contains "accelerate" total: 3**
- [arXiv260119] MHA2MLA-VLM: Enabling DeepSeek's Economical Multi-Head Latent Attention across Vision-Language Models [link](https://arxiv.org/pdf/2601.11464)
- [arXiv260119] Reasoning Models Generate Societies of Thought [link](https://arxiv.org/pdf/2601.10825)
- [arXiv260119] Differentially Private Subspace Fine-Tuning for Large Language Models [link](https://arxiv.org/pdf/2601.11113)

## 2026-01-21

**cs.DC total: 51**

- **[arXiv260121] Radio Labeling of Strong Prismatic Network With Star**
  - **tags:** [sys], [graph theory, combinatorial optimization], [radio labeling, strong product, prismatic network, star graph, parallel algorithm]
  - **authors:** Liming Wang, Feng Li, Linlin Cui
  - **institution:** Qinghai Normal University
  - **link:** https://arxiv.org/pdf/2601.11624
  - **Simple LLM Summary:** This paper studies the radio labeling problem for a strong prismatic network with a star, which is a combinatorial optimization model for wireless spectrum assignment. It presents theorems and examples for this specific graph class and proposes a parallel algorithm to enhance computational efficiency for large-scale networks.

- **[arXiv260121] Cost-Aware Logging: Measuring the Financial Impact of Excessive Log Retention in Small-Scale Cloud Deployments**
  - **tags:** [sys], [cloud cost optimization], [log retention, storage cost, operational usefulness, cost-effectiveness, synthetic log datasets]
  - **authors:** Jody Almaida Putra
  - **institution:** Independent Researcher
  - **link:** https://arxiv.org/pdf/2601.11584
  - **Simple LLM Summary:** This paper uses synthetic log datasets to analyze the cost-effectiveness of different log retention windows in small-scale cloud deployments. It finds that reducing retention from 90 to 14 days can lower storage costs by up to 78% while preserving over 97% of operationally useful logs, suggesting significant savings are possible without compromising reliability.

- **[arXiv260121] PerCache: Predictive Hierarchical Cache for RAG Applications on Mobile Devices**
  - **tags:** [mlsys], [llm inference], [hierarchical cache, predictive caching, KV cache reuse, semantic cache reuse, mobile RAG, latency reduction]
  - **authors:** Kaiwei Liu, Liekang Zeng, Lilin Xu, Bufang Yang, Zhenyu Yan
  - **institution:** The Chinese University of Hong Kong, Columbia University
  - **link:** https://arxiv.org/pdf/2601.11553
  - **Simple LLM Summary:** The paper proposes PerCache, a predictive hierarchical cache designed to reduce latency in mobile RAG applications by reusing intermediate computational results like QKV caches across queries. It employs a progressive matching architecture and predictive population to improve cache hit rates while adapting to dynamic system loads. Evaluations show it reduces latency by 34.4% compared to baselines and maintains performance under changing resource conditions.

- **[arXiv260121] Enhancing Model Context Protocol (MCP) with Context-Aware Server Collaboration**
  - **tags:** [mlsys], [llm inference], [Model Context Protocol (MCP), Shared Context Store (SCS), Context-Aware MCP (CA-MCP), multi-agent systems, autonomous server coordination]
  - **authors:** Meenakshi Amulya Jayanti, X.Y. Han
  - **institution:** University of Chicago
  - **link:** https://arxiv.org/pdf/2601.11595
  - **Simple LLM Summary:** This paper proposes a Context-Aware Model Context Protocol (CA-MCP) that enhances traditional MCP by introducing a Shared Context Store, allowing specialized MCP servers to read from and write to a shared memory for more autonomous coordination. The experiments on TravelPlanner and REALM-Bench benchmarks show that CA-MCP reduces LLM calls and response failures, improving efficiency and responsiveness in multi-agent systems.

- **[arXiv260121] Hardware-Aware Reformulation of Convolutions for Efficient Execution on Specialized AI Hardware: A Case Study on NVIDIA Tensor Cores**
  - **tags:** [mlsys], [post-training], [hardware-aware reformulation, rewrite rules, width folding, structured filter expansion, semantic tuning, convolutional neural networks, tensor cores]
  - **authors:** Ganesh Bikshandi
  - **institution:** Independent researcher (no explicit institution; based on gmail.com email domain)
  - **link:** https://arxiv.org/pdf/2601.11608
  - **Simple LLM Summary:** This paper introduces a hardware-aware reformulation method for CNNs using rewrite rules to restructure convolution computations post-training, ensuring alignment with hardware constraints like NVIDIA Tensor Cores without modifying network weights. It demonstrates that this approach eliminates inefficient zero-padding and provides a foundation for systematic semantic tuning to optimize CNN deployment on specialized AI hardware.

- **[arXiv260121] EPD-Serve: A Flexible Multimodal EPD Disaggregation Inference Serving System On Ascend**
  - **tags:** [mlsys], [multi-modal inference], [stage-level disaggregation, asynchronous feature prefetching, hierarchical grouped KV cache, dynamic orchestration, spatial multiplexing]
  - **authors:** Fan Bai, Pai Peng, Zhengzhi Tang, Zhe Wang, Gong Chen, Xiang Lu, Yinuo Li, Huan Lin, Weizhe Lin, Yaoyuan Wang, Xiaosong Li
  - **institution:** Huawei Technologies Co., Ltd
  - **link:** https://arxiv.org/pdf/2601.11590
  - **Simple LLM Summary:** The paper proposes EPD-Serve, a stage-level disaggregated inference serving system that decouples multimodal model inference into Encode, Prefill, and Decode stages for flexible deployment on Ascend hardware. It introduces mechanisms like asynchronous feature prefetching and hierarchical KV cache transmission to improve communication efficiency. Experiments show that EPD-Serve significantly improves throughput under high concurrency while meeting strict latency constraints.

- **[arXiv260121] Computation-Bandwidth-Memory Trade-offs: A Unified Paradigm for AI Infrastructure**
  - **tags:** [mlsys], [cluster infrastructure], [computation-bandwidth-memory trade-offs, AI Trinity, dynamic resource allocation, edge-cloud communication, distributed training, model inference]
  - **authors:** Yuankai Fan, Qizhen Weng, Xuelong Li
  - **institution:** Institute of Artificial Intelligence (TeleAI), China Telecom
  - **link:** https://arxiv.org/pdf/2601.11577
  - **Simple LLM Summary:** The paper introduces the "AI Trinity" paradigm, a unified framework that treats computation, bandwidth, and memory as coequal pillars and dynamically trades resources among them to optimize system performance. It demonstrates the framework's effectiveness through applications in edge-cloud communication, distributed training, and model inference, concluding that this approach provides a foundational paradigm for designing scalable AI infrastructure.

- **[arXiv260121] WISP: Waste- and Interference-Suppressed Distributed Speculative LLM Serving at the Edge via Dynamic Drafting and SLO-Aware Batching**
  - **tags:** [mlsys], [llm inference], [speculative decoding, distributed inference, edge computing, dynamic drafting, SLO-aware batching, verification interference, wasted drafting time]
  - **authors:** Xiangchen Li, Jiakun Fan, Qingyuan Wang, Dimitrios Spatharakis, Saeid Ghafouri, Hans Vandierendonck, Deepu John, Bo Ji, Ali R. Butt, Dimitrios S. Nikolopoulos
  - **institution:** Virginia Tech, University College Dublin, National Technical University of Athens, Queen’s University Belfast
  - **link:** https://arxiv.org/pdf/2601.11652
  - **Simple LLM Summary:** The paper proposes WISP, a distributed LLM inference system that uses edge devices for speculative drafting and a cloud server for verification. Its core method involves dynamic drafting and SLO-aware batching to suppress wasted drafting time and verification interference. The main conclusion is that WISP significantly improves system capacity and goodput compared to centralized serving and prior distributed speculative decoding systems.

- **[arXiv260121] A Forward Simulation-Based Hierarchy of Linearizable Concurrent Objects**
  - **tags:** [sys], [concurrency theory], [linearizability, forward simulation, wait-freedom, lock-freedom, obstruction-freedom, Herlihy-Wing queue, time-stamped queue]
  - **authors:** Chao Wang, Ruijia Li, Yang Zhou, Peng Wu, Yi Lv, Jianwei Liao, Jim Woodcock, Zhiming Liu
  - **institution:** Southwest University, Institute of Software, Chinese Academy of Sciences, University of Chinese Academy of Sciences, Aarhus University, University of York
  - **link:** https://arxiv.org/pdf/2601.11646
  - **Simple LLM Summary:** This paper systematically investigates the connection between linearizable concurrent objects and forward simulation. It proves that sets of linearizable objects form bounded semilattices or lattices under the forward simulation relation and provides an equivalent characterization of linearizability via forward simulation. The results are demonstrated by proving simulation relations between objects like the time-stamped queue and the Herlihy-Wing queue.

- **[arXiv260121] PLA-Serve: A Prefill-Length-Aware LLM Serving System**
  - **tags:** [mlsys], [llm inference], [prefill-decode disaggregation, dual-queue scheduling, length-aware batching, CUDA Graph, temporal/spatial disaggregation]
  - **authors:** Jianshu She, Zonghang Li, Hongchao Du, Shangyu Wu, Wenhao Zheng, Eric Xing, Zhengzhong Liu, Huaxiu Yao, Jason Xue, Qirong Ho
  - **institution:** Mohamed bin Zayed University of Artificial Intelligence, The University of North Carolina at Chapel Hill
  - **link:** https://arxiv.org/pdf/2601.11589
  - **Simple LLM Summary:** PLA-Serve is an LLM serving system that reduces latency by disaggregating requests based on prompt length and using a dual-queue design with length-aware batching. It separates long-prefill from short-prefill requests to mitigate performance interference. The system significantly reduces prefill latency and SLO violations compared to existing methods, demonstrating effectiveness for heterogeneous workloads.

- **[arXiv260121] Nixie: Efficient, Transparent Temporal Multiplexing for Consumer GPUs**
  - **tags:** [mlsys], [llm inference], [temporal multiplexing, GPU memory management, MLFQ scheduling, transparent system service]
  - **authors:** Yechen Xu, Yifei Wang, Nathanael Ren, Yiran Chen, Danyang Zhuo
  - **institution:** Duke University
  - **link:** https://arxiv.org/pdf/2601.11743
  - **Simple LLM Summary:** Nixie is a system service that enables efficient, transparent temporal multiplexing on consumer GPUs by coordinating GPU memory allocation and kernel launches, without requiring application or driver changes. It uses a lightweight scheduler with MLFQ-inspired techniques to prioritize latency-sensitive interactive jobs. The system significantly improves interactive task latency and reduces CPU pinned memory usage compared to existing sharing mechanisms.

- **[arXiv260121] HALO: Semantic-Aware Distributed LLM Inference in Lossy Edge Network**
  - **tags:** [mlsys], [llm inference], [distributed inference, tensor parallelism, semantic-aware predictor, load-balancing scheduler, edge computing]
  - **authors:** Peirong Zheng, Wenchao Xu, Haozhao Wang, Jinyu Chen, Xuemin Shen
  - **institution:** The Hong Kong Polytechnic University, The Hong Kong University of Science and Technology, Huazhong University of Science and Technology, University of Waterloo
  - **link:** https://arxiv.org/pdf/2601.11676
  - **Simple LLM Summary:** The paper proposes HALO, a framework for distributed LLM inference in lossy edge networks. It uses a semantic-aware predictor and load-balancing scheduler to allocate less critical computations to unstable devices, enabling relaxed synchronization. Experiments show HALO achieves a 3.41x speedup under unreliable network conditions while maintaining performance.

- **[arXiv260121] Big Data Workload Profiling for Energy-Aware Cloud Resource Management**
  - **tags:** [sys], [cloud resource management], [workload profiling, energy-aware scheduling, virtual machine placement, SLA compliance, adaptive consolidation]
  - **authors:** Milan Parikh, Aniket Abhishek Soni, Sneja Mitinbhai Shah, Ayush Raj Jha
  - **institution:** Independent Researchers (IEEE)
  - **link:** https://arxiv.org/pdf/2601.11935
  - **Simple LLM Summary:** This paper proposes a workload-aware scheduling framework that profiles CPU, memory, and I/O usage to guide energy-efficient virtual machine placement. By combining historical logs with real-time data, it predicts energy and performance impacts for adaptive workload consolidation. The method achieves 15-20% energy savings on big data workloads like Hadoop and Spark with negligible performance degradation.

- **[arXiv260121] GPU-Resident Inverted File Index for Streaming Vector Databases**
  - **tags:** [mlsys], [GPU kernels], [slab-based allocation, validity bitmap, address translation table, inverted file index, streaming vector database]
  - **authors:** Dongfang Zhao
  - **institution:** University of Washington
  - **link:** https://arxiv.org/pdf/2601.11808
  - **Simple LLM Summary:** This paper proposes SIVF, a GPU-native architecture for streaming vector databases that replaces static memory layouts with a slab-based allocation system and a validity bitmap to enable in-place mutation directly in VRAM. It introduces a GPU-resident address translation table for O(1) vector access, achieving orders-of-magnitude improvements in ingestion and deletion latency with minimal memory overhead.

- **[arXiv260121] Opportunistic Scheduling for Optimal Spot Instance Savings in the Cloud**
  - **tags:** [sys], [cloud computing, job scheduling], [queuing theory, stochastic processes, optimization, knapsack problem, G/G/1 queue, spot instances, on-demand instances]
  - **authors:** Neelkamal Bhuyan, Randeep Bhatia, Murali Kodialam, TV Lakshman
  - **institution:** Georgia Institute of Technology, Nokia Bell Labs
  - **link:** https://arxiv.org/pdf/2601.12266
  - **Simple LLM Summary:** This paper proposes an opportunistic scheduling framework for delay-sensitive jobs using spot and on-demand cloud instances to minimize cost. It uses queuing theory and optimization to derive optimal policies for different delay regimes, including a knapsack-based policy for high delays. The proposed adaptive algorithm is shown to be near-optimal in empirical evaluations.

- **[arXiv260121] RIPPLE++: An Incremental Framework for Efficient GNN Inference on Evolving Graphs**
  - **tags:** [mlsys], [others], [incremental inference, dynamic graphs, graph neural networks, streaming updates, distributed deployment, aggregation functions]
  - **authors:** Pranjal Naman, Parv Agarwal, Hrishikesh Haritas, Yogesh Simmhan
  - **institution:** Indian Institute of Science (IISc)
  - **link:** https://arxiv.org/pdf/2601.12347
  - **Simple LLM Summary:** The paper proposes RIPPLE++, an incremental framework for efficient GNN inference on evolving graphs. It introduces a generalized incremental programming model to propagate updates through affected neighborhoods, avoiding full recomputation. The framework achieves high throughput and low latency on both single-machine and distributed deployments, significantly outperforming baseline methods.

- **[arXiv260121] RAPID-Serve: Resource-efficient and Accelerated P/D Intra-GPU Disaggregation**
  - **tags:** [mlsys], [llm inference], [disaggregated serving, hybrid batching, adaptive resource management, CU masking, KV-cache]
  - **authors:** Amna Masood, Pratishtha Gaur, Nuwan Jayasena
  - **institution:** Advanced Micro Devices (AMD)
  - **link:** https://arxiv.org/pdf/2601.11822
  - **Simple LLM Summary:** The paper proposes RAPID-Serve, a technique for LLM inference that concurrently executes prefill and decode phases on the same GPU(s) to meet latency SLOs while maintaining high throughput and resource efficiency. It introduces Adaptive Resource Management, optionally leveraging fine-grained GPU partitioning like AMD's CU masking. The method shows significant throughput improvements, especially under SLO constraints, compared to state-of-the-art approaches like hybrid batching and disaggregated serving.

- **[arXiv260121] DaggerFFT: A Distributed FFT Framework Using Task Scheduling in Julia**
  - **tags:** [sys], [high-performance computing], [task scheduling, dynamic scheduler, work stealing, distributed arrays, pencil decomposition, slab decomposition, MPI]
  - **authors:** Sana Taghipour Anvari, Julian Samaroo, Matin Raayai Ardakani, David Kaeli
  - **institution:** Northeastern University, Massachusetts Institute of Technology
  - **link:** https://arxiv.org/pdf/2601.12209
  - **Simple LLM Summary:** The paper presents DaggerFFT, a distributed FFT framework in Julia that uses a dynamic task scheduler with work stealing to execute FFT computations as a task graph. It demonstrates that this approach outperforms static-distribution libraries, achieving up to 2.6x speedup on CPU clusters and 1.35x on GPU clusters, and shows its practical integration into a geophysical fluid dynamics simulation.

- **[arXiv260121] Canonicalization of Batched Einstein Summations for Tuning Retrieval**
  - **tags:** [sys], [computational mathematics], [batched einsum, graph canonicalization, tensor contractions, finite element methods, JAX]
  - **authors:** Kaushik Kulkarni, Andreas Klöckner
  - **institution:** University of Illinois at Urbana-Champaign
  - **link:** https://arxiv.org/pdf/2601.12220
  - **Simple LLM Summary:** The paper presents an algorithm to canonicalize batched Einstein summation (einsum) expressions by encoding them as colored graphs and applying graph canonicalization to derive a unique normal form. This enables the reuse of optimization knowledge for performance tuning. The evaluation shows the method achieves a geomean speedup of 4.7x compared to JAX for benchmarks from TCCG and an FEM solver.

- **[arXiv260121] Power Aware Dynamic Reallocation For Inference**
  - **tags:** [mlsys], [llm inference], [disaggregation, power-aware scheduling, dynamic reallocation, SLO attainment, goodput]
  - **authors:** Yiwei Jiang, Sangeeta Chowdhary, Nathaniel Morris, Rutwik Jain, Srilatha Manne, Sam Bayliss
  - **institution:** AMD Research and Advanced Development, University of Wisconsin-Madison
  - **link:** https://arxiv.org/pdf/2601.12241
  - **Simple LLM Summary:** This paper proposes RAPID, a power-aware disaggregated inference framework that jointly manages GPU roles and power budgets to improve performance under strict power caps. It combines static and dynamic power reallocation with GPU reallocation to sustain goodput and service-level objective (SLO) attainment. The method demonstrates up to a 2x improvement in SLO attainment at peak load compared to static assignments without increasing complexity or cost.

- **[arXiv260121] SGCP: A Self-Organized Game-Theoretic Framework For Collaborative Perception**
  - **tags:** [mlsys], [others], [game theory, self-organization, clustering, potential game, distributed algorithms, collaborative perception, V2V communication]
  - **authors:** Zechuan Gong, Hui Zhang, Yuquan Yang, Wenyu Lu
  - **institution:** University of Science and Technology of China
  - **link:** https://arxiv.org/pdf/2601.12524
  - **Simple LLM Summary:** This paper proposes a decentralized, game-theoretic framework for collaborative perception in autonomous driving, where vehicles self-organize into clusters and selectively share point cloud data to reduce communication overhead. The method uses a two-stage approach involving cluster formation and a non-cooperative potential game for data selection. Experiments show it improves perception accuracy and coverage while lowering communication costs compared to existing baselines.

- **[arXiv260121] On Resilient and Efficient Linear Secure Aggregation in Hierarchical Federated Learning**
  - **tags:** [mlsys], [fault-tolerance], [secure aggregation, hierarchical federated learning, information-theoretic security, unreliable communication, communication cost, randomness cost]
  - **authors:** Shudi Weng, Xiang Zhang, Yizhou Zhao, Giuseppe Caire, Ming Xiao, Mikael Skoglund
  - **institution:** KTH Royal Institute of Technology, Technical University of Berlin, Southwest University
  - **link:** https://arxiv.org/pdf/2601.12853
  - **Simple LLM Summary:** This paper studies hierarchical secure aggregation in federated learning under unreliable communication links. It characterizes the fundamental limits of communication and randomness costs for robust aggregation and proposes an optimal protocol that achieves these minimum costs.

- **[arXiv260121] ASAS-BridgeAMM: Trust-Minimized Cross-Chain Bridge AMM with Failure Containment**
  - **tags:** [sys], [blockchain security], [cross-chain bridge, automated market maker, failure containment, collateral haircuts, slippage bounds, withdrawal limits, Byzantine relayer model, formal verification]
  - **authors:** Shengwei You, Aditya Joshi, Andrey Kuehlkamp, Jarek Nabrzyski
  - **institution:** University of Notre Dame
  - **link:** https://arxiv.org/pdf/2601.12434
  - **Simple LLM Summary:** The paper introduces ASAS-BridgeAMM, a bridge-coupled automated market maker that uses "Contained Degradation" to dynamically adjust parameters like collateral haircuts based on cross-chain message latency, treating it as execution risk. It demonstrates a 73% reduction in worst-case bridge-induced insolvency compared to traditional designs while maintaining transaction volume during stress periods.

- **[arXiv260121] Dynamic Detection of Inefficient Data Mapping Patterns in Heterogeneous OpenMP Applications**
  - **tags:** [sys], [performance profiling], [dynamic analysis, OMPDataPerf, OpenMP Tools Interface (OMPT), data mapping, data transfer]
  - **authors:** Luke Marzen, Junhyung Shim, Ali Jannesari
  - **institution:** Iowa State University
  - **link:** https://arxiv.org/pdf/2601.12713
  - **Simple LLM Summary:** The paper proposes dynamic analysis techniques to detect inefficient data transfer patterns in heterogeneous OpenMP applications, implemented in a tool called OMPDataPerf. The tool uses the OpenMP Tools Interface (OMPT) to profile data mappings with low runtime overhead. The main conclusion is that OMPDataPerf effectively identifies problematic data transfers and provides optimization guidance, incurring only a 5% geometric-mean runtime overhead.

- **[arXiv260121] Efficient Local-to-Global Collaborative Perception via Joint Communication and Computation Optimization**
  - **tags:** [mlsys], [others], [local-to-global collaborative perception, roadside unit (RSU) scheduling, CAV group fusion, communication overhead reduction]
  - **authors:** Hui Zhang, Yuquan Yang, Zechuan Gong, Xiaohua Xu, Dan Keun Sung
  - **institution:** University of Science and Technology of China, Korea Advanced Institute of Science and Technology
  - **link:** https://arxiv.org/pdf/2601.12749
  - **Simple LLM Summary:** The paper proposes a local-to-global collaborative perception framework (LGCP) that partitions roads into areas managed by CAV groups, with leaders fusing local data and uploading results to an RSU for global aggregation and broadcast. This centralized scheduling approach reduces redundant transmissions and computational load. Experiments show the framework achieves an average 44x reduction in data transmission while maintaining or improving collaborative perception performance.

- **[arXiv260121] SWORD: A Secure LoW-Latency Offline-First Authentication and Data Sharing Scheme for Resource Constrained Distributed Networks**
  - **tags:** [sys], [authentication and data sharing], [proximity-based clustering, offline-first authentication, blockchain, low-latency, IoT, IoV]
  - **authors:** Faisal Haque Bappy, Tahrim Hossain, Raiful Hasan, Kamrul Hasan, Mohamed Younis, Tariqul Islam
  - **institution:** University of Maryland Baltimore County, Kent State University, Tennessee State University
  - **link:** https://arxiv.org/pdf/2601.12875
  - **Simple LLM Summary:** The paper introduces SWORD, a novel offline-first authentication and data-sharing scheme for resource-constrained networks that uses proximity-based clustering to enable secure, low-latency operations without continuous connectivity. It demonstrates that SWORD outperforms traditional blockchain-based solutions and matches the efficiency of central-server-based approaches while being resilient to various security attacks.

- **[arXiv260121] Unleashing Efficient Asynchronous RL Post-Training via Staleness-Constrained Rollout Coordination**
  - **tags:** [mlsys], [post-training], [asynchronous reinforcement learning, data staleness, data skewness, global consistency protocol, rollout coordination, data servers]
  - **authors:** Haoyang Li, Sheng Lin, Fangcheng Fu, Yuming Zhou, Xiaodong Ji, Yanfeng Zhao, Lefeng Wang, Jie Jiang, Bin Cui
  - **institution:** Peking University, Shanghai Jiao Tong University, Tencent Inc.
  - **link:** https://arxiv.org/pdf/2601.12784
  - **Simple LLM Summary:** The paper proposes StaleFlow, a system for asynchronous RL post-training that jointly addresses data staleness and skewness through a global consistency protocol and a redesigned architecture with data servers for flexible rollout coordination. It demonstrates that StaleFlow achieves significantly higher throughput than state-of-the-art systems without compromising model convergence.

- **[arXiv260121] CooperLLM: Cloud-Edge-End Cooperative Federated Fine-tuning for LLMs via ZOO-based Gradient Correction**
  - **tags:** [mlsys], [llm training], [federated learning, zeroth-order optimization, gradient rectification, pipeline scheduling, adaptive compression]
  - **authors:** He Sun, Jinrui Zhou, Li Li, Mingjun Xiao
  - **institution:** University of Science and Technology of China, University of Macau
  - **link:** https://arxiv.org/pdf/2601.12917
  - **Simple LLM Summary:** The paper proposes CooperLLM, a federated fine-tuning framework that uses zeroth-order optimization on mobile devices for privacy, while a cloud server fine-tunes on public data and injects guided gradient perturbations to correct the local updates. This approach, combined with pipeline scheduling and adaptive compression, significantly reduces on-device memory usage, accelerates convergence, and improves model accuracy compared to baseline methods.

- **[arXiv260121] Sutradhara: An Intelligent Orchestrator-Engine Co-design for Tool-based Agentic Inference**
  - **tags:** [mlsys], [llm inference], [orchestrator-engine co-design, tool-aware prompt splitting, streaming tool execution, orchestrator-aware KV cache management, vLLM]
  - **authors:** Anish Biswas, Kanishk Goel, Jayashree Mohan, Alind Khare, Anjaly Parayil, Ramachandran Ramjee, Chetan Bansal
  - **institution:** Microsoft Research, M365 Research
  - **link:** https://arxiv.org/pdf/2601.12967
  - **Simple LLM Summary:** The paper presents SUTRADHARA, a co-designed inference system that integrates orchestration with the LLM serving engine to optimize tool-based agentic workloads. It introduces optimizations like overlapping tool execution with LLM prefill and streaming tool dispatch to reduce latency. The implementation on vLLM demonstrates significant reductions in First Token Rendered and end-to-end latency, showing that co-design effectively addresses performance bottlenecks in agentic systems.

- **[arXiv260121] From Design to Deorbit: A Solar-Electric Autonomous Module for Multi-Debris Remediation**
  - **tags:** [sys], [space systems], [NASA Evolutionary Xenon Thruster (NEXT), Extended Kalman Filter (EKF), Delay/Disruption Tolerant Network (DTN), mechanical clamping system, solar-electric propulsion]
  - **authors:** Om Mishra, Jayesh Patil, Sathwik Narkedimilli, G Srikantha Sharma, Ananda S, Manjunath K Vanahalli
  - **institution:** Indian Institute of Information Technology Dharwad, National University of Singapore, Hindustan Aeronautics Limited, U R Rao Satellite Center (ISRO)
  - **link:** https://arxiv.org/pdf/2601.12830
  - **Simple LLM Summary:** This paper introduces a solar-electric autonomous module for orbital debris removal, integrating a mechanical clamping capture system with a NASA NEXT ion thruster and autonomous navigation. High-fidelity simulations demonstrate successful deorbiting from 800 km, precise navigation with radar-based EKF, and efficient data delivery using DTN protocols. The approach establishes a renewable propulsion benchmark for multi-target debris remediation, reducing reliance on conventional fuels.

- **[arXiv260121] Exploration on Highly Dynamic Graphs**
  - **tags:** [sys], [distributed computing], [mobile agents, dynamic graphs, 1-Interval Connectivity, Connectivity Time, deterministic algorithm]
  - **authors:** Ashish Saxena, Kaushik Mondal
  - **institution:** Indian Institute of Technology Ropar
  - **link:** https://arxiv.org/pdf/2601.13047
  - **Simple LLM Summary:** This paper studies the exploration problem in two dynamic graph models using mobile agents. It strengthens impossibility results and proves that exploration in the Connectivity Time model requires at least (n-1)(n-2)/2 + 1 agents, even with strong capabilities, and presents a matching algorithm using that many agents with 1-hop visibility and O(log n) memory.

- **[arXiv260121] CPU-less parallel execution of lambda calculus in digital logic**
  - **tags:** [sys], [functional programming hardware], [lambda calculus, digital logic, parallel beta-reduction, tree-based representation, data flow]
  - **authors:** Harry Fitchett, Charles Fox
  - **institution:** University of Lincoln
  - **link:** https://arxiv.org/pdf/2601.13040
  - **Simple LLM Summary:** The paper proposes a CPU-less architecture that compiles lambda calculus directly into digital logic for parallel execution, using a tree-based representation with nodes corresponding to grammar forms. It demonstrates a proof-of-concept implementation where independent beta-reductions are performed simultaneously via message-passing between logic blocks. The successful simulation results suggest this approach could be scaled to support larger functional languages.

- **[arXiv260121] Enshrined Proposer Builder Separation in the presence of Maximal Extractable Value**
  - **tags:** [sys], [blockchain consensus], [Proposer Builder Separation, Maximal Extractable Value, agent-based simulation, Gini coefficient, auction mechanism]
  - **authors:** Yitian Wang, Yebo Feng, Yingjiu Li, Jiahua Xu
  - **institution:** University College London, Nanyang Technological University, University of Oregon
  - **link:** https://arxiv.org/pdf/2601.12989
  - **Simple LLM Summary:** This paper develops a formal framework combining mathematical analysis and agent-based simulations to evaluate the enshrined Proposer Builder Separation (ePBS) mechanism in Ethereum. It finds that ePBS, despite separating block building and proposal, significantly increases profit centralization and economic bias, with most block value going to proposers and a few builders capturing most MEV.

- **[arXiv260121] OPTIMUM-DERAM: Highly Consistent, Scalable, and Secure Multi-Object Memory using RLNC**
  - **tags:** [sys], [distributed systems], [Random Linear Network Codes (RLNC), consistent hashing, blockchain oracle, Byzantine fault tolerance, atomic storage]
  - **authors:** Nicolas Nicolaou, Kishori M. Konwar, Moritz Grundei, Aleksandr Bezobchuk, Muriel Médard, Sriram Vishwanath
  - **institution:** Optimum, Georgia Tech
  - **link:** https://arxiv.org/pdf/2601.13146
  - **Simple LLM Summary:** This paper introduces OPTIMUM-DERAM, a decentralized shared memory system that uses Random Linear Network Codes (RLNC) and a consistent hashing ring to improve scalability and performance for multi-object atomic storage. It scales in objects and participants while tolerating Byzantine failures. Experimental results show it outperforms previous solutions like the ABD algorithm.

- **[arXiv260121] The Energy-Throughput Trade-off in Lossless-Compressed Source Code Storage**
  - **tags:** [mlsys], [cluster infrastructure], [key-value store, lossless compression, data parallelism, Pareto-optimal trade-offs, green benchmarking]
  - **authors:** Paolo Ferragina, Francesco Tosoni
  - **institution:** Sant’Anna School of Advanced Studies
  - **link:** https://arxiv.org/pdf/2601.13220
  - **Simple LLM Summary:** This paper designs and evaluates a compressed key-value store for indexing large-scale source code archives, analyzing the trade-offs between space, retrieval throughput, and energy efficiency. The experiments show that different compression configurations can yield high compression ratios and significant gains in throughput and energy, but scaling energy efficiency with data parallelism is challenging due to hardware non-energy-proportionality. The work provides guidelines and automated tools for building sustainable, energy-aware storage backends for massive code datasets.

- **[arXiv260121] Federated Learning Under Temporal Drift -- Mitigating Catastrophic Forgetting via Experience Replay**
  - **tags:** [mlsys], [others], [federated learning, experience replay, catastrophic forgetting, temporal drift, FedAvg]
  - **authors:** Sahasra Kokkula, Daniel David, Aaditya Baruah
  - **institution:** Columbia University
  - **link:** https://arxiv.org/pdf/2601.13456
  - **Simple LLM Summary:** The paper proposes client-side experience replay, where each client maintains a small buffer of past data samples, to mitigate catastrophic forgetting in Federated Learning under temporal concept drift. Experiments show this simple method, without changing server aggregation, effectively restores model performance, demonstrating a clear trade-off between memory buffer size and accuracy.

- **[arXiv260121] RASC: Enhancing Observability & Programmability in Smart Spaces**
  - **tags:** [sys], [IoT systems], [RASC, RPC, Home Assistant, scheduling, observability, programmability]
  - **authors:** Anna Karanika, Kai-Siang Wang, Han-Ting Liang, Shalni Sundram, Indranil Gupta
  - **institution:** University of Illinois Urbana-Champaign
  - **link:** https://arxiv.org/pdf/2601.13496
  - **Simple LLM Summary:** The paper introduces the RASC (Request-Acknowledge-Start-Complete) abstraction to enhance observability and programmability for IoT actions in smart spaces. It integrates RASC into the Home Assistant framework, and evaluations show it meets latency SLOs for long actions and improves scheduling performance by 10%-55%.

- **[arXiv260121] Driving Computational Efficiency in Large-Scale Platforms using HPC Technologies**
  - **tags:** [sys], [HPC resource efficiency], [workload characterization, CPU utilization, walltime utilization, I/O patterns, Monte Carlo simulations, task-parallel execution]
  - **authors:** Alexander Martinez Mendez, Antonio J. Rubio-Montero, Carlos J. Barrios H., Hernán Asorey, Rafael Mayo-García, Luis A. Núñez
  - **institution:** Universidad Industrial de Santander, Centre for Energy, Environmental and Technological Research (CIEMAT), INRIA
  - **link:** https://arxiv.org/pdf/2601.13424
  - **Simple LLM Summary:** This paper analyzes historical job accounting data from the EGI FedCloud platform to characterize the computational workloads and quantify resource utilization efficiency for the LAGO astroparticle physics project. The study identifies key workload categories and efficiency metrics, revealing patterns such as high CPU efficiency in simulation tasks but inefficiencies from short test jobs. The findings provide data-driven recommendations for optimizing resource requests and workflow management to maximize scientific output from HPC investments.

- **[arXiv260121] Towards Scalable Federated Container Orchestration: The CODECO Approach**
  - **tags:** [mlsys], [cluster infrastructure], [federated orchestration, Kubernetes, semantic application models, partition-based federation, AI-assisted decision support, data-compute-network co-orchestration]
  - **authors:** Rute C. Sofia, Josh Salomon, Ray Carrol, Luis Garcés-Erice, Peter Urbanetz, Jürgen Gesswein, Rizkallah Touma, Alejandro Espinosa, Luis M. Contreras, Vasileios Theodorou, George Papathanail, Georgios Koukis, Vassilis Tsaoussidis, Alberto del Rio, David Jimenez, Efterpi Paraskevoulakou, Panagiotis Karamolegkos, John Soldatos, Borja Dorado Nogales, Alejandro Tjaarda
  - **institution:** fortiss GmbH, Red Hat, IBM Research Europe - Zurich, Siemens AG, i2CAT Foundation, Telefónica, Intracom Telecom, Democritus University of Thrace / Athena Research Center, Universidad Politécnica de Madrid, University of Piraeus Research Centre, Netcompany, Universidad Carlos III de Madrid
  - **link:** https://arxiv.org/pdf/2601.13351
  - **Simple LLM Summary:** The paper introduces CODECO, a federated orchestration framework that extends Kubernetes with semantic models, partition-based federation, and AI-assisted decision-making to manage applications across heterogeneous Edge-Cloud environments. It employs a hybrid governance model combining centralized policy with decentralized execution to support autonomy while maintaining global coherence. The main conclusion is that CODECO addresses the limitations of cloud-centric container orchestration by enabling scalable, context-aware, and adaptive management in federated infrastructures.

- **[arXiv260121] Automatic Adjustment of HPA Parameters and Attack Prevention in Kubernetes Using Random Forests**
  - **tags:** [mlsys], [cluster infrastructure], [Random Forest, HTTP status codes, HPA, Kubernetes, honeypot]
  - **authors:** Hanlin Zhou, Huah Yong Chan, Jingfei Ni, Mengchun Wu, Qing Deng
  - **institution:** Universiti Sains Malaysia, Xiamen Institute of Software Technology, Manzhouli Customs, Jimei University
  - **link:** https://arxiv.org/pdf/2601.13515
  - **Simple LLM Summary:** This paper proposes a method that uses the Random Forest algorithm to predict attacks based on HTTP status codes and dynamically adjusts the Horizontal Pod Autoscaler (HPA) parameters in Kubernetes to manage traffic. It redirects attack traffic to honeypots, preventing excessive scaling and effectively isolating malicious access. The experiments highlight the importance of setting appropriate thresholds for HPA adjustments to maintain system stability under attack.

- **[arXiv260121] A Kubernetes custom scheduler based on reinforcement learning for compute-intensive pods**
  - **tags:** [mlsys], [cluster infrastructure], [reinforcement learning, deep q-network, kubernetes scheduler, pod scheduling, compute-intensive workloads]
  - **authors:** Hanlin Zhou, Huah Yong Chan, Shun Yao Zhang, Meie Lin, Jingfei Ni
  - **institution:** Universiti Sains Malaysia, Xiamen Institute of Software Technology
  - **link:** https://arxiv.org/pdf/2601.13579
  - **Simple LLM Summary:** This paper proposes two custom Kubernetes schedulers, SDQN and SDQN-n, based on Deep Q-Network reinforcement learning for scheduling compute-intensive pods. The models outperform the default Kubernetes scheduler and other alternatives, reducing average CPU utilization per node by 10% and over 20% with SDQN-n, demonstrating improved resource efficiency and energy savings.

- **[arXiv260121] ContiguousKV: Accelerating LLM Prefill with Granularity-Aligned KV Cache Management**
  - **tags:** [mlsys], [llm inference], [KV cache offloading, KV cache pruning, read amplification, asynchronous prefetching, attention-guided cache management]
  - **authors:** Jing Zou, Shangyu Wu, Hancong Duan, Qiao Li, Chun Jason Xue
  - **institution:** UESTC, MBZUAI
  - **link:** https://arxiv.org/pdf/2601.13631
  - **Simple LLM Summary:** This paper proposes ContiguousKV, a system that accelerates the LLM prefill phase by aligning KV cache pruning granularity with I/O operations using ContiguousChunks and employing asynchronous prefetching to break I/O-compute dependencies. It eliminates read amplification and idle resource bubbles. Evaluations show it achieves a 3.85x speedup over the state-of-the-art system IMPRESS while maintaining output quality.

- **[arXiv260121] Why Does the LLM Stop Computing: An Empirical Study of User-Reported Failures in Open-Source LLMs**
  - **tags:** [mlsys], [llm inference], [empirical study, failure analysis, deployment stack, tokenizer defects, fine-tuning, orchestration]
  - **authors:** Guangba Yu, Zirui Wang, Yujie Huang, Renyi Zhong, Yuedong Zhong, Yilun Wang, Michael R. Lyu
  - **institution:** The Chinese University of Hong Kong, Sun Yat-sen University
  - **link:** https://arxiv.org/pdf/2601.13655
  - **Simple LLM Summary:** This paper conducts a large-scale empirical study of 705 real-world failures from open-source LLM ecosystems (DeepSeek, Llama, Qwen). It concludes that in user-managed deployments, the primary reliability bottleneck shifts from algorithmic defects to systemic fragility in the deployment stack, identifying key failure patterns like diagnostic divergence and lifecycle escalation.

- **[arXiv260121] A Blockchain-Oriented Software Engineering Architecture for Carbon Credit Certification Systems**
  - **tags:** [sys], [blockchain-IoT integration], [blockchain, IoT, smart contracts, edge computing, carbon credit certification, smart meters, permissioned blockchain]
  - **authors:** Matteo Vaccargiu, Azmat Ullah, Pierluigi Gallo
  - **institution:** University of Cagliari, University of Camerino, University of Palermo
  - **link:** https://arxiv.org/pdf/2601.13772
  - **Simple LLM Summary:** The paper proposes a blockchain-based software architecture that integrates IoT data collection, edge-level aggregation, and smart contracts on a permissioned blockchain for carbon credit certification. It demonstrates the system through a photovoltaic case study, showing how it aligns with legislation and reduces transaction costs. The main conclusion is that this architecture provides a verifiable and structured pathway for generating carbon-credit records, particularly supporting small and medium-scale renewable installations.

- **[arXiv260121] Device Association and Resource Allocation for Hierarchical Split Federated Learning in Space-Air-Ground Integrated Network**
  - **tags:** [mlsys], [others], [hierarchical split federated learning, device association, resource allocation, model split layer selection, iterative optimization, brute-force search]
  - **authors:** Haitao Zhao, Xiaoyu Tang, Bo Xu, Jinlong Sun, Linghao Zhang
  - **institution:** Nanjing University of Posts and Telecommunications
  - **link:** https://arxiv.org/pdf/2601.13817
  - **Simple LLM Summary:** This paper proposes a Hierarchical Split Federated Learning (HSFL) framework for the Space-Air-Ground Integrated Network to address resource constraints and unbalanced data distribution. It formulates a joint optimization problem for device association, model split point selection, and resource allocation, solved via an iterative algorithm. Simulation results show the proposed method effectively balances training efficiency and model accuracy in SAGIN.

- **[arXiv260121] Efficient Parallel $(Δ+1)$-Edge-Coloring**
  - **tags:** [sys], [parallel algorithms], [PRAM, Vizing's theorem, edge-coloring, parallel algorithm, arboricity]
  - **authors:** Michael Elkin, Ariel Khuzman
  - **institution:** Ben-Gurion University of the Negev
  - **link:** https://arxiv.org/pdf/2601.13822
  - **Simple LLM Summary:** The paper presents a new parallel algorithm for the (Δ+1)-edge-coloring problem in the PRAM model, improving upon previous time and processor bounds. It corrects an analysis flaw in prior work and offers several trade-offs, including a variant with near-quartic time in Δ and logarithmic factors in n. The algorithm also provides a faster and simpler method for updating edge colorings compared to the previous state-of-the-art.

- **[arXiv260121] Know Your Contract: Extending eIDAS Trust into Public Blockchains**
  - **tags:** [sys], [blockchain, trust frameworks], [eIDAS, qualified electronic seal, smart contract, ECDSA P-256, CAdES, on-chain validation, regulatory compliance]
  - **authors:** Awid Vaziry, Christoph Wronka, Sandro Rodriguez Garzon, Axel Küpper
  - **institution:** Technische Universität Berlin, Baker Tilly
  - **link:** https://arxiv.org/pdf/2601.13903
  - **Simple LLM Summary:** This paper proposes an architecture that cryptographically binds smart contracts to qualified electronic seals under the EU's eIDAS framework, creating a verifiable chain of trust from legal entities to blockchain addresses. It enables automated, machine-verifiable regulatory checks like Know Your Contract. The main conclusion is that this approach integrates European digital trust infrastructure into public blockchains, enabling institutional DeFi and compliant tokenization without new intermediaries.

- **[arXiv260121] torch-sla: Differentiable Sparse Linear Algebra with Adjoint Solvers and Sparse Tensor Parallelism for PyTorch**
  - **tags:** [mlsys], [GPU kernels], [sparse linear algebra, adjoint-based differentiation, domain decomposition, halo exchange, PyTorch autograd, cuDSS backend]
  - **authors:** Mingyuan Chi
  - **institution:** (Institution not explicitly stated; inferred from email domain: gmail.com - no clear institutional affiliation)
  - **link:** https://arxiv.org/pdf/2601.13994
  - **Simple LLM Summary:** This paper introduces torch-sla, a PyTorch library for GPU-accelerated, scalable, and differentiable sparse linear algebra. It addresses key challenges by providing multi-GPU scaling via domain decomposition and efficient gradient computation using adjoint-based differentiation, which reduces memory overhead. The library enables end-to-end differentiable simulations with large-scale sparse systems, such as solving a 400 million DOF linear problem on 3 GPUs.

- **[arXiv260121] "Range as a Key" is the Key! Fast and Compact Cloud Block Store Index with RASK**
  - **tags:** [sys], [cloud storage indexing], [range-as-a-key, log-structured leaf, range-aware split/merge, tree-structured index, garbage collection]
  - **authors:** Haoru Zhao, Mingkai Dong, Erci Xu, Zhongyu Wang, Haibo Chen
  - **institution:** Shanghai Jiao Tong University, Alibaba Group
  - **link:** https://arxiv.org/pdf/2601.14129
  - **Simple LLM Summary:** The paper proposes RASK, a tree-structured index for cloud block stores that directly indexes block ranges instead of individual blocks to save memory. It addresses challenges like range overlap using log-structured leaves and reduces fragmentation with range-aware split/merge mechanisms. Evaluation on production traces shows RASK reduces memory footprint by up to 98.9% and increases throughput by up to 31.0x compared to state-of-the-art indexes.

- **[arXiv260121] SecureSplit: Mitigating Backdoor Attacks in Split Learning**
  - **tags:** [mlsys], [others], [split learning, backdoor attacks, dimensionality transformation, adaptive filtering, majority-based voting, embedding separation]
  - **authors:** Zhihao Dou, Dongfei Cui, Weida Wang, Anjun Gao, Yueyang Quan, Mengyao Ma, Viet Vo, Guangdong Bai, Zhuqing Liu, Minghong Fang
  - **institution:** Case Western Reserve University, Northeast Electric Power University, Fudan University, University of Louisville, University of North Texas, The University of Queensland, Swinburne University of Technology, City University of Hong Kong
  - **link:** https://arxiv.org/pdf/2601.14054
  - **Simple LLM Summary:** The paper introduces SecureSplit, a defense mechanism for Split Learning that uses a dimensionality transformation strategy to highlight differences between benign and poisoned embeddings, followed by an adaptive filtering approach to remove malicious ones. The method is validated through experiments on multiple datasets and attack scenarios, demonstrating its effectiveness in mitigating backdoor attacks while preserving model utility.

- **[arXiv260121] Multi-Partner Project: Multi-GPU Performance Portability Analysis for CFD Simulations at Scale**
  - **tags:** [sys], [high-performance computing], [performance portability, computational fluid dynamics, spectral finite element method, multi-GPU, design space exploration, scalability analysis]
  - **authors:** Panagiotis-Eleftherios Eleftherakis, George Anagnostopoulos, Anastassis Kapetanakis, Mohammad Umair, Jean-Yves Vet, Konstantinos Iliakis, Jonathan Vincent, Jing Gong, Akshay Patil, Clara García-Sánchez, Gerardo Zampino, Ricardo Vinuesa, Sotirios Xydis
  - **institution:** National Technical University of Athens, KTH Royal Institute of Technology, Hewlett Packard Enterprise (HPE), Technical University of Delft, University of Michigan
  - **link:** https://arxiv.org/pdf/2601.14159
  - **Simple LLM Summary:** This paper analyzes the performance portability of the SOD2D Spectral Elements CFD framework across AMD and NVIDIA GPU architectures. The method involves a multi-level, full-stack design space exploration to characterize performance and scalability. The main conclusion is that memory access optimizations cause significant performance deviations (0.69x to 3.91x speedup variations), highlighting the limits of performance projections and the need for informed, multi-level tuning for portable efficiency.


**cs.AI/cs.LG contains "reinforcement learning" total: 47**
- [arXiv260121] Hindsight Preference Replay Improves Preference-Conditioned Multi-Objective Reinforcement Learning [link](https://arxiv.org/pdf/2601.11604)
- [arXiv260121] Reinforcement Learning for Dynamic Workflow Optimization in CI/CD Pipelines [link](https://arxiv.org/pdf/2601.11647)
- [arXiv260121] Bielik 11B v3: Multilingual Large Language Model for European Languages [link](https://arxiv.org/pdf/2601.11579)
- [arXiv260121] GRADE: Replacing Policy Gradients with Backpropagation for LLM Alignment [link](https://arxiv.org/pdf/2601.11574)
- [arXiv260121] AGGC: Adaptive Group Gradient Clipping for Stabilizing Large Language Model Training [link](https://arxiv.org/pdf/2601.11864)
- [arXiv260121] Controlling Underestimation Bias in Constrained Reinforcement Learning for Safe Exploration [link](https://arxiv.org/pdf/2601.11953)
- [arXiv260121] R$^2$PO: Decoupling Training Trajectories from Inference Responses for LLM Reasoning [link](https://arxiv.org/pdf/2601.11960)
- [arXiv260121] Extreme Value Policy Optimization for Safe Reinforcement Learning [link](https://arxiv.org/pdf/2601.12008)
- [arXiv260121] UniMo: Unified Motion Generation and Understanding with Chain of Thought [link](https://arxiv.org/pdf/2601.12126)
- [arXiv260121] Aletheia: What Makes RLVR For Code Verifiers Tick? [link](https://arxiv.org/pdf/2601.12186)
- [arXiv260121] Speculative Sampling with Reinforcement Learning [link](https://arxiv.org/pdf/2601.12212)
- [arXiv260121] Optimal Power Allocation and Sub-Optimal Channel Assignment for Downlink NOMA Systems Using Deep Reinforcement Learning [link](https://arxiv.org/pdf/2601.12242)
- [arXiv260121] Beyond the Dirac Delta: Mitigating Diversity Collapse in Reinforcement Fine-Tuning for Versatile Image Generation [link](https://arxiv.org/pdf/2601.12401)
- [arXiv260121] Incentivizing In-depth Reasoning over Long Contexts with Process Advantage Shaping [link](https://arxiv.org/pdf/2601.12465)
- [arXiv260121] Agentic Reasoning for Large Language Models [link](https://arxiv.org/pdf/2601.12538)
- [arXiv260121] STEP-LLM: Generating CAD STEP Models from Natural Language with Large Language Models [link](https://arxiv.org/pdf/2601.12641)
- [arXiv260121] Decentralized Learning Strategies for Estimation Error Minimization with Graph Neural Networks [link](https://arxiv.org/pdf/2601.12662)
- [arXiv260121] Resource-Conscious RL Algorithms for Deep Brain Stimulation [link](https://arxiv.org/pdf/2601.12699)
- [arXiv260121] Decoding Rewards in Competitive Games: Inverse Game Theory with Entropy Regularization [link](https://arxiv.org/pdf/2601.12707)
- [arXiv260121] Teaching Large Reasoning Models Effective Reflection [link](https://arxiv.org/pdf/2601.12720)
- [arXiv260121] Distribution-Centric Policy Optimization Dominates Exploration-Exploitation Trade-off [link](https://arxiv.org/pdf/2601.12730)
- [arXiv260121] Teaching LLMs to Learn Tool Trialing and Execution through Environment Interaction [link](https://arxiv.org/pdf/2601.12762)
- [arXiv260121] Communication Methods in Multi-Agent Reinforcement Learning [link](https://arxiv.org/pdf/2601.12886)
- [arXiv260121] PaperGuide: Making Small Language-Model Paper-Reading Agents More Efficient [link](https://arxiv.org/pdf/2601.12988)
- [arXiv260121] Training instability in deep learning follows low-dimensional dynamical principles [link](https://arxiv.org/pdf/2601.13160)
- [arXiv260121] CURE-Med: Curriculum-Informed Reinforcement Learning for Multilingual Medical Reasoning [link](https://arxiv.org/pdf/2601.13262)
- [arXiv260121] Balancing Classification and Calibration Performance in Decision-Making LLMs via Calibration Aware Reinforcement Learning [link](https://arxiv.org/pdf/2601.13284)
- [arXiv260121] Reasoning While Recommending: Entropy-Guided Latent Reasoning in Generative Re-ranking Models [link](https://arxiv.org/pdf/2601.13533)
- [arXiv260121] Behavior Knowledge Merge in Reinforced Agentic Models [link](https://arxiv.org/pdf/2601.13572)
- [arXiv260121] Communication-Free Collective Navigation for a Swarm of UAVs via LiDAR-Based Deep Reinforcement Learning [link](https://arxiv.org/pdf/2601.13657)
- [arXiv260121] Reinforcement Learning for Opportunistic Routing in Software-Defined LEO-Terrestrial Systems [link](https://arxiv.org/pdf/2601.13662)
- [arXiv260121] Finding RELIEF: Shaping Reasoning Behavior without Reasoning Supervision via Belief Engineering [link](https://arxiv.org/pdf/2601.13752)
- [arXiv260121] TractRLFusion: A GPT-Based Multi-Critic Policy Fusion Framework for Fiber Tractography [link](https://arxiv.org/pdf/2601.13897)
- [arXiv260121] Glance-or-Gaze: Incentivizing LMMs to Adaptively Focus Search via Reinforcement Learning [link](https://arxiv.org/pdf/2601.13942)
- [arXiv260121] RL-BioAug: Label-Efficient Reinforcement Learning for Self-Supervised EEG Representation Learning [link](https://arxiv.org/pdf/2601.13964)
- [arXiv260121] Optimizing Energy and Data Collection in UAV-aided IoT Networks using Attention-based Multi-Objective Reinforcement Learning [link](https://arxiv.org/pdf/2601.14092)
- [arXiv260121] Toward Efficient Agents: Memory, Tool learning, and Planning [link](https://arxiv.org/pdf/2601.14192)
- [arXiv260121] Differentiated Pickup Point Offering for Emission Reduction in Last-Mile Delivery [link](https://arxiv.org/pdf/2601.14196)
- [arXiv260121] InT: Self-Proposed Interventions Enable Credit Assignment in LLM Reasoning [link](https://arxiv.org/pdf/2601.14209)
- [arXiv260121] Attention-Based Offline Reinforcement Learning and Clustering for Interpretable Sepsis Treatment [link](https://arxiv.org/pdf/2601.14228)
- [arXiv260121] KAGE-Bench: Fast Known-Axis Visual Generalization Evaluation for Reinforcement Learning [link](https://arxiv.org/pdf/2601.14232)
- [arXiv260121] Q-learning with Adjoint Matching [link](https://arxiv.org/pdf/2601.14234)
- [arXiv260121] Spatiotemporal Wildfire Prediction and Reinforcement Learning for Helitack Suppression [link](https://arxiv.org/pdf/2601.14238)
- [arXiv260121] Jet-RL: Enabling On-Policy FP8 Reinforcement Learning with Unified Training and Rollout Precision Flow [link](https://arxiv.org/pdf/2601.14243)
- [arXiv260121] A New Strategy for Artificial Intelligence: Training Foundation Models Directly on Human Brain Data [link](https://arxiv.org/pdf/2601.12053)
- [arXiv260121] Primate-like perceptual decision making emerges through deep recurrent reinforcement learning [link](https://arxiv.org/pdf/2601.12577)
- [arXiv260121] Sample Complexity of Average-Reward Q-Learning: From Single-agent to Federated Reinforcement Learning [link](https://arxiv.org/pdf/2601.13642)

**cs.AI/cs.LG contains "accelerate" total: 37**
- [arXiv260121] Reinforcement Learning for Dynamic Workflow Optimization in CI/CD Pipelines [link](https://arxiv.org/pdf/2601.11647)
- [arXiv260121] Mixture of Distributions Matters: Dynamic Sparse Attention for Efficient Video Diffusion Transformers [link](https://arxiv.org/pdf/2601.11641)
- [arXiv260121] DeepEvidence: Empowering Biomedical Discovery with Deep Knowledge Graph Research [link](https://arxiv.org/pdf/2601.11560)
- [arXiv260121] Overview of the SciHigh Track at FIRE 2025: Research Highlight Generation from Scientific Papers [link](https://arxiv.org/pdf/2601.11582)
- [arXiv260121] Speculative Decoding: Performance or Illusion? [link](https://arxiv.org/pdf/2601.11580)
- [arXiv260121] NoiseFormer -- Noise Diffused Symmetric Attention Transformer [link](https://arxiv.org/pdf/2601.11619)
- [arXiv260121] A Proof of Concept for a Digital Twin of an Ultrasonic Fermentation System [link](https://arxiv.org/pdf/2601.11723)
- [arXiv260121] Large language models struggle with ethnographic text annotation [link](https://arxiv.org/pdf/2601.12099)
- [arXiv260121] Ordered Local Momentum for Asynchronous Distributed Learning under Arbitrary Delays [link](https://arxiv.org/pdf/2601.12322)
- [arXiv260121] Harmonizing the Arabic Audio Space with Data Scheduling [link](https://arxiv.org/pdf/2601.12494)
- [arXiv260121] Life, Machine Learning, and the Search for Habitability: Predicting Biosignature Fluxes for the Habitable Worlds Observatory [link](https://arxiv.org/pdf/2601.12557)
- [arXiv260121] A Cloud-based Multi-Agentic Workflow for Science [link](https://arxiv.org/pdf/2601.12607)
- [arXiv260121] HERMES: A Unified Open-Source Framework for Realtime Multimodal Physiological Sensing, Edge AI, and Intervention in Closed-Loop Smart Healthcare Applications [link](https://arxiv.org/pdf/2601.12610)
- [arXiv260121] Mixed Precision PointPillars for Efficient 3D Object Detection with TensorRT [link](https://arxiv.org/pdf/2601.12638)
- [arXiv260121] Distilling Time Series Foundation Models for Efficient Forecasting [link](https://arxiv.org/pdf/2601.12785)
- [arXiv260121] From Prefix Cache to Fusion RAG Cache: Accelerating LLM Inference in Retrieval-Augmented Generation [link](https://arxiv.org/pdf/2601.12904)
- [arXiv260121] PaperGuide: Making Small Language-Model Paper-Reading Agents More Efficient [link](https://arxiv.org/pdf/2601.12988)
- [arXiv260121] Probe and Skip: Self-Predictive Token Skipping for Efficient Long-Context LLM Inference [link](https://arxiv.org/pdf/2601.13155)
- [arXiv260121] The Geometry of Thought: How Scale Restructures Reasoning In Large Language Models [link](https://arxiv.org/pdf/2601.13358)
- [arXiv260121] Patterning: The Dual of Interpretability [link](https://arxiv.org/pdf/2601.13548)
- [arXiv260121] Vulnerability of LLMs' Belief Systems? LLMs Belief Resistance Check Through Strategic Persuasive Conversation Interventions [link](https://arxiv.org/pdf/2601.13590)
- [arXiv260121] Machine learning based radiative parameterization scheme and its performance in operational reforecast experiments [link](https://arxiv.org/pdf/2601.13592)
- [arXiv260121] Communication-Free Collective Navigation for a Swarm of UAVs via LiDAR-Based Deep Reinforcement Learning [link](https://arxiv.org/pdf/2601.13657)
- [arXiv260121] HeteroCache: A Dynamic Retrieval Approach to Heterogeneous KV Cache Compression for Long-Context LLM Inference [link](https://arxiv.org/pdf/2601.13684)
- [arXiv260121] Breaking the Data Barrier in Learning Symbolic Computation: A Case Study on Variable Ordering Suggestion for Cylindrical Algebraic Decomposition [link](https://arxiv.org/pdf/2601.13731)
- [arXiv260121] A universal linearized subspace refinement framework for neural networks [link](https://arxiv.org/pdf/2601.13989)
- [arXiv260121] Group-Invariant Unsupervised Skill Discovery: Symmetry-aware Skill Representations for Generalizable Behavior [link](https://arxiv.org/pdf/2601.14000)
- [arXiv260121] Credible CO2 Comparisons: A Machine Learning Approach to Vehicle Powertrain Assessment [link](https://arxiv.org/pdf/2601.14022)
- [arXiv260121] '1'-bit Count-based Sorting Unit to Reduce Link Power in DNN Accelerators [link](https://arxiv.org/pdf/2601.14087)
- [arXiv260121] Quantum Kernel Machine Learning for Autonomous Materials Science [link](https://arxiv.org/pdf/2601.11775)
- [arXiv260121] On the Provable Suboptimality of Momentum SGD in Nonstationary Stochastic Optimization [link](https://arxiv.org/pdf/2601.12238)
- [arXiv260121] BiCoLoR: Communication-Efficient Optimization with Bidirectional Compression and Local Training [link](https://arxiv.org/pdf/2601.12400)
- [arXiv260121] Artificial Intelligence in Materials Science and Engineering: Current Landscape, Key Challenges, and Future Trajectorie [link](https://arxiv.org/pdf/2601.12554)
- [arXiv260121] onepot CORE -- an enumerated chemical space to streamline drug discovery, enabled by automated small molecule synthesis and AI [link](https://arxiv.org/pdf/2601.12603)
- [arXiv260121] Reorienting off-path Nudged Elastic Bands (RONEB) via Minimum Mode Following [link](https://arxiv.org/pdf/2601.12630)
- [arXiv260121] Pixelwise Uncertainty Quantification of Accelerated MRI Reconstruction [link](https://arxiv.org/pdf/2601.13236)
- [arXiv260121] Unified Unbiased Variance Estimation for MMD: Robust Finite-Sample Performance with Imbalanced Data and Exact Acceleration under Null and Alternative Hypotheses [link](https://arxiv.org/pdf/2601.13874)

## 2026-01-22

**cs.DC total: 13**

- **[arXiv260122] Agent Identity URI Scheme: Topology-Independent Naming and Capability-Based Discovery for Multi-Agent Systems**
  - **tags:** [sys], [distributed systems], [agent:// URI, DHT, PASETO, capability-based discovery, decentralized identity]
  - **authors:** Roland R. Rodriguez Jr
  - **institution:** Independent Researcher
  - **link:** https://arxiv.org/pdf/2601.14567
  - **Simple LLM Summary:** This paper proposes a new agent:// URI scheme to decouple agent identity from network location, using a trust root, capability path, and unique identifier. It enables decentralized, capability-based discovery via DHTs and cryptographic attestation. The authors conclude that this scheme provides a stable, high-performance foundation for identity and discovery in multi-agent systems.

- **[arXiv260122] Specifying and Verifying RDMA Synchronisation (Extended Version)**
  - **tags:** [sys], [distributed computing], [RDMA, formal semantics, read-modify-write, TSO, verification, locks]
  - **authors:** Guillaume Ambal, Max Stupple, Brijesh Dongol, Azalea Raad
  - **institution:** Imperial College London, University of Surrey
  - **link:** https://arxiv.org/pdf/2601.14642
  - **Simple LLM Summary:** This paper introduces a formal semantics for remote read-modify-write (RMW) instructions in RDMA over TSO, enabling the verification of synchronisation abstractions like locks. It develops libraries for remote locks and a strong RDMA model, ensuring compatibility with existing high-performance libraries.

- **[arXiv260122] Beyond Denial-of-Service: The Puppeteer's Attack for Fine-Grained Control in Ranking-Based Federated Learning**
  - **tags:** [mlsys], [others], [federated rank learning, edge control attack, model poisoning, fine-grained control, byzantine-robust aggregation]
  - **authors:** Zhihao Chen, Zirui Gong, Jianting Ning, Yanjun Zhang, Leo Yu Zhang
  - **institution:** Fujian Normal University, Griffith University
  - **link:** https://arxiv.org/pdf/2601.14687
  - **Simple LLM Summary:** This paper introduces the Edge Control Attack (ECA), a novel fine-grained model poisoning attack against Federated Rank Learning (FRL). The attack precisely degrades a model's accuracy to a target level while evading detection by maintaining a normal convergence trajectory. The findings demonstrate a vulnerability in ranking-based FL and highlight the need for stronger defenses.

- **[arXiv260122] Exploiting Spot Instances for Time-Critical Cloud Workloads Using Optimal Randomized Strategies**
  - **tags:** [sys], [cloud scheduling], [randomized algorithm, online scheduling, competitive analysis, spot instances, on-demand instances, deadline-aware, ROSS]
  - **authors:** Neelkamal Bhuyan, Randeep Bhatia, Murali Kodialam, TV Lakshman
  - **institution:** Georgia Institute of Technology, Nokia Bell Labs
  - **link:** https://arxiv.org/pdf/2601.14612
  - **Simple LLM Summary:** The paper introduces ROSS, a novel randomized online scheduling algorithm for running time-critical jobs on a mix of cheap but unreliable spot instances and expensive on-demand cloud instances. It proves that ROSS achieves an optimal competitive ratio of √K, significantly improving over deterministic policies. Evaluations on real-world cloud traces show it reduces costs by up to 30% while meeting hard deadlines.

- **[arXiv260122] AlertGuardian: Intelligent Alert Life-Cycle Management for Large-scale Cloud Systems**
  - **tags:** [mlsys], [others], [large language models (LLMs), graph learning model, Retrieval Augmented Generation (RAG), multi-agent iterative feedback, alert denoise, alert summary, alert rule refinement]
  - **authors:** Guangba Yu, Genting Mai, Rui Wang, Ruipeng Li, Pengfei Chen, Long Pan, Ruijie Xu
  - **institution:** Sun Yat-sen University, Tencent
  - **link:** https://arxiv.org/pdf/2601.14912
  - **Simple LLM Summary:** The paper proposes AlertGuardian, a framework that combines large language models (LLMs) and lightweight graph models to manage the alert life-cycle in cloud systems through denoising, summarization, and rule refinement. It significantly reduces alert fatigue and improves fault diagnosis accuracy, as validated on real-world datasets from a major cloud provider.

- **[arXiv260122] Optimizing FaaS Platforms for MCP-enabled Agentic Workflows**
  - **tags:** [mlsys], [llm inference], [FaaS, AWS Lambda, LangGraph, AWS Step Functions, DynamoDB, S3, Model Context Protocol (MCP), serverless, agentic workflows]
  - **authors:** Varad Kulkarni, Vaibhav Jha, Nikhil Reddy, Yogesh Simmhan
  - **institution:** Indian Institute of Science, Bangalore
  - **link:** https://arxiv.org/pdf/2601.14735
  - **Simple LLM Summary:** This paper proposes FAME, a serverless architecture that decomposes AI agent workflows into modular Functions-as-a-Service (FaaS) components orchestrated with AWS Step Functions and LangGraph, and uses DynamoDB for state persistence. It demonstrates that this approach significantly reduces latency and cost while improving completion rates for complex, multi-agent AI workflows compared to traditional hosting methods.

- **[arXiv260122] Application-level observability for adaptive Edge to Cloud continuum systems**
  - **tags:** [mlsys], [fault-tolerance], [OpenTelemetry, Prometheus, K3s, Chaos Mesh, SLO-aware feedback, adaptive control]
  - **authors:** Kaddour Sidi, Daniel Balouek, Baptiste Jonglez
  - **institution:** IMT Atlantique, Inria, LS2N
  - **link:** https://arxiv.org/pdf/2601.14923
  - **Simple LLM Summary:** This paper proposes an application-level observability framework for Edge-to-Cloud systems, integrating developer-driven instrumentation and SLO-aware feedback for autonomous adaptation. It combines tools like OpenTelemetry and Prometheus for monitoring and uses a video processing case to demonstrate automatic adjustments to maintain performance under variable loads and faults. The preliminary results show the framework improves scalability, fault tolerance, and responsiveness for adaptive, SLO-compliant applications.

- **[arXiv260122] Parallel Collaborative ADMM Privacy Computing and Adaptive GPU Acceleration for Distributed Edge Networks**
  - **tags:** [mlsys], [GPU kernels], [ADMM, Paillier homomorphic encryption, quantization, GPU acceleration, parallel encryption]
  - **authors:** Mengchun Xia, Zhicheng Dong, Donghong Cai, Fang Fang, Lisheng Fan, Pingzhi Fan
  - **institution:** Tibet University, Jinan University, Western University, Guangzhou University, Southwest Jiaotong University
  - **link:** https://arxiv.org/pdf/2601.14980
  - **Simple LLM Summary:** This paper proposes a three-phase parallel collaborative ADMM privacy computing (3P-ADMM-PC2) algorithm for distributed edge networks, which uses Paillier homomorphic encryption and quantization to protect data privacy. It also introduces a GPU acceleration method to overcome architectural mismatches and speed up encryption/decryption. Experiments show the method achieves performance close to non-private ADMM while offering significant computational speedup compared to CPU-based implementations.

- **[arXiv260122] JAXMg: A multi-GPU linear solver in JAX**
  - **tags:** [mlsys], [GPU kernels], [JAX, cuSOLVERMg, XLA Foreign Function Interface, multi-GPU, Cholesky decomposition, symmetric eigendecomposition, JIT compilation]
  - **authors:** Roeland Wiersema
  - **institution:** Flatiron Institute
  - **link:** https://arxiv.org/pdf/2601.14466
  - **Simple LLM Summary:** This paper introduces JAXMg, a method that integrates NVIDIA's multi-GPU linear algebra library cuSOLVERMg into the JAX framework using an XLA Foreign Function Interface. This enables scalable, JIT-compatible dense linear solves and eigendecompositions across multiple GPUs directly within JAX programs. The main conclusion is that JAXMg bridges a critical gap, allowing composable, end-to-end scientific workflows in JAX to scale beyond single-GPU memory limits.

- **[arXiv260122] Exploring Performance-Productivity Trade-offs in AMT Runtimes: A Task Bench Study of Itoyori, ItoyoriFBC, HPX, and MPI**
  - **tags:** [sys], [parallel computing], [asynchronous many-task (AMT), task bench, partitioned global address space (PGAS), RDMA, work stealing, future-based synchronization, MPI, HPX, Itoyori]
  - **authors:** Torben R. Lahnor, Mia Reitz, Jonas Posner, Patrick Diehl
  - **institution:** University of Kassel, Fulda University of Applied Sciences, Los Alamos National Laboratory (LANL)
  - **link:** https://arxiv.org/pdf/2601.14608
  - **Simple LLM Summary:** This paper integrates the Itoyori and ItoyoriFBC asynchronous many-task runtimes into the Task Bench framework to compare their performance and programmer productivity against MPI and HPX. The evaluation uses metrics like application efficiency, minimum effective task granularity, lines of code, and number of library constructs. The results show distinct trade-offs: MPI excels in regular workloads but is low-level, HPX handles load imbalance well but is less productive, while Itoyori leads in communication-intensive performance and programmer productivity.

- **[arXiv260122] RadixMLP - Intra-batch Deduplication for Causal Transformers**
  - **tags:** [mlsys], [llm inference], [prefix deduplication, prefix trie, gather-scatter, stateless inference, position-wise computation]
  - **authors:** Michael Feil, Julius Lipp
  - **institution:** Baseten, Independent
  - **link:** https://arxiv.org/pdf/2601.15013
  - **Simple LLM Summary:** The paper introduces RadixMLP, a stateless technique that eliminates redundant computation in causal transformer inference by dynamically mapping batch sequences to a prefix trie, gathering shared segments for position-wise computation, and scattering results at attention boundaries. It achieves speedups of 1.44–1.59× in real-world reranking tasks and up to 5× in synthetic benchmarks with long shared prefixes.

- **[arXiv260122] DeepFedNAS: A Unified Framework for Principled, Hardware-Aware, and Predictor-Free Federated Neural Architecture Search**
  - **tags:** [mlsys], [others], [federated learning, neural architecture search, supernet, pareto optimal, predictor-free search, hardware-aware]
  - **authors:** Bostan Khan, Masoud Daneshtalab
  - **institution:** Mälardalen University
  - **link:** https://arxiv.org/pdf/2601.15127
  - **Simple LLM Summary:** The paper introduces DeepFedNAS, a framework for Federated Neural Architecture Search that uses a principled fitness function and a Pareto-optimal cache to guide supernet training, followed by a predictor-free search method for rapid subnet discovery. It achieves higher accuracy and efficiency while drastically reducing the search time from hours to seconds, making hardware-aware federated learning deployments practical.

- **[arXiv260122] On Distributed Quantum Computing with Distributed Fan-Out Operations**
  - **tags:** [sys], [distributed quantum computing], [distributed fan-out operations, GHZ states, circuit depth reduction, entanglement resources, distributed CNOT gates]
  - **authors:** Seng W. Loke
  - **institution:** Deakin University
  - **link:** https://arxiv.org/pdf/2601.14734
  - **Simple LLM Summary:** The paper proposes using distributed fan-out operations, which leverage multipartite GHZ states, as a primitive for distributed quantum computing. It compares circuits using only entangled pairs versus those using fan-out, demonstrating advantages in reduced circuit depth and potentially lower entanglement resource requirements. The main conclusion is that distributed GHZ states could serve as a fundamental building block for efficient distributed quantum operations if they can be realized practically.


**cs.AI/cs.LG contains "reinforcement learning" total: 23**
- [arXiv260122] Improving Regret Approximation for Unsupervised Dynamic Environment Generation [link](https://arxiv.org/pdf/2601.14957)
- [arXiv260122] CI4A: Semantic Component Interfaces for Agents Empowering Web Automation [link](https://arxiv.org/pdf/2601.14790)
- [arXiv260122] Beyond Error-Based Optimization: Experience-Driven Symbolic Regression with Goal-Conditioned Reinforcement Learning [link](https://arxiv.org/pdf/2601.14693)
- [arXiv260122] What Makes Low-Bit Quantization-Aware Training Work for Reasoning LLMs? A Systematic Study [link](https://arxiv.org/pdf/2601.14888)
- [arXiv260122] CoScale-RL: Efficient Post-Training by Co-Scaling Data and Computation [link](https://arxiv.org/pdf/2601.14695)
- [arXiv260122] Proximal Policy Optimization with Evolutionary Mutations [link](https://arxiv.org/pdf/2601.14705)
- [arXiv260122] Beyond Affinity: A Benchmark of 1D, 2D, and 3D Methods Reveals Critical Trade-offs in Structure-Based Drug Design [link](https://arxiv.org/pdf/2601.14283)
- [arXiv260122] MAS-Orchestra: Understanding and Improving Multi-Agent Reasoning Through Holistic Orchestration and Controlled Benchmarks [link](https://arxiv.org/pdf/2601.14652)
- [arXiv260122] SearchGym: Bootstrapping Real-World Search Agents via Cost-Effective and High-Fidelity Environment Simulation [link](https://arxiv.org/pdf/2601.14615)
- [arXiv260122] Case-Guided Sequential Assay Planning in Drug Discovery [link](https://arxiv.org/pdf/2601.14710)
- [arXiv260122] Towards Execution-Grounded Automated AI Research [link](https://arxiv.org/pdf/2601.14525)
- [arXiv260122] Large Language Model-Powered Evolutionary Code Optimization on a Phylogenetic Tree [link](https://arxiv.org/pdf/2601.14523)
- [arXiv260122] Report for NSF Workshop on AI for Electronic Design Automation [link](https://arxiv.org/pdf/2601.14541)
- [arXiv260122] DARA: Few-shot Budget Allocation in Online Advertising via In-Context Decision Making with RL-Finetuned LLMs [link](https://arxiv.org/pdf/2601.14711)
- [arXiv260122] PCL-Reasoner-V1.5: Advancing Math Reasoning with Offline Reinforcement Learning [link](https://arxiv.org/pdf/2601.14716)
- [arXiv260122] Plug-and-Play Benchmarking of Reinforcement Learning Algorithms for Large-Scale Flow Control [link](https://arxiv.org/pdf/2601.15015)
- [arXiv260122] A Curriculum-Based Deep Reinforcement Learning Framework for the Electric Vehicle Routing Problem [link](https://arxiv.org/pdf/2601.15038)
- [arXiv260122] Memory Retention Is Not Enough to Master Memory Tasks in Reinforcement Learning [link](https://arxiv.org/pdf/2601.15086)
- [arXiv260122] Vehicle Routing with Finite Time Horizon using Deep Reinforcement Learning with Improved Network Embedding [link](https://arxiv.org/pdf/2601.15131)
- [arXiv260122] CLEANER: Self-Purified Trajectories Boost Agentic Reinforcement Learning [link](https://arxiv.org/pdf/2601.15141)
- [arXiv260122] Outcome-Based RL Provably Leads Transformers to Reason, but Only With the Right Data [link](https://arxiv.org/pdf/2601.15158)
- [arXiv260122] Knowledge Graphs are Implicit Reward Models: Path-Derived Signals Enable Compositional Reasoning [link](https://arxiv.org/pdf/2601.15160)
- [arXiv260122] The Flexibility Trap: Why Arbitrary Order Limits Reasoning Potential in Diffusion Language Models [link](https://arxiv.org/pdf/2601.15165)

**cs.AI/cs.LG contains "accelerate" total: 14**
- [arXiv260122] Variance-Adaptive Muon: Accelerating LLM Pretraining with NSR-Modulated and Variance-Scaled Momentum [link](https://arxiv.org/pdf/2601.14603)
- [arXiv260122] Measuring the State of Open Science in Transportation Using Large Language Models [link](https://arxiv.org/pdf/2601.14429)
- [arXiv260122] What Makes Low-Bit Quantization-Aware Training Work for Reasoning LLMs? A Systematic Study [link](https://arxiv.org/pdf/2601.14888)
- [arXiv260122] SilentDrift: Exploiting Action Chunking for Stealthy Backdoor Attacks on Vision-Language-Action Models [link](https://arxiv.org/pdf/2601.14323)
- [arXiv260122] Towards Execution-Grounded Automated AI Research [link](https://arxiv.org/pdf/2601.14525)
- [arXiv260122] Search over Self-Edit Strategies for LLM Adaptation [link](https://arxiv.org/pdf/2601.14532)
- [arXiv260122] GPU-accelerated simulated annealing based on p-bits with real-world device-variability modeling [link](https://arxiv.org/pdf/2601.14476)
- [arXiv260122] Quality or Quantity? Error-Informed Selective Online Learning with Gaussian Processes in Multi-Agent Systems: Extended Version [link](https://arxiv.org/pdf/2601.14275)
- [arXiv260122] End-to-End Transformer Acceleration Through Processing-in-Memory Architectures [link](https://arxiv.org/pdf/2601.14260)
- [arXiv260122] Plug-and-Play Benchmarking of Reinforcement Learning Algorithms for Large-Scale Flow Control [link](https://arxiv.org/pdf/2601.15015)
- [arXiv260122] The Responsibility Vacuum: Organizational Failure in Scaled Agent Systems [link](https://arxiv.org/pdf/2601.15059)
- [arXiv260122] LoRAP: Low-Rank Aggregation Prompting for Quantized Graph Neural Networks Training [link](https://arxiv.org/pdf/2601.15079)
- [arXiv260122] Rethinking Video Generation Model for the Embodied World [link](https://arxiv.org/pdf/2601.15282)
- [arXiv260122] TRSVR: An Adaptive Stochastic Trust-Region Method with Variance Reduction [link](https://arxiv.org/pdf/2601.14647)
