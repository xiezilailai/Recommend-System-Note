# 20260202-20260208

## 2026-02-02

**cs.DC total: 12**

- **[arXiv260202] Coordinating Power Grid Frequency Regulation Service with Data Center Load Flexibility**
  - **tags:** [mlsys], [cluster infrastructure], [frequency regulation, Exogenous Carbon, EcoCenter, GPU data centers, load flexibility]
  - **authors:** Ali Jahanshahi, Sara Rashidi Golrouye, Osten Anderson, Nanpeng Yu, Daniel Wong
  - **institution:** University of California, Riverside
  - **link:** https://arxiv.org/pdf/2601.22487
  - **Simple LLM Summary:** The paper introduces a framework called EcoCenter and a metric called Exogenous Carbon to enable GPU data centers to provide frequency regulation services to the power grid. It concludes that by coordinating with the grid, data centers can reduce the need for fossil-fueled reserves, and the resulting carbon savings often exceed the data centers' own operational emissions.

- **[arXiv260202] AsyncMesh: Fully Asynchronous Optimization for Data and Pipeline Parallelism**
  - **tags:** [mlsys], [llm training], [asynchronous optimization, sparse averaging, weight look-ahead, data parallelism, pipeline parallelism]
  - **authors:** Thalaiyasingam Ajanthan, Sameera Ramasinghe, Gil Avraham, Hadi Mohaghegh Dolatabadi, Chamin P Hewa Koneputugodage, Violetta Shevchenko, Yan Zuo, Alexander Long
  - **institution:** Pluralis Research
  - **link:** https://arxiv.org/pdf/2601.22442
  - **Simple LLM Summary:** This paper introduces AsyncMesh, a fully asynchronous optimization method for data and pipeline parallelism that eliminates synchronization barriers to reduce communication overhead. It mitigates staleness using weight look-ahead for pipeline parallelism and asynchronous sparse averaging with an exponential moving average correction for data parallelism. Experiments on large language models up to 1B parameters show it matches synchronous baseline performance while significantly reducing communication costs.

- **[arXiv260202] Towards Resiliency in Large Language Model Serving with KevlarFlow**
  - **tags:** [mlsys], [fault-tolerance], [decoupled model parallelism initialization, dynamic traffic rerouting, background KV cache replication, model parallelism, tensor parallelism, pipeline parallelism]
  - **authors:** Shangshu Qian, Kipling Liu, P. C. Sruthi, Lin Tan, Yongle Zhang
  - **institution:** Purdue University
  - **link:** https://arxiv.org/pdf/2601.22438
  - **Simple LLM Summary:** The paper introduces KevlarFlow, a fault-tolerant serving architecture for LLMs that uses decoupled model parallelism initialization, dynamic traffic rerouting, and background KV cache replication to handle hardware failures. It significantly reduces recovery time and improves latency and time-to-first-token metrics during failures compared to existing systems.

- **[arXiv260202] FedAdaVR: Adaptive Variance Reduction for Robust Federated Learning under Limited Client Participation**
  - **tags:** [mlsys], [others], [federated learning, variance reduction, adaptive optimizer, quantization, client drift, partial client participation]
  - **authors:** S M Ruhul Kabir Howlader, Xiao Chen, Yifei Xie, Lu Liu
  - **institution:** University of Leicester, University of Edinburgh, University of Exeter
  - **link:** https://arxiv.org/pdf/2601.22204
  - **Simple LLM Summary:** The paper proposes FedAdaVR, a federated learning algorithm that combines an adaptive optimizer with variance reduction to address errors from sporadic client participation by reusing stored client updates. It also introduces a quantized version, FedAdaVR-Quant, to reduce memory overhead. The method is proven to eliminate partial participation error and is shown to outperform state-of-the-art baselines in experiments.

- **[arXiv260202] Learning Provably Correct Distributed Protocols Without Human Knowledge**
  - **tags:** [mlsys], [fault-tolerance], [Monte Carlo Tree Search, transformer-based action encoder, depth-first search, model checking, Satisfiability Modulo Theories (SMT)]
  - **authors:** Yujie Hui, Xiaoyi Lu, Andrew Perrault, Yang Wang
  - **institution:** The Ohio State University, University of Florida
  - **link:** https://arxiv.org/pdf/2601.22369
  - **Simple LLM Summary:** The paper proposes GGMS, a learning framework that combines a specialized Monte Carlo Tree Search with a transformer-based action encoder, global depth-first search, and model checker feedback to automatically design provably correct distributed protocols. It proves the search is complete under mild assumptions and demonstrates that GGMS can learn correct protocols for larger settings than existing methods.

- **[arXiv260202] CONCUR: High-Throughput Agentic Batch Inference of LLM via Congestion-Based Concurrency Control**
  - **tags:** [mlsys], [llm inference], [KV cache management, admission control, congestion control, batch inference, agentic workloads]
  - **authors:** Qiaoling Chen, Zhisheng Ye, Tian Tang, Peng Sun, Boyu Tian, Guoteng Wang, Shenggui Li, Yonggang Wen, Zhenhua Han, Tianwei Zhang
  - **institution:** Nanyang Technological University, Shanghai Qiji Zhifeng Co., Ltd.
  - **link:** https://arxiv.org/pdf/2601.22705
  - **Simple LLM Summary:** The paper introduces CONCUR, a proactive agent-level admission control system that prevents KV cache thrashing in LLM batch inference by dynamically regulating the number of active agents based on runtime cache pressure. It improves throughput significantly, up to 4.09x on Qwen3-32B, and remains compatible with existing serving systems.

- **[arXiv260202] ZK-HybridFL: Zero-Knowledge Proof-Enhanced Hybrid Ledger for Federated Learning**
  - **tags:** [mlsys], [others], [zero-knowledge proofs, directed acyclic graph, sidechains, federated learning, smart contracts, blockchain]
  - **authors:** Amirhossein Taherpour, Xiaodong Wang
  - **institution:** Columbia University
  - **link:** https://arxiv.org/pdf/2601.22302
  - **Simple LLM Summary:** This paper proposes ZK-HybridFL, a decentralized federated learning framework that uses a DAG-based hybrid ledger with sidechains and zero-knowledge proofs to privately and securely validate model updates. The method integrates event-driven smart contracts and a challenge mechanism to detect adversarial behavior. The authors conclude that ZK-HybridFL offers a scalable and secure solution, demonstrating faster convergence, higher accuracy, and robustness against attacks in experiments.

- **[arXiv260202] HetCCL: Accelerating LLM Training with Heterogeneous GPUs**
  - **tags:** [mlsys], [cluster infrastructure], [collective communication library, RDMA, NCCL, RCCL, heterogeneous GPUs, All-Reduce]
  - **authors:** Heehoon Kim, Jaehwan Lee, Taejeoung Kim, Jongwon Park, Jinpyo Kim, Pyongwon Suh, Ryan H. Choi, Sangwoo Lee, Jaejin Lee
  - **institution:** Seoul National University, Samsung Research, Moreh Inc.
  - **link:** https://arxiv.org/pdf/2601.22585
  - **Simple LLM Summary:** The paper introduces HetCCL, a collective communication library that enables RDMA-based communication across heterogeneous GPUs from different vendors (e.g., NVIDIA and AMD) without requiring driver modifications. It unifies vendor-specific backends like NCCL and RCCL to facilitate cross-vendor communication. Evaluations show that HetCCL matches homogeneous performance and uniquely scales in heterogeneous environments, enabling high-performance LLM training without changes to existing applications.

- **[arXiv260202] SAIR: Cost-Efficient Multi-Stage ML Pipeline Autoscaling via In-Context Reinforcement Learning**
  - **tags:** [mlsys], [llm inference], [in-context reinforcement learning, Pareto-dominance reward shaping, surprisal-guided experience retrieval, GPU rate control, CUDA interception, regret analysis]
  - **authors:** Jianchang Su, Yifan Zhang, Shengkai Lin, Shizhen Zhao, Yusheng Zheng, Yiwei Yang, Wei Zhang
  - **institution:** University of Connecticut, Shanghai Jiao Tong University, University of California, Santa Cruz
  - **link:** https://arxiv.org/pdf/2601.22397
  - **Simple LLM Summary:** This paper presents SAIR, an autoscaling framework for multi-stage ML inference pipelines that uses an LLM as an in-context reinforcement learning controller to learn scaling policies online without gradient updates. It combines reward shaping, efficient experience retrieval, and fine-grained GPU control to dynamically manage resources. The method achieves significant improvements in latency and cost reduction compared to existing baselines.

- **[arXiv260202] SQUAD: Scalable Quorum Adaptive Decisions via ensemble of early exit neural networks**
  - **tags:** [mlsys], [llm inference], [early-exit neural networks, ensemble learning, quorum-based stopping, neural architecture search, distributed inference]
  - **authors:** Matteo Gambella, Fabrizio Pittorino, Giuliano Casale, Manuel Roveri
  - **institution:** Politecnico di Milano, Imperial College London
  - **link:** https://arxiv.org/pdf/2601.22711
  - **Simple LLM Summary:** This paper introduces SQUAD, an inference scheme that combines early-exit neural networks with distributed ensemble learning, using a quorum-based voting mechanism to decide when to stop computation. It also proposes QUEST, a neural architecture search method to optimize the diversity of the ensemble learners. The method improves test accuracy by up to 5.95% compared to dynamic baselines and reduces inference latency by up to 70.60% compared to static ensembles.

- **[arXiv260202] ERA: Epoch-Resolved Arbitration for Duelling Admins in Group Management CRDTs**
  - **tags:** [sys], [distributed systems], [CRDTs, Byzantine fault tolerance, epoch events, finality, arbitration]
  - **authors:** Kegan Dougal
  - **institution:** Element Creations Ltd
  - **link:** https://arxiv.org/pdf/2601.22963
  - **Simple LLM Summary:** The paper proposes ERA, a method using epoch events and external arbitration to resolve the "Duelling Admins" problem in group management CRDTs. It introduces a bounded total order within epochs to prevent Byzantine admins from exploiting concurrency, thereby improving consistency and providing finality.

- **[arXiv260202] AscendCraft: Automatic Ascend NPU Kernel Generation via DSL-Guided Transcompilation**
  - **tags:** [mlsys], [GPU kernels], [DSL-guided transcompilation, large language models, AscendC kernel generation, MultiKernelBench]
  - **authors:** Zhongzhen Wen, Shudi Shao, Zhong Li, Yu Ge, Tongtong Xu, Yuanyi Lin, Tian Zhang
  - **institution:** Nanjing University, Huawei
  - **link:** https://arxiv.org/pdf/2601.22760
  - **Simple LLM Summary:** AscendCraft introduces a lightweight domain-specific language (DSL) to abstract complexity and model Ascend NPU execution semantics, enabling LLMs to generate kernels via structured transcompilation. It achieves high compilation success and functional correctness, with many kernels matching or surpassing PyTorch eager performance, demonstrating effective NPU kernel generation.


**cs.AI/cs.LG contains "reinforcement learning" total: 39**
- [arXiv260202] RulePlanner: All-in-One Reinforcement Learner for Unifying Design Rules in 3D Floorplanning [link](https://arxiv.org/pdf/2601.22476)
- [arXiv260202] Adapting Reinforcement Learning for Path Planning in Constrained Parking Scenarios [link](https://arxiv.org/pdf/2601.22545)
- [arXiv260202] ShellForge: Adversarial Co-Evolution of Webshell Generation and Multi-View Detection for Robust Webshell Defense [link](https://arxiv.org/pdf/2601.22182)
- [arXiv260202] Real-Time Aligned Reward Model beyond Semantics [link](https://arxiv.org/pdf/2601.22664)
- [arXiv260202] Models Under SCOPE: Scalable and Controllable Routing via Pre-hoc Reasoning [link](https://arxiv.org/pdf/2601.22323)
- [arXiv260202] Unrewarded Exploration in Large Language Models Reveals Latent Learning from Psychology [link](https://arxiv.org/pdf/2601.22474)
- [arXiv260202] Learn More with Less: Uncertainty Consistency Guided Query Selection for RLVR [link](https://arxiv.org/pdf/2601.22595)
- [arXiv260202] Action-Sufficient Goal Representations [link](https://arxiv.org/pdf/2601.22496)
- [arXiv260202] Aligning Microscopic Vehicle and Macroscopic Traffic Statistics: Reconstructing Driving Behavior from Partial Data [link](https://arxiv.org/pdf/2601.22242)
- [arXiv260202] Exo-Plore: Exploring Exoskeleton Control Space through Human-aligned Simulation [link](https://arxiv.org/pdf/2601.22550)
- [arXiv260202] Continual Policy Distillation from Distributed Reinforcement Learning Teachers [link](https://arxiv.org/pdf/2601.22475)
- [arXiv260202] Latent Spherical Flow Policy for Reinforcement Learning with Combinatorial Actions [link](https://arxiv.org/pdf/2601.22211)
- [arXiv260202] Quantum-Inspired Reinforcement Learning for Secure and Sustainable AIoT-Driven Supply Chain Systems [link](https://arxiv.org/pdf/2601.22339)
- [arXiv260202] From Self-Evolving Synthetic Data to Verifiable-Reward RL: Post-Training Multi-turn Interactive Tool-Using Agents [link](https://arxiv.org/pdf/2601.22607)
- [arXiv260202] Detect and Act: Automated Dynamic Optimizer through Meta-Black-Box Optimization [link](https://arxiv.org/pdf/2601.22542)
- [arXiv260202] Learning Reward Functions for Cooperative Resilience in Multi-Agent Systems [link](https://arxiv.org/pdf/2601.22292)
- [arXiv260202] A Step Back: Prefix Importance Ratio Stabilizes Policy Optimization [link](https://arxiv.org/pdf/2601.22718)
- [arXiv260202] TSPO: Breaking the Double Homogenization Dilemma in Multi-turn Search Policy Optimization [link](https://arxiv.org/pdf/2601.22776)
- [arXiv260202] Clipping-Free Policy Optimization for Large Language Models [link](https://arxiv.org/pdf/2601.22801)
- [arXiv260202] CVeDRL: An Efficient Code Verifier via Difficulty-aware Reinforcement Learning [link](https://arxiv.org/pdf/2601.22803)
- [arXiv260202] Offline Reinforcement Learning of High-Quality Behaviors Under Robust Style Alignment [link](https://arxiv.org/pdf/2601.22823)
- [arXiv260202] Degradation-Aware Frequency Regulation of a Heterogeneous Battery Fleet via Reinforcement Learning [link](https://arxiv.org/pdf/2601.22865)
- [arXiv260202] Reinforcement Learning-Based Co-Design and Operation of Chiller and Thermal Energy Storage for Cost-Optimal HVAC Systems [link](https://arxiv.org/pdf/2601.22880)
- [arXiv260202] PlatoLTL: Learning to Generalize Across Symbols in LTL Instructions for Multi-Task RL [link](https://arxiv.org/pdf/2601.22891)
- [arXiv260202] MulFeRL: Enhancing Reinforcement Learning with Verbal Feedback in a Multi-turn Loop [link](https://arxiv.org/pdf/2601.22900)
- [arXiv260202] MTDrive: Multi-turn Interactive Reinforcement Learning for Autonomous Driving [link](https://arxiv.org/pdf/2601.22930)
- [arXiv260202] Golden Goose: A Simple Trick to Synthesize Unlimited RLVR Tasks from Unverifiable Internet Text [link](https://arxiv.org/pdf/2601.22975)
- [arXiv260202] Automatic Constraint Policy Optimization based on Continuous Constraint Interpolation Framework for Offline Reinforcement Learning [link](https://arxiv.org/pdf/2601.23010)
- [arXiv260202] Mem-T: Densifying Rewards for Long-Horizon Memory Agents [link](https://arxiv.org/pdf/2601.23014)
- [arXiv260202] Guided by Trajectories: Repairing and Rewarding Tool-Use Trajectories for Tool-Integrated Reasoning [link](https://arxiv.org/pdf/2601.23032)
- [arXiv260202] From Absolute to Relative: Rethinking Reward Shaping in Group-Based Reinforcement Learning [link](https://arxiv.org/pdf/2601.23058)
- [arXiv260202] RN-D: Discretized Categorical Actors with Regularized Networks for On-Policy Reinforcement Learning [link](https://arxiv.org/pdf/2601.23075)
- [arXiv260202] Why GRPO Needs Normalization: A Local-Curvature Perspective on Adaptive Gradients [link](https://arxiv.org/pdf/2601.23135)
- [arXiv260202] THINKSAFE: Self-Generated Safety Alignment for Reasoning Models [link](https://arxiv.org/pdf/2601.23143)
- [arXiv260202] On Safer Reinforcement Learning Policies for Sedation and Analgesia in Intensive Care [link](https://arxiv.org/pdf/2601.23154)
- [arXiv260202] Unsupervised Hierarchical Skill Discovery [link](https://arxiv.org/pdf/2601.23156)
- [arXiv260202] Med-Scout: Curing MLLMs' Geometric Blindness in Medical Perception via Geometry-Aware RL Post-Training [link](https://arxiv.org/pdf/2601.23220)
- [arXiv260202] Agile Reinforcement Learning through Separable Neural Architecture [link](https://arxiv.org/pdf/2601.23225)
- [arXiv260202] IRL-DAL: Safe and Adaptive Trajectory Planning for Autonomous Driving via Energy-Guided Diffusion Models [link](https://arxiv.org/pdf/2601.23266)

**cs.AI/cs.LG contains "accelerate" total: 10**
- [arXiv260202] Predicting Intermittent Job Failure Categories for Diagnosis Using Few-Shot Fine-Tuned Language Models [link](https://arxiv.org/pdf/2601.22264)
- [arXiv260202] Scalable Topology-Preserving Graph Coarsening with Graph Collapse [link](https://arxiv.org/pdf/2601.22943)
- [arXiv260202] Why GRPO Needs Normalization: A Local-Curvature Perspective on Adaptive Gradients [link](https://arxiv.org/pdf/2601.23135)
- [arXiv260202] Unsupervised Hierarchical Skill Discovery [link](https://arxiv.org/pdf/2601.23156)
- [arXiv260202] TriSpec: Ternary Speculative Decoding via Lightweight Proxy Verification [link](https://arxiv.org/pdf/2601.23180)
- [arXiv260202] YuriiFormer: A Suite of Nesterov-Accelerated Transformers [link](https://arxiv.org/pdf/2601.23236)
- [arXiv260202] Spectral Gradient Descent Mitigates Anisotropy-Driven Misalignment: A Case Study in Phase Retrieval [link](https://arxiv.org/pdf/2601.22652)
- [arXiv260202] A Cross-Domain Graph Learning Protocol for Single-Step Molecular Geometry Refinement [link](https://arxiv.org/pdf/2601.22723)
- [arXiv260202] Disentangling multispecific antibody function with graph neural networks [link](https://arxiv.org/pdf/2601.23212)
- [arXiv260202] Nested Slice Sampling: Vectorized Nested Sampling for GPU-Accelerated Inference [link](https://arxiv.org/pdf/2601.23252)
