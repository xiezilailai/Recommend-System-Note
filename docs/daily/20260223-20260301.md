# 20260223-20260301

## 2026-02-23

**cs.DC total: 13**

- **[arXiv260223] Distributed Triangle Enumeration in Hypergraphs**
  - **tags:** [sys], [distributed algorithms], [distributed triangle enumeration, hypergraph models, CONGEST model, sparse hypergraphs]
  - **authors:** Duncan Adamson, Will Rosenbaum, Paul G. Spirakis
  - **institution:** University of St Andrews, University of Liverpool
  - **link:** https://arxiv.org/pdf/2602.17834
  - **Simple LLM Summary:** This paper introduces new computational models for hypergraphs that generalize the CONGEST model and develops distributed algorithms for triangle enumeration within these models. It proves the optimality of these algorithms in two models and introduces efficient methods for sparse hypergraph classes. The work establishes a foundational framework for distributed sub-hypergraph enumeration.

- **[arXiv260223] It's Not Just Timestamps: A Study on Docker Reproducibility**
  - **tags:** [sys], [container security], [reproducible builds, Dockerfile, software supply chain, bitwise reproducibility, container images]
  - **authors:** Oreofe Solarin
  - **institution:** Case Western Reserve University
  - **link:** https://arxiv.org/pdf/2602.17678
  - **Simple LLM Summary:** The paper builds a Docker measurement pipeline and applies it to a sample of 2,000 GitHub repositories to study the reproducibility of container builds. It finds that very few Dockerfiles produce bitwise reproducible images, with major causes being developer-controlled factors like uncleaned caches and floating versions, not just timestamps.

- **[arXiv260223] Collaborative Processing for Multi-Tenant Inference on Memory-Constrained Edge TPUs**
  - **tags:** [mlsys], [llm inference], [collaborative processing, model partitioning, queueing model, memory swapping, Edge TPU, adaptive scheduling]
  - **authors:** Nathan Ng, Walid A. Hanafy, Prashanthi Kadambi, Balachandra Sunil, Ayush Gupta, David Irwin, Yogesh Simmhan, Prashant Shenoy
  - **institution:** University of Massachusetts Amherst, Indian Institute of Science
  - **link:** https://arxiv.org/pdf/2602.17808
  - **Simple LLM Summary:** The paper presents SwapLess, a system that uses an analytic queueing model to adaptively partition model inference between CPU and Edge TPU and allocate CPU cores, minimizing swapping overhead and latency. It demonstrates significant latency reductions for both single-tenant and multi-tenant workloads compared to the default Edge TPU compiler.

- **[arXiv260223] Message-Oriented Middleware Systems: Technology Overview**
  - **tags:** [sys], [distributed systems], [message-oriented middleware, publish/subscribe, brokers, flow control, multi-tenancy]
  - **authors:** Wael Al-Manasrah, Zuhair AlSader, Tim Brecht, Ahmed Alquraan, Samer Al-Kiswany
  - **institution:** University of Waterloo
  - **link:** https://arxiv.org/pdf/2602.17774
  - **Simple LLM Summary:** This paper conducts a comprehensive characterization study of ten open-source message-oriented middleware (MOM) systems by examining 42 features across 134 options. It concludes that MOM systems have evolved into flexible frameworks for cloud applications and identifies an opportunity for the community to consolidate efforts on fewer projects. The authors also provide a publicly available annotated dataset to verify findings and aid in system comparison.

- **[arXiv260223] Joint Training on AMD and NVIDIA GPUs**
  - **tags:** [mlsys], [llm training], [heterogeneous training, CPU-Forwarding Communication, Device-Direct Communication, GPU Direct RDMA, pipeline parallelism, cross-vendor GPU communication]
  - **authors:** Jon Hu, Thomas Jia, Jing Zhu, Zhendong Yu
  - **institution:** Zettabyte AI, Inc.
  - **link:** https://arxiv.org/pdf/2602.18007
  - **Simple LLM Summary:** This paper presents two approaches for joint training of large language models on heterogeneous clusters containing both AMD and NVIDIA GPUs. The proposed Device-Direct Communication method, which enables direct data transfer between different vendor GPUs, achieves up to 98% of the throughput of a homogeneous NVIDIA system while maintaining training stability and correctness.

- **[arXiv260223] Faster Parallel Batch-Dynamic Algorithms for Low Out-Degree Orientation**
  - **tags:** [sys], [graph algorithms], [parallel batch-dynamic algorithms, low out-degree orientation, arboricity, polylogarithmic depth]
  - **authors:** Guy Blelloch, Andrew Brady, Laxman Dhulipala, Jeremy Fineman, Kishen Gowda, Chase Hutton
  - **institution:** Carnegie Mellon University, University of Maryland, Georgetown University
  - **link:** https://arxiv.org/pdf/2602.17811
  - **Simple LLM Summary:** This paper presents new parallel batch-dynamic algorithms for maintaining a low out-degree orientation of an undirected graph. The algorithms achieve polylogarithmic depth and improve upon prior work by reducing the work per edge update, offering results with asymptotically optimal expected work, worst-case work matching the best sequential algorithm, and a significant improvement for maintaining a near-optimal orientation.

- **[arXiv260223] Closing Africa's Early Warning Gap: AI Weather Forecasting for Disaster Prevention**
  - **tags:** [mlsys], [cluster infrastructure], [NVIDIA Earth-2, PostgreSQL, ProcessPoolExecutor, aiobotocore, async Python, database-backed serving, coordinate management, WhatsApp distribution]
  - **authors:** Qness Ndlovu
  - **institution:** Dimension Research Lab
  - **link:** https://arxiv.org/pdf/2602.17726
  - **Simple LLM Summary:** This paper presents a low-cost, production-grade architecture using NVIDIA Earth-2 AI weather models and PostgreSQL caching to provide national-scale weather forecasts and early warnings in Africa. The system reduces deployment costs by over 2,000 times compared to traditional radar and delivers forecasts via WhatsApp. The main conclusion is that this architecture makes continent-scale early warning systems economically viable, which can significantly reduce disaster-related deaths.

- **[arXiv260223] GPU Memory and Utilization Estimation for Training-Aware Resource Management: Opportunities and Limitations**
  - **tags:** [mlsys], [cluster infrastructure], [GPU memory estimation, GPU utilization estimation, analytical models, CPU-side libraries, ML-based estimators, Horus, PyTorch FakeTensor]
  - **authors:** Ehsan Yousefzadeh-Asl-Miandoab, Reza Karimzadeh, Danyal Yorulmaz, Bulat Ibragimov, Pınar Tözün
  - **institution:** IT University of Copenhagen, University of Copenhagen
  - **link:** https://arxiv.org/pdf/2602.17817
  - **Simple LLM Summary:** This paper systematically analyzes three paradigms for estimating GPU memory and utilization—analytical models, CPU-side libraries, and ML-based estimators—to improve resource management for collocated deep learning training. It finds key trade-offs: analytical models are hardware-dependent, CPU-side libraries are intrusive, and ML-based estimators struggle with generalization. The authors conclude that significant challenges remain in achieving accurate, generalizable, and low-overhead estimation for robust task collocation.

- **[arXiv260223] Mind the Boundary: Stabilizing Gemini Enterprise A2A via a Cloud Run Hub Across Projects and Accounts**
  - **tags:** [mlsys], [llm inference], [agent-to-agent (A2A) protocol, JSON-RPC, Cloud Run, retrieval-augmented generation (RAG), Vertex AI, authentication, orchestration]
  - **authors:** Takao Morita
  - **institution:** Independent Researcher
  - **link:** https://arxiv.org/pdf/2602.17675
  - **Simple LLM Summary:** This paper implements an A2A Hub orchestrator on Google Cloud Run to route queries across different projects and accounts for Gemini Enterprise, addressing UI compatibility and authentication challenges. The core method involves enforcing a text-only JSON-RPC mode and separating structured data into a REST API to ensure stable responses. The main conclusion is that practical multi-agent interoperability requires managing not just protocol compliance but also UI constraints and cross-boundary authentication.

- **[arXiv260223] Distributed Security: From Isolated Properties to Synergistic Trust**
  - **tags:** [sys], [distributed systems security], [Byzantine fault tolerance, consensus protocols, distributed agreement, data consistency, secure multi-party computation, privacy, verifiability, accountability]
  - **authors:** Minghui Xu
  - **institution:** Shandong University, Quan Cheng Laboratory
  - **link:** https://arxiv.org/pdf/2602.18063
  - **Simple LLM Summary:** This vision paper argues for a paradigm shift in distributed security research, moving from the isolated study of foundational properties like agreement, consistency, privacy, verifiability, and accountability towards understanding their synergistic combinations. It traces the evolution of these properties and posits that the research frontier lies at their intersections, where fusion creates new capabilities. The paper concludes that the future of distributed security is in harnessing these synergies to build a unified fabric of trust, while identifying challenges like property convergence frameworks and post-quantum threats.

- **[arXiv260223] Green by Design: Constraint-Based Adaptive Deployment in the Cloud Continuum**
  - **tags:** [sys], [cloud computing], [green constraints, adaptive orchestration, deployment plans, energy-aware scheduling, cloud-edge continuum]
  - **authors:** Andrea D'Iapico, Monica Vitali
  - **institution:** Politecnico di Milano
  - **link:** https://arxiv.org/pdf/2602.18287
  - **Simple LLM Summary:** The paper proposes a methodology for automatically generating deployment plans for cloud-native applications based on dynamically learned green constraints, which consider energy consumption and infrastructure carbon intensity. This enables adaptive, energy-aware orchestration across the cloud-edge continuum. The approach is validated to effectively reduce energy usage and associated emissions in realistic deployment scenarios.

- **[arXiv260223] A reliability- and latency-driven task allocation framework for workflow applications in the edge-hub-cloud continuum**
  - **tags:** [sys], [edge computing], [binary integer linear programming, multi-objective optimization, time redundancy, task allocation]
  - **authors:** Andreas Kouloumpris, Georgios L. Stavrinides, Maria K. Michael, Theocharis Theocharides
  - **institution:** University of Cyprus, KIOS Research and Innovation Center of Excellence
  - **link:** https://arxiv.org/pdf/2602.18158
  - **Simple LLM Summary:** The paper proposes an exact multi-objective task allocation framework using binary integer linear programming to jointly optimize reliability and latency for workflow applications in an edge-hub-cloud architecture. The method incorporates time redundancy and key constraints, showing significant improvements over baselines in experiments with real-world and synthetic workflows.

- **[arXiv260223] It does not matter how you define locally checkable labelings**
  - **tags:** [sys], [distributed graph algorithms], [locally checkable labeling, LOCAL model, round elimination, symmetry-breaking oracle, O(log* n) rounds]
  - **authors:** Antonio Cruciani, Avinandan Das, Alesya Raevskaya, Jukka Suomela
  - **institution:** Aalto University
  - **link:** https://arxiv.org/pdf/2602.18188
  - **Simple LLM Summary:** The paper shows that the family of Locally Checkable Labeling (LCL) problems is highly robust by proving that even a very restricted version (node-edge checkable on regular unlabeled graphs) can be translated to and from the standard LCL definition with minimal overhead. This translation uses local reductions requiring only a symmetry-breaking oracle, incurring at most an additive O(log* n) rounds in the LOCAL model. The main conclusion is that counterintuitive properties of LCLs are inherent and not artifacts of the specific definition, as they persist even in this restricted formalism.


**cs.AI/cs.LG contains "reinforcement learning" total: 17**
- [arXiv260223] Learning Optimal and Sample-Efficient Decision Policies with Guarantees [link](https://arxiv.org/pdf/2602.17978)
- [arXiv260223] CodeScaler: Scaling Code LLM Training and Test-Time Inference via Execution-Free Reward Models [link](https://arxiv.org/pdf/2602.17684)
- [arXiv260223] MePoly: Max Entropy Polynomial Policy Optimization [link](https://arxiv.org/pdf/2602.17832)
- [arXiv260223] Epistemic Traps: Rational Misalignment Driven by Model Misspecification [link](https://arxiv.org/pdf/2602.17676)
- [arXiv260223] Cross-Embodiment Offline Reinforcement Learning for Heterogeneous Robot Datasets [link](https://arxiv.org/pdf/2602.18025)
- [arXiv260223] Gradient Regularization Prevents Reward Hacking in Reinforcement Learning from Human Feedback and Verifiable Rewards [link](https://arxiv.org/pdf/2602.18037)
- [arXiv260223] Whole-Brain Connectomic Graph Model Enables Whole-Body Locomotion Control in Fruit Fly [link](https://arxiv.org/pdf/2602.17997)
- [arXiv260223] MIRA: Memory-Integrated Reinforcement Learning Agent with Limited LLM Guidance [link](https://arxiv.org/pdf/2602.17930)
- [arXiv260223] Mean-Field Reinforcement Learning without Synchrony [link](https://arxiv.org/pdf/2602.18026)
- [arXiv260223] Flow Actor-Critic for Offline Reinforcement Learning [link](https://arxiv.org/pdf/2602.18015)
- [arXiv260223] Memory-Based Advantage Shaping for LLM-Guided Reinforcement Learning [link](https://arxiv.org/pdf/2602.17931)
- [arXiv260223] Optimal Multi-Debris Mission Planning in LEO: A Deep Reinforcement Learning Approach with Co-Elliptic Transfers and Refueling [link](https://arxiv.org/pdf/2602.17685)
- [arXiv260223] Interacting safely with cyclists using Hamilton-Jacobi reachability and reinforcement learning [link](https://arxiv.org/pdf/2602.18097)
- [arXiv260223] TempoNet: Slack-Quantized Transformer-Guided Reinforcement Scheduler for Adaptive Deadline-Centric Real-Time Dispatchs [link](https://arxiv.org/pdf/2602.18109)
- [arXiv260223] Flow Matching with Injected Noise for Offline-to-Online Reinforcement Learning [link](https://arxiv.org/pdf/2602.18117)
- [arXiv260223] PRISM: Parallel Reward Integration with Symmetry for MORL [link](https://arxiv.org/pdf/2602.18277)
- [arXiv260223] Diffusing to Coordinate: Efficient Online Multi-Agent Diffusion Policies [link](https://arxiv.org/pdf/2602.18291)

**cs.AI/cs.LG contains "accelerate" total: 9**
- [arXiv260223] A Case Study of Selected PTQ Baselines for Reasoning LLMs on Ascend NPU [link](https://arxiv.org/pdf/2602.17693)
- [arXiv260223] Solving and learning advective multiscale Darcian dynamics with the Neural Basis Method [link](https://arxiv.org/pdf/2602.17776)
- [arXiv260223] Multi-material Multi-physics Topology Optimization with Physics-informed Gaussian Process Priors [link](https://arxiv.org/pdf/2602.17783)
- [arXiv260223] Hardware-Friendly Input Expansion for Accelerating Function Approximation [link](https://arxiv.org/pdf/2602.17952)
- [arXiv260223] Balancing Symmetry and Efficiency in Graph Flow Matching [link](https://arxiv.org/pdf/2602.18084)
- [arXiv260223] A Probabilistic Framework for LLM-Based Model Discovery [link](https://arxiv.org/pdf/2602.18266)
- [arXiv260223] PRISM: Parallel Reward Integration with Symmetry for MORL [link](https://arxiv.org/pdf/2602.18277)
- [arXiv260223] Clever Materials: When Models Identify Good Materials for the Wrong Reasons [link](https://arxiv.org/pdf/2602.17730)
- [arXiv260223] AgriVariant: Variant Effect Prediction using DeepChem-Variant for Precision Breeding in Rice [link](https://arxiv.org/pdf/2602.17747)

## 2026-02-24

**cs.DC total: 19**

- **[arXiv260224] When Coordination Is Avoidable: A Monotonicity Analysis of Organizational Tasks**
  - **tags:** [ai], [multi-agent systems], [monotonicity, coordination tax, interdependence taxonomy, Thompson's taxonomy, workflow classification]
  - **authors:** Harang Ju
  - **institution:** Johns Hopkins University
  - **link:** https://arxiv.org/pdf/2602.18673
  - **Simple LLM Summary:** The paper applies a monotonicity criterion from distributed systems theory to organizational tasks, showing coordination is necessary only for non-monotonic tasks. By classifying enterprise workflows and occupational tasks, it finds a significant portion are monotonic, concluding that 24-57% of coordination spending may be unnecessary for correctness.

- **[arXiv260224] Deep Reinforcement Learning for Optimizing Energy Consumption in Smart Grid Systems**
  - **tags:** [mlsys], [others], [Reinforcement Learning, Physics-Informed Neural Networks, surrogate models, Optimal Power Flow]
  - **authors:** Abeer Alsheikhi, Amirfarhad Farhadi, Azadeh Zamanifar
  - **institution:** Iran University of Science and Technology, Islamic Azad University
  - **link:** https://arxiv.org/pdf/2602.18531
  - **Simple LLM Summary:** This paper proposes using Physics-Informed Neural Networks (PINNs) as a surrogate model to accelerate deep reinforcement learning for smart grid energy optimization. By incorporating physical laws, the PINN surrogate enables efficient policy training without costly simulator interactions. The method achieves 50% faster training while maintaining performance comparable to using the original simulator.

- **[arXiv260224] ucTrace: A Multi-Layer Profiling Tool for UCX-driven Communication**
  - **tags:** [sys], [HPC communication profiling], [UCX, MPI, profiling, visualization, GPU-aware communication, transport layer]
  - **authors:** Emir Gencer, Mohammad Kefah Taha Issa, Ilyas Turimbetov, James D. Trotter, Didem Unat
  - **institution:** Koc University, Simula Research Laboratory
  - **link:** https://arxiv.org/pdf/2602.19084
  - **Simple LLM Summary:** The paper introduces ucTrace, a novel profiling tool that captures and visualizes fine-grained communication at the UCX transport layer in HPC systems. It links low-level operations between hosts and devices to high-level MPI functions, providing insights for performance optimization and debugging. The tool is demonstrated to be effective across various experiments, including MPI benchmarks and large-scale GPU-accelerated applications like GROMACS.

- **[arXiv260224] A Formal Framework for Predicting Distributed System Performance under Faults**
  - **tags:** [sys], [distributed systems, fault tolerance], [Maude, formal framework, fault injector, performance prediction, throughput, latency]
  - **authors:** Ziwei Zhou, Si Liu, Zhou Zhou, Peixin Wang, MIn Zhang
  - **institution:** East China Normal University, Texas A&M University
  - **link:** https://arxiv.org/pdf/2602.19088
  - **Simple LLM Summary:** This paper presents a formal framework for predicting the performance (e.g., throughput, latency) of distributed systems under various fault conditions. The framework, implemented as an automated tool called PerF in Maude, integrates a reusable fault injector library with system models for statistical analysis. The authors demonstrate that PerF accurately predicts performance degradation across different fault scenarios, with results consistent with real-world deployments.

- **[arXiv260224] The Category Mistake of Cislunar Time: Why NASA Cannot Synchronize What Doesn't Exist**
  - **tags:** [sys], [distributed systems, time synchronization], [Coordinated Lunar Time, category mistake, ontic vs epistemic, atomic clocks, relativistic corrections, LunaNet, Forward-In-Time-Only, Leibnizian operationalism, fine-tuning argument]
  - **authors:** Paul Borrill
  - **institution:** DÆDÆLUS
  - **link:** https://arxiv.org/pdf/2602.18641
  - **Simple LLM Summary:** The paper critiques NASA's plan to establish Coordinated Lunar Time by arguing it commits a philosophical category mistake, treating synchronized time as an independent ontic entity rather than an epistemic, model-dependent construct. It applies concepts from quantum foundations, such as Spekkens' operationalism and the ontic/epistemic distinction, to show the program's conceptual incoherence and proposes a transactional alternative based on bilateral atomic interactions.

- **[arXiv260224] Asymptotic Subspace Consensus in Dynamic Networks**
  - **tags:** [sys], [distributed computing], [asymptotic subspace consensus, convex hull, oblivious message adversaries, dynamic networks]
  - **authors:** Matthias Függer, Thomas Nowak
  - **institution:** Université Paris-Saclay, CNRS, ENS Paris-Saclay, LMF, Institut Universitaire de France
  - **link:** https://arxiv.org/pdf/2602.19121
  - **Simple LLM Summary:** This paper introduces the problem of asymptotic subspace consensus, a relaxation of traditional asymptotic consensus where processes' outputs converge to a common subspace rather than a single point. It provides a complete characterization of solvability under oblivious message adversaries and shows that many existing consensus algorithms degrade gracefully to this weaker problem in dynamic networks. The work also analyzes the rate at which the dimension of agreement is reduced.

- **[arXiv260224] What Distributed Computing Got Wrong: The Category Mistake That Turned Design Choices into Laws of Nature**
  - **tags:** [sys], [distributed computing], [FITO, category mistake, impossibility theorems, bilateral transactions, ontic/epistemic distinction]
  - **authors:** Paul Borrill
  - **institution:** DÆDÆLUS
  - **link:** https://arxiv.org/pdf/2602.18723
  - **Simple LLM Summary:** The paper argues that foundational impossibility results in distributed computing (like FLP and CAP) are not physical laws but consequences of the design choice of Forward-In-Time-Only (FITO) information flow. By applying a category mistake framework and Spekkens' Leibnizian principle, it shows these limits are specific to FITO systems and proposes bilateral transactional interactions as an alternative. The conclusion is that distributed computing has been optimizing within an unnecessarily constrained design space.

- **[arXiv260224] WANSpec: Leveraging Global Compute Capacity for LLM Inference**
  - **tags:** [mlsys], [llm inference], [speculative decoding, wide area network offloading, cloud deployment, latency reduction, draft model offloading]
  - **authors:** Noah Martin, Fahad Dogar
  - **institution:** Tufts University
  - **link:** https://arxiv.org/pdf/2602.18931
  - **Simple LLM Summary:** The paper introduces WANSpec, a method that leverages under-utilized global compute resources for LLM inference by offloading the draft model of speculative decoding to remote data centers over a wide area network. This approach reduces the forward passes of the draft model in high-demand data centers by over 50% while maintaining low latency through judicious redundancy. The core conclusion is that WANSpec can effectively mitigate GPU capacity constraints and augment cloud providers by utilizing distributed, heterogeneous compute resources.

- **[arXiv260224] BiScale: Energy-Efficient Disaggregated LLM Serving via Phase-Aware Placement and DVFS**
  - **tags:** [mlsys], [llm inference], [disaggregated serving, dynamic voltage and frequency scaling (DVFS), model predictive control (MPC), phase-aware placement, slack-aware adaptation]
  - **authors:** Omar Basit, Yunzhao Liu, Z. Jonny Kong, Y. Charlie Hu
  - **institution:** Purdue University
  - **link:** https://arxiv.org/pdf/2602.18755
  - **Simple LLM Summary:** The paper presents BiScale, a two-tier energy optimization framework for disaggregated LLM serving that jointly optimizes GPU placement and frequency scaling. It uses coarse-grained phase-aware placement and fine-grained, stage-specific DVFS control (MPC for prefill, slack-aware for decode) to reduce energy. Evaluation shows it meets latency SLOs while reducing energy by up to 39% in prefill and 48% in decode compared to prior systems.

- **[arXiv260224] Carbon-aware decentralized dynamic task offloading in MIMO-MEC networks via multi-agent reinforcement learning**
  - **tags:** [mlsys], [others], [multi-agent proximal policy optimization (PPO), decentralized partially observable markov decision process (DEC-POMDP), decentralized execution with parameter sharing (DEPS), carbon-aware reward, power control, task offloading]
  - **authors:** Mubshra Zulfiqar, Muhammad Ayzed Mirza, Basit Qureshi
  - **institution:** Wuhan University of Technology, Qilu Institute of Technology, Prince Sultan University
  - **link:** https://arxiv.org/pdf/2602.18797
  - **Simple LLM Summary:** This paper proposes CADDTO-PPO, a carbon-aware decentralized task offloading framework for MIMO-MEC networks using multi-agent proximal policy optimization. It models the system as a DEC-POMDP and employs decentralized execution with parameter sharing to enable IoT agents to make local decisions. The method outperforms baselines by achieving lower carbon intensity and near-zero packet overflow, with constant inference complexity suitable for sustainable IoT.

- **[arXiv260224] Semantic Conflict Model for Collaborative Data Structures**
  - **tags:** [sys], [distributed systems], [conflict-free replicated data types (CRDTs), semantic dependencies, three-way merge, replicated journal, optimistic concurrency control, eventual consistency]
  - **authors:** Georgii Semenov, Vitaly Aksenov
  - **institution:** ITMO University
  - **link:** https://arxiv.org/pdf/2602.19231
  - **Simple LLM Summary:** This paper introduces a conflict model for collaborative data structures that uses semantic dependencies between operations to identify conflicts and resolves them by rebasing operations via a three-way merge over a replicated journal. The approach enables explicit, local-first conflict resolution without central coordination, as demonstrated on collaborative registers.

- **[arXiv260224] Why iCloud Fails: The Category Mistake of Cloud Synchronization**
  - **tags:** [sys], [distributed systems, cloud storage], [cloud synchronization, POSIX semantics, network partitioning, causal graph, Open Atomic Ethernet, transactional semantics]
  - **authors:** Paul Borrill
  - **institution:** DAEDAELUS
  - **link:** https://arxiv.org/pdf/2602.19433
  - **Simple LLM Summary:** The paper analyzes iCloud Drive's failures as a fundamental category mistake, arguing its synchronization semantics violate POSIX filesystem expectations by projecting a distributed causal graph onto a linear timeline. It concludes that Open Atomic Ethernet's bilateral, reversible transactional semantics provide a structural solution by aligning protocol behavior with physical reality.

- **[arXiv260224] GPU-Resident Gaussian Process Regression Leveraging Asynchronous Tasks with HPX**
  - **tags:** [mlsys], [GPU kernels], [Gaussian Process Regression, Cholesky Decomposition, Asynchronous Many-task Runtimes, Tiled Algorithms, HPX, CUDA]
  - **authors:** Henrik Möllmann, Dirk Pflüger, Alexander Strack
  - **institution:** Institute of Parallel and Distributed Systems, University of Stuttgart
  - **link:** https://arxiv.org/pdf/2602.19683
  - **Simple LLM Summary:** This paper extends the GPRat library by implementing a fully GPU-resident Gaussian process prediction pipeline using tiled algorithms and optimized CUDA libraries, managed asynchronously by the HPX runtime. The results show that the GPU implementation provides significant speedups for larger datasets, with performance matching or surpassing cuSOLVER when HPX is combined with multiple CUDA streams.

- **[arXiv260224] Health+: Empowering Individuals via Unifying Health Data**
  - **tags:** [mlsys], [multi-modal inference], [multimodal data management, data fusion, user-centric privacy, cloud storage, information retrieval]
  - **authors:** Sujaya Maiyya, Shantanu Sharma, Avinash Kumar
  - **institution:** University of Waterloo, New Jersey Institute of Technology
  - **link:** https://arxiv.org/pdf/2602.19319
  - **Simple LLM Summary:** This vision paper proposes Health+, a user-centric system designed to unify and manage an individual's fragmented multimodal health data (e.g., images, reports, EHRs) through ingestion, storage, fusion, and querying. It emphasizes intuitive interfaces and privacy-aware sharing to empower patients. The main conclusion is that Health+ lays the foundation for a more connected, interpretable, and user-controlled health information ecosystem by prioritizing individual agency over institutional overhaul.

- **[arXiv260224] Complex Event Processing in the Edge: A Combined Optimization Approach for Data and Code Placement**
  - **tags:** [sys], [IoT and Edge Computing], [complex event processing, constrained programming optimization, critical path performance, virtual shared memory, task graph]
  - **authors:** Halit Uyanık, Tolga Ovatman
  - **institution:** Istanbul Technical University
  - **link:** https://arxiv.org/pdf/2602.19338
  - **Simple LLM Summary:** This paper proposes a constrained programming optimization approach to balance execution costs and improve the critical path performance in Complex Event Processing (CEP) task graphs for IoT edge devices. The method is implemented as a Python library that optimizes code and data placement, abstracting communication and virtualizing shared memory. The results demonstrate that this optimization increases throughput and reduces delay during CEP operations across multiple devices.

- **[arXiv260224] Linear Reservoir: A Diagonalization-Based Optimization**
  - **tags:** [mlsys], [others], [diagonalization, eigenvalue decomposition, eigenbasis transformation, linear echo state networks, computational complexity reduction]
  - **authors:** Romain de Coudenhove, Yannis Bendi-Ouis, Anthony Strock, Xavier Hinaut
  - **institution:** ENS PSL, Inria, LaBRI, IMN, Stanford University
  - **link:** https://arxiv.org/pdf/2602.19802
  - **Simple LLM Summary:** The paper introduces a diagonalization-based optimization for Linear Echo State Networks that reformulates reservoir dynamics in the eigenbasis of the recurrent matrix, reducing the per-step computational complexity from O(N²) to O(N). The proposed methods preserve predictive accuracy while offering significant computational speedups, suggesting a paradigm shift towards direct eigenvalue selection for linear ESNs.

- **[arXiv260224] Mitigating Artifacts in Pre-quantization Based Scientific Data Compressors with Quantization-aware Interpolation**
  - **tags:** [sys], [scientific data compression], [pre-quantization, error-bounded lossy compression, quantization-aware interpolation, artifact mitigation, parallel computing]
  - **authors:** Pu Jiao, Sheng Di, Jiannan Tian, Mingze Xia, Xuan Wu, Yang Zhang, Xin Liang, Franck Cappello
  - **institution:** University of Kentucky, Argonne National Laboratory, Oakland University, Oregon State University, Miami University
  - **link:** https://arxiv.org/pdf/2602.20097
  - **Simple LLM Summary:** This paper proposes a novel quantization-aware interpolation algorithm to mitigate artifacts in pre-quantization based scientific data compressors. The method improves decompressed data quality while maintaining high compression throughput, as validated using real-world datasets.

- **[arXiv260224] A Risk-Aware UAV-Edge Service Framework for Wildfire Monitoring and Emergency Response**
  - **tags:** [mlsys], [others], [fire-history-weighted clustering, QoS-aware edge assignment, 2-opt route optimization, adaptive fleet sizing, dynamic emergency rerouting]
  - **authors:** Yulun Huang, Zhiyu Wang, Rajkumar Buyya
  - **institution:** The University of Melbourne
  - **link:** https://arxiv.org/pdf/2602.19742
  - **Simple LLM Summary:** The paper proposes an integrated UAV-edge service framework that co-optimizes route planning, fleet sizing, and edge provisioning for wildfire monitoring. It uses risk-aware clustering, QoS-aware edge assignment, and 2-opt route optimization with a dynamic rerouting mechanism for emergencies. Experiments show the framework significantly reduces response time, energy consumption, and fleet size compared to baseline methods.

- **[arXiv260224] A Context-Aware Knowledge Graph Platform for Stream Processing in Industrial IoT**
  - **tags:** [sys], [Industrial IoT], [Knowledge Graph, Apache Kafka, Apache Flink, SPARQL, SWRL, Context-aware reasoning]
  - **authors:** Monica Marconi Sciarroni, Emanuele Storti
  - **institution:** Polytechnic University of Marche
  - **link:** https://arxiv.org/pdf/2602.19990
  - **Simple LLM Summary:** This paper proposes a semantic platform for managing Industrial IoT data streams by unifying heterogeneous sources into a Knowledge Graph and using Apache Kafka/Flink for real-time processing. It combines semantic models with context-aware reasoning (SPARQL/SWRL) for dynamic stream discovery and access control. The experimental evaluation concludes that this approach enables flexible and interoperable data workflows for Industry 5.0 environments.


**cs.AI/cs.LG contains "reinforcement learning" total: 42**
- [arXiv260224] Issues with Measuring Task Complexity via Random Policies in Robotic Tasks [link](https://arxiv.org/pdf/2602.18856)
- [arXiv260224] In-Context Planning with Latent Temporal Abstractions [link](https://arxiv.org/pdf/2602.18694)
- [arXiv260224] MagicAgent: Towards Generalized Agent Planning [link](https://arxiv.org/pdf/2602.19000)
- [arXiv260224] FineRef: Fine-Grained Error Reflection and Correction for Long-Form Generation with Citations [link](https://arxiv.org/pdf/2602.18437)
- [arXiv260224] VariBASed: Variational Bayes-Adaptive Sequential Monte-Carlo Planning for Deep Reinforcement Learning [link](https://arxiv.org/pdf/2602.18857)
- [arXiv260224] Toward AI Autonomous Navigation for Mechanical Thrombectomy using Hierarchical Modular Multi-agent Reinforcement Learning (HM-MARL) [link](https://arxiv.org/pdf/2602.18663)
- [arXiv260224] Learning to Detect Language Model Training Data via Active Reconstruction [link](https://arxiv.org/pdf/2602.19020)
- [arXiv260224] TPRU: Advancing Temporal and Procedural Understanding in Large Multimodal Models [link](https://arxiv.org/pdf/2602.18884)
- [arXiv260224] Learning to Remember: End-to-End Training of Memory Agents for Long-Context Reasoning [link](https://arxiv.org/pdf/2602.18493)
- [arXiv260224] TAG: Thinking with Action Unit Grounding for Facial Expression Recognition [link](https://arxiv.org/pdf/2602.18763)
- [arXiv260224] Task-Aware Exploration via a Predictive Bisimulation Metric [link](https://arxiv.org/pdf/2602.18724)
- [arXiv260224] HONEST-CAV: Hierarchical Optimization of Network Signals and Trajectories for Connected and Automated Vehicles with Multi-Agent Reinforcement Learning [link](https://arxiv.org/pdf/2602.18740)
- [arXiv260224] DeepInterestGR: Mining Deep Multi-Interest Using Multi-Modal LLMs for Generative Recommendation [link](https://arxiv.org/pdf/2602.18907)
- [arXiv260224] Adaptive Time Series Reasoning via Segment Selection [link](https://arxiv.org/pdf/2602.18645)
- [arXiv260224] 1D-Bench: A Benchmark for Iterative UI Code Generation with Visual Feedback in Real-World [link](https://arxiv.org/pdf/2602.18548)
- [arXiv260224] Hierarchical Reward Design from Language: Enhancing Alignment of Agent Behavior with Human Specifications [link](https://arxiv.org/pdf/2602.18582)
- [arXiv260224] Adaptive Problem Generation via Symbolic Representations [link](https://arxiv.org/pdf/2602.19187)
- [arXiv260224] How to Allocate, How to Learn? Dynamic Rollout Allocation and Advantage Modulation for Policy Optimization [link](https://arxiv.org/pdf/2602.19208)
- [arXiv260224] Characterizing MARL for Energy Control: A Multi-KPI Benchmark on the CityLearn Environment [link](https://arxiv.org/pdf/2602.19223)
- [arXiv260224] Robust Exploration in Directed Controller Synthesis via Reinforcement Learning with Soft Mixture-of-Experts [link](https://arxiv.org/pdf/2602.19244)
- [arXiv260224] DGPO: RL-Steered Graph Diffusion for Neural Architecture Generation [link](https://arxiv.org/pdf/2602.19261)
- [arXiv260224] ALPACA: A Reinforcement Learning Environment for Medication Repurposing and Treatment Optimization in Alzheimer's Disease [link](https://arxiv.org/pdf/2602.19298)
- [arXiv260224] TOPReward: Token Probabilities as Hidden Zero-Shot Rewards for Robotics [link](https://arxiv.org/pdf/2602.19313)
- [arXiv260224] Learning to Reason for Multi-Step Retrieval of Personal Context in Personalized Question Answering [link](https://arxiv.org/pdf/2602.19317)
- [arXiv260224] Soft Sequence Policy Optimization: Bridging GMPO and SAPO [link](https://arxiv.org/pdf/2602.19327)
- [arXiv260224] LLMs Can Learn to Reason Via Off-Policy RL [link](https://arxiv.org/pdf/2602.19362)
- [arXiv260224] Stable Deep Reinforcement Learning via Isotropic Gaussian Representations [link](https://arxiv.org/pdf/2602.19373)
- [arXiv260224] IR$^3$: Contrastive Inverse Reinforcement Learning for Interpretable Detection and Mitigation of Reward Hacking [link](https://arxiv.org/pdf/2602.19416)
- [arXiv260224] RAmmStein: Regime Adaptation in Mean-reverting Markets with Stein Thresholds -- Optimal Impulse Control in Concentrated AMMs [link](https://arxiv.org/pdf/2602.19419)
- [arXiv260224] SenTSR-Bench: Thinking with Injected Knowledge for Time-Series Reasoning [link](https://arxiv.org/pdf/2602.19455)
- [arXiv260224] Cost-Aware Diffusion Active Search [link](https://arxiv.org/pdf/2602.19538)
- [arXiv260224] Advantage-based Temporal Attack in Reinforcement Learning [link](https://arxiv.org/pdf/2602.19582)
- [arXiv260224] Meta-Learning and Meta-Reinforcement Learning - Tracing the Path towards DeepMind's Adaptive Agent [link](https://arxiv.org/pdf/2602.19837)
- [arXiv260224] DSDR: Dual-Scale Diversity Regularization for Exploration in LLM Reasoning [link](https://arxiv.org/pdf/2602.19895)
- [arXiv260224] Uncertainty-Aware Rank-One MIMO Q Network Framework for Accelerated Offline Reinforcement Learning [link](https://arxiv.org/pdf/2602.19917)
- [arXiv260224] Janus-Q: End-to-End Event-Driven Trading via Hierarchical-Gated Reward Modeling [link](https://arxiv.org/pdf/2602.19919)
- [arXiv260224] Sparse Masked Attention Policies for Reliable Generalization [link](https://arxiv.org/pdf/2602.19956)
- [arXiv260224] A Secure and Private Distributed Bayesian Federated Learning Design [link](https://arxiv.org/pdf/2602.20003)
- [arXiv260224] Descent-Guided Policy Gradient for Scalable Cooperative Multi-Agent Learning [link](https://arxiv.org/pdf/2602.20078)
- [arXiv260224] ReSyn: Autonomously Scaling Synthetic Environments for Reasoning Models [link](https://arxiv.org/pdf/2602.20117)
- [arXiv260224] LAD: Learning Advantage Distribution for Reasoning [link](https://arxiv.org/pdf/2602.20132)
- [arXiv260224] AAVGen: Precision Engineering of Adeno-associated Viral Capsids for Renal Selective Targeting [link](https://arxiv.org/pdf/2602.18915)

**cs.AI/cs.LG contains "accelerate" total: 27**
- [arXiv260224] InfEngine: A Self-Verifying and Self-Optimizing Intelligent Engine for Infrared Radiation Computing [link](https://arxiv.org/pdf/2602.18985)
- [arXiv260224] ConfSpec: Efficient Step-Level Speculative Reasoning via Confidence-Gated Verification [link](https://arxiv.org/pdf/2602.18447)
- [arXiv260224] VariBASed: Variational Bayes-Adaptive Sequential Monte-Carlo Planning for Deep Reinforcement Learning [link](https://arxiv.org/pdf/2602.18857)
- [arXiv260224] IDLM: Inverse-distilled Diffusion Language Models [link](https://arxiv.org/pdf/2602.19066)
- [arXiv260224] Vectorized Bayesian Inference for Latent Dirichlet-Tree Allocation [link](https://arxiv.org/pdf/2602.18795)
- [arXiv260224] Exponential Convergence of (Stochastic) Gradient Descent for Separable Logistic Regression [link](https://arxiv.org/pdf/2602.18946)
- [arXiv260224] DeepInnovator: Triggering the Innovative Capabilities of LLMs [link](https://arxiv.org/pdf/2602.18920)
- [arXiv260224] Task-Aware Exploration via a Predictive Bisimulation Metric [link](https://arxiv.org/pdf/2602.18724)
- [arXiv260224] Can Multimodal LLMs See Science Instruction? Benchmarking Pedagogical Reasoning in K-12 Classroom Videos [link](https://arxiv.org/pdf/2602.18466)
- [arXiv260224] Learning from Complexity: Exploring Dynamic Sample Pruning of Spatio-Temporal Training [link](https://arxiv.org/pdf/2602.19113)
- [arXiv260224] LLM-Assisted Replication for Quantitative Social Science [link](https://arxiv.org/pdf/2602.18453)
- [arXiv260224] Habilis-$β$: A Fast-Motion and Long-Lasting On-Device Vision-Language-Action Model [link](https://arxiv.org/pdf/2602.18813)
- [arXiv260224] CORVET: A CORDIC-Powered, Resource-Frugal Mixed-Precision Vector Processing Engine for High-Throughput AIoT applications [link](https://arxiv.org/pdf/2602.19268)
- [arXiv260224] Taming Preconditioner Drift: Unlocking the Potential of Second-Order Optimizers for Federated Learning on Non-IID Data [link](https://arxiv.org/pdf/2602.19271)
- [arXiv260224] CTS-Bench: Benchmarking Graph Coarsening Trade-offs for GNNs in Clock Tree Synthesis [link](https://arxiv.org/pdf/2602.19330)
- [arXiv260224] Laplacian Multi-scale Flow Matching for Generative Modeling [link](https://arxiv.org/pdf/2602.19461)
- [arXiv260224] Relational Feature Caching for Accelerating Diffusion Transformers [link](https://arxiv.org/pdf/2602.19506)
- [arXiv260224] Leap+Verify: Regime-Adaptive Speculative Weight Prediction for Accelerating Neural Network Training [link](https://arxiv.org/pdf/2602.19580)
- [arXiv260224] Rules or Weights? Comparing User Understanding of Explainable AI Techniques with the Cognitive XAI-Adaptive Model [link](https://arxiv.org/pdf/2602.19620)
- [arXiv260224] Iconographic Classification and Content-Based Recommendation for Digitized Artworks [link](https://arxiv.org/pdf/2602.19698)
- [arXiv260224] Hexagon-MLIR: An AI Compilation Stack For Qualcomm's Neural Processing Units (NPUs) [link](https://arxiv.org/pdf/2602.19762)
- [arXiv260224] Fully Convolutional Spatiotemporal Learning for Microstructure Evolution Prediction [link](https://arxiv.org/pdf/2602.19915)
- [arXiv260224] DP-FedAdamW: An Efficient Optimizer for Differentially Private Federated Large Models [link](https://arxiv.org/pdf/2602.19945)
- [arXiv260224] A Secure and Private Distributed Bayesian Federated Learning Design [link](https://arxiv.org/pdf/2602.20003)
- [arXiv260224] Adaptation to Intrinsic Dependence in Diffusion Language Models [link](https://arxiv.org/pdf/2602.20126)
- [arXiv260224] AAVGen: Precision Engineering of Adeno-associated Viral Capsids for Renal Selective Targeting [link](https://arxiv.org/pdf/2602.18915)
- [arXiv260224] Kaiwu-PyTorch-Plugin: Bridging Deep Learning and Photonic Quantum Computing for Energy-Based Models and Active Sample Selection [link](https://arxiv.org/pdf/2602.19114)

## 2026-02-25

**cs.DC total: 11**

- **[arXiv260225] A Granularity Characterization of Task Scheduling Effectiveness**
  - **tags:** [sys], [task scheduling], [task granularity, dependency topology, strong-scaling, overhead modeling, dynamic scheduling]
  - **authors:** Sana Taghipour Anvar, David Kaeli
  - **institution:** Northeastern University
  - **link:** https://arxiv.org/pdf/2602.20561
  - **Simple LLM Summary:** This paper introduces a framework that links scheduling overhead growth to the dependency topology of a task graph, showing that structure, not just problem size, governs overhead scaling. It proposes a granularity measure to predict when scheduling overhead dominates performance, enabling a runtime rule to choose between dynamic and static execution without extensive tuning.

- **[arXiv260225] Heterogeneity-Aware Client Selection Methodology For Efficient Federated Learning**
  - **tags:** [mlsys], [cluster infrastructure], [federated learning, client selection, gradient updates, deterministic algorithm, statistical heterogeneity, Terraform]
  - **authors:** Nihal Balivada, Shrey Gupta, Shashank Shreedhar Bhatt, Suyash Gupta
  - **institution:** University of Oregon, Boston College, Microsoft Research
  - **link:** https://arxiv.org/pdf/2602.20450
  - **Simple LLM Summary:** The paper introduces Terraform, a novel client selection methodology for Federated Learning that uses gradient updates and a deterministic clustering algorithm to select heterogeneous clients for retraining. This approach addresses statistical heterogeneity and achieves up to 47% higher accuracy compared to prior works, demonstrating improved efficiency and robustness.

- **[arXiv260225] Circumventing the FLP Impossibility Result with Open Atomic Ethernet**
  - **tags:** [sys], [distributed consensus], [FLP impossibility, bisynchrony, Open Atomic Ethernet, deterministic consensus, asynchronous model, swap protocol]
  - **authors:** Paul Borrill
  - **institution:** DÆDÆLUS
  - **link:** https://arxiv.org/pdf/2602.20444
  - **Simple LLM Summary:** The paper proposes Open Atomic Ethernet (OAE), a bisynchronous Layer 2 protocol using swap operations to achieve deterministic atomic coordination. It circumvents the FLP impossibility result by rejecting the asynchronous system model, demonstrating that FLP is a theorem about a specific model rather than a universal physical constraint.

- **[arXiv260225] ReviveMoE: Fast Recovery for Hardware Failures in Large-Scale MoE LLM Inference Deployments**
  - **tags:** [mlsys], [fault-tolerance], [MoE, model-as-a-service, xDeepServe, XCCL, disaggregated architecture]
  - **authors:** Haley Li, Xinglu Wang, Cong Feng, Chunxu Zuo, Yanan Wang, Hei Lo, Yufei Cui, Bingji Wang, Duo Cui, Shuming Jing, Yizhou Shan, Ying Xiong, Jiannan Wang, Yong Zhang, Zhenan Fan
  - **institution:** Huawei Technologies, Simon Fraser University
  - **link:** https://arxiv.org/pdf/2602.21140
  - **Simple LLM Summary:** The paper proposes ReviveMoE, a method for fast hardware failure recovery in large-scale MoE LLM inference deployments without restarting the serving instance. It supports both traditional and disaggregated LLM architectures. The method is integrated into Huawei Cloud's MaaS and built on their xDeepServe platform and XCCL library to minimize service interruption.

- **[arXiv260225] A Morton-Type Space-Filling Curve for Pyramid Subdivision and Hybrid Adaptive Mesh Refinement**
  - **tags:** [sys], [computational geometry], [space-filling curve, adaptive mesh refinement, forest-of-refinement-trees, pyramid element, hybrid mesh, parallel algorithms]
  - **authors:** David Knapp, Johannes Albrecht Holke, Thomas Spenke, Carsten Burstedde
  - **institution:** Universität zu Köln, German Aerospace Center (DLR), Rheinische Friedrich-Wilhelms-Universität Bonn
  - **link:** https://arxiv.org/pdf/2602.20887
  - **Simple LLM Summary:** This paper introduces a Morton-type space-filling curve for pyramid elements to enable hybrid adaptive mesh refinement, connecting tetrahedral and hexahedral meshes. It generalizes parallel algorithms for refinement, coarsening, and partitioning to support this new element type. The demonstrations confirm the efficiency and scalability of the complete hybrid-element dynamic AMR framework.

- **[arXiv260225] Circumventing the CAP Theorem with Open Atomic Ethernet**
  - **tags:** [sys], [distributed systems], [Open Atomic Ethernet, bisynchrony, spanning trees, soft partitions, CAL theorem, PACELC, network fault healing]
  - **authors:** Paul Borrill
  - **institution:** DÆDÆLUS
  - **link:** https://arxiv.org/pdf/2602.21182
  - **Simple LLM Summary:** This paper proposes Open Atomic Ethernet (OAE), a network architecture that uses bisynchronous links and octavalent meshes with local spanning tree repair to drastically reduce the frequency and duration of application-visible network partitions. It argues that by detecting and healing fabric faults within hundreds of nanoseconds, OAE shifts the engineering regime, effectively circumventing the practical trade-offs imposed by the CAP theorem in distributed systems.

- **[arXiv260225] Scaling State-Space Models on Multiple GPUs with Tensor Parallelism**
  - **tags:** [mlsys], [llm inference], [tensor parallelism, selective state space models, SSM state cache, quantized all-reduce, Mamba, Falcon-Mamba, Zamba]
  - **authors:** Anurag Dutt, Nimit Shah, Hazem Masarani, Anshul Gandhi
  - **institution:** Stony Brook University
  - **link:** https://arxiv.org/pdf/2602.21144
  - **Simple LLM Summary:** This paper introduces a communication-efficient tensor parallelism design for scaling selective state-space model (SSM) inference across multiple GPUs. The method addresses challenges like state caching, parameter partitioning, and using quantized all-reduce to reduce overhead. The evaluation shows substantial throughput gains, especially for long-context workloads, on SSM-based LLMs like Mamba.

- **[arXiv260225] The Tragedy of Chain Commons**
  - **tags:** [sys], [blockchain consensus], [decoupled consensus, gaslighting attack, Byzantine Fault Tolerance, modular blockchains, parallel execution]
  - **authors:** Ignacio Amores-Sesar, Mirza Ahad Baig, Seth Gilbert, Ray Neiheiser, Michelle X. Yeo
  - **institution:** Aarhus University, Institute of Science and Technology Austria, National University of Singapore, Nanyang Technological University
  - **link:** https://arxiv.org/pdf/2602.20341
  - **Simple LLM Summary:** This paper studies decoupled blockchain architectures that separate transaction ordering from execution to improve performance. It introduces a formal framework and identifies a new "gaslighting" attack enabled by this design, proving a fundamental trade-off between attack resilience and resource utilization. To address this, the authors propose an intermediate leader-based model that is robust to such attacks while maintaining high throughput and low latency.

- **[arXiv260225] Lagom: Unleashing the Power of Communication and Computation Overlapping for Distributed LLM Training**
  - **tags:** [mlsys], [llm training], [communication-computation overlap, unified cost model, priority-based search, parameter tuning, NCCL, AutoCCL]
  - **authors:** Guanbin Xu, ZhenGuo Xu, Yuzhe Li, Youhui Bai, Ping Gong, Chaoyi Ruan, Cheng Li
  - **institution:** University of Science and Technology of China, National University of Singapore
  - **link:** https://arxiv.org/pdf/2602.20656
  - **Simple LLM Summary:** Lagom is a system that co-tunes communication parameters to balance resource usage between computation and communication in distributed LLM training. It introduces a unified cost model and a priority-based search algorithm to reduce optimization complexity from exponential to linear. Evaluations show it achieves speedups over existing methods like NCCL and AutoCCL across diverse models and parallelizations.

- **[arXiv260225] Is a LOCAL algorithm computable?**
  - **tags:** [sys], [distributed computing], [LOCAL model, locally checkable labeling, computability, graph algorithms, round complexity]
  - **authors:** Antonio Cruciani, Avinandan Das, Massimo Equi, Henrik Lievonen, Diep Luong-Le, Augusto Modanese, Jukka Suomela
  - **institution:** Aalto University, Columbia University, CISPA Helmholtz Center for Information Security
  - **link:** https://arxiv.org/pdf/2602.21022
  - **Simple LLM Summary:** This paper investigates the distinction between computable and uncomputable functions in the standard LOCAL model for distributed graph algorithms. It demonstrates that this distinction is significant for Locally Checkable Labeling (LCL) problems and is intrinsically linked to knowledge of the graph size n. The main conclusion is that for LCL problems, having any bound on n makes the round complexity identical in both computable and uncomputable models, but without such knowledge, computability can drastically increase the required number of rounds.

- **[arXiv260225] Untied Ulysses: Memory-Efficient Context Parallelism via Headwise Chunking**
  - **tags:** [mlsys], [llm training], [context parallelism, activation memory, headwise chunking, sequence parallelism, Ring Attention, DeepSpeed Ulysses, Fully Pipelined Distributed Transformer, activation offloading]
  - **authors:** Ravi Ghadia, Maksim Abraham, Sergei Vorobyov, Max Ryabinin
  - **institution:** Together AI
  - **link:** https://arxiv.org/pdf/2602.21196
  - **Simple LLM Summary:** The paper introduces UPipe, a context parallelism technique that performs fine-grained chunking at the attention head level to reduce activation memory usage in self-attention during long-sequence training. This method significantly cuts intermediate tensor memory (e.g., by up to 87.5% for 32B Transformers) while maintaining training throughput. It enables training with context lengths up to 5M tokens on an 8×H100 node, improving over prior methods by over 25%.


**cs.AI/cs.LG contains "reinforcement learning" total: 22**
- [arXiv260225] CAMEL: Confidence-Gated Reflection for Reward Modeling [link](https://arxiv.org/pdf/2602.20670)
- [arXiv260225] A Generalized Apprenticeship Learning Framework for Capturing Evolving Student Pedagogical Strategies [link](https://arxiv.org/pdf/2602.20527)
- [arXiv260225] Balancing Multiple Objectives in Urban Traffic Control with Reinforcement Learning from AI Feedback [link](https://arxiv.org/pdf/2602.20728)
- [arXiv260225] Buffer Matters: Unleashing the Power of Off-Policy Reinforcement Learning in Large Language Model Reasoning [link](https://arxiv.org/pdf/2602.20722)
- [arXiv260225] Actor-Curator: Co-adaptive Curriculum Learning via Policy-Improvement Bandits for RL Post-Training [link](https://arxiv.org/pdf/2602.20532)
- [arXiv260225] Localized Dynamics-Aware Domain Adaption for Off-Dynamics Offline Reinforcement Learning [link](https://arxiv.org/pdf/2602.21072)
- [arXiv260225] From Logs to Language: Learning Optimal Verbalization for LLM-Based Recommendation in Production [link](https://arxiv.org/pdf/2602.20558)
- [arXiv260225] Cooperative-Competitive Team Play of Real-World Craft Robots [link](https://arxiv.org/pdf/2602.21119)
- [arXiv260225] The Art of Efficient Reasoning: Data, Reward, and Optimization [link](https://arxiv.org/pdf/2602.20945)
- [arXiv260225] What Matters for Simulation to Online Reinforcement Learning on Real Robots [link](https://arxiv.org/pdf/2602.20220)
- [arXiv260225] KairosVL: Orchestrating Time Series and Semantics for Unified Reasoning [link](https://arxiv.org/pdf/2602.20494)
- [arXiv260225] OptiLeak: Efficient Prompt Reconstruction via Reinforcement Learning in Multi-tenant LLM Services [link](https://arxiv.org/pdf/2602.20595)
- [arXiv260225] SELAUR: Self Evolving LLM Agent via Uncertainty-aware Rewards [link](https://arxiv.org/pdf/2602.21158)
- [arXiv260225] Fuz-RL: A Fuzzy-Guided Robust Framework for Safe Reinforcement Learning under Uncertainty [link](https://arxiv.org/pdf/2602.20729)
- [arXiv260225] TrajGPT-R: Generating Urban Mobility Trajectory with Reinforcement Learning-Enhanced Generative Pre-trained Transformer [link](https://arxiv.org/pdf/2602.20643)
- [arXiv260225] Regret-Guided Search Control for Efficient Learning in AlphaZero [link](https://arxiv.org/pdf/2602.20809)
- [arXiv260225] Controllable Exploration in Hybrid-Policy RLVR for Multi-Modal Reasoning [link](https://arxiv.org/pdf/2602.20197)
- [arXiv260225] PyVision-RL: Forging Open Agentic Vision Models via RL [link](https://arxiv.org/pdf/2602.20739)
- [arXiv260225] Probing Dec-POMDP Reasoning in Cooperative MARL [link](https://arxiv.org/pdf/2602.20804)
- [arXiv260225] Diffusion Modulation via Environment Mechanism Modeling for Planning [link](https://arxiv.org/pdf/2602.20422)
- [arXiv260225] Squint: Fast Visual Reinforcement Learning for Sim-to-Real Robotics [link](https://arxiv.org/pdf/2602.21203)
- [arXiv260225] Gap-Dependent Bounds for Nearly Minimax Optimal Reinforcement Learning with Linear Function Approximation [link](https://arxiv.org/pdf/2602.20297)

**cs.AI/cs.LG contains "accelerate" total: 12**
- [arXiv260225] GeoPT: Scaling Physics Simulation via Lifted Geometric Pre-Training [link](https://arxiv.org/pdf/2602.20399)
- [arXiv260225] Shape-informed cardiac mechanics surrogates in data-scarce regimes via geometric encoding and generative augmentation [link](https://arxiv.org/pdf/2602.20306)
- [arXiv260225] Extending $μ$P: Spectral Conditions for Feature Learning Across Optimizers [link](https://arxiv.org/pdf/2602.20937)
- [arXiv260225] WeirNet: A Large-Scale 3D CFD Benchmark for Geometric Surrogate Modeling of Piano Key Weirs [link](https://arxiv.org/pdf/2602.20714)
- [arXiv260225] Coupled Cluster con MōLe: Molecular Orbital Learning for Neural Wavefunctions [link](https://arxiv.org/pdf/2602.20232)
- [arXiv260225] Nonparametric Teaching of Attention Learners [link](https://arxiv.org/pdf/2602.20461)
- [arXiv260225] LESA: Learnable Stage-Aware Predictors for Diffusion Model Acceleration [link](https://arxiv.org/pdf/2602.20497)
- [arXiv260225] CHESS: Context-aware Hierarchical Efficient Semantic Selection for Long-Context LLM Inference [link](https://arxiv.org/pdf/2602.20732)
- [arXiv260225] KnapSpec: Self-Speculative Decoding via Adaptive Layer Selection as a Knapsack Problem [link](https://arxiv.org/pdf/2602.20217)
- [arXiv260225] Amortized Bayesian inference for actigraph time sheet data from mobile devices [link](https://arxiv.org/pdf/2602.20611)
- [arXiv260225] Functional Continuous Decomposition [link](https://arxiv.org/pdf/2602.20857)
- [arXiv260225] Complexity of Classical Acceleration for $\ell_1$-Regularized PageRank [link](https://arxiv.org/pdf/2602.21138)

## 2026-02-26

**cs.DC total: 16**

- **[arXiv260226] Type-Based Enforcement of Non-Interference for Choreographic Programming**
  - **tags:** [sys], [programming languages, security], [type system, non-interference, choreographic programming, constraint generation, program-counter discipline]
  - **authors:** Marco Bertoni, Saverio Giallorenzo, Marco Peressotti
  - **institution:** Inria Paris, Université di Bologna, Inria Sophia Antipolis, University of Southern Denmark
  - **link:** https://arxiv.org/pdf/2602.21630
  - **Simple LLM Summary:** This paper develops a policy-parametric type system for choreographic programming to enforce confidentiality. The method prevents information leaks by handling explicit and implicit flows and supports recursive procedures via constraint generation. The authors prove that their system ensures termination-insensitive non-interference.

- **[arXiv260226] General Convex Agreement with Near-Optimal Communication**
  - **tags:** [sys], [distributed consensus], [convex agreement, Byzantine agreement, extractor graphs, committee assignment, Helly number, communication complexity]
  - **authors:** Marc Dufay, Diana Ghinea, Anton Paramonov
  - **institution:** ETH Zurich, Lucerne University of Applied Sciences and Arts
  - **link:** https://arxiv.org/pdf/2602.21411
  - **Simple LLM Summary:** The paper presents deterministic synchronous Convex Agreement protocols for general convexity spaces, using extractor graphs to assign parties to committees resiliently. It achieves near-optimal communication complexity and round complexity, with resilience close to the theoretical limit defined by the Helly number of the convexity space.

- **[arXiv260226] Make Every Draft Count: Hidden State based Speculative Decoding**
  - **tags:** [mlsys], [llm inference], [speculative decoding, hidden state reuse, auto-regressive hidden states, token tree, verification failure resampling]
  - **authors:** Yuetao Chen, Xuliang Wang, Xinzhou Zheng, Ming Li, Peng Wang, Hong Xu
  - **institution:** The Chinese University of Hong Kong, University of Waterloo, University of Science and Technology of China
  - **link:** https://arxiv.org/pdf/2602.21224
  - **Simple LLM Summary:** This paper proposes a novel speculative decoding system that reuses the hidden states from discarded draft tokens to improve computational efficiency. The core method involves performing auto-regressive prediction at the hidden state level and injecting token information later, enabling the system to repurpose failed drafts. The evaluation shows the method achieves up to a 3.3x speedup compared to standard speculative decoding.

- **[arXiv260226] Epoch-based Optimistic Concurrency Control in Geo-replicated Databases**
  - **tags:** [sys], [distributed databases], [epoch-based replication, optimistic concurrency control, deterministic re-execution, conflict graph, maximum weight independent set, multi-leader replication]
  - **authors:** Yunhao Mao, Harunari Takata, Michail Bachras, Yuqiu Zhang, Shiquan Zhang, Gengrui Zhang, Hans-Arno Jacobsen
  - **institution:** University of Toronto, Keio University, Concordia University
  - **link:** https://arxiv.org/pdf/2602.21566
  - **Simple LLM Summary:** The paper introduces Minerva, a geo-replicated database system that uses an epoch-based optimistic concurrency control protocol with deterministic re-execution and a conflict graph algorithm to resolve transaction conflicts. It decouples data propagation from commitment to enable high concurrency across multiple replicas. The evaluation shows Minerva significantly outperforms existing systems in throughput under high latency and scalability tests.

- **[arXiv260226] Lamport's Arrow of Time: The Category Mistake in Logical Clocks**
  - **tags:** [sys], [distributed systems theory], [logical clocks, happens-before relation, directed acyclic graph, FITO, mutual information conservation, CAP theorem, Fischer-Lynch-Paterson, TLA+]
  - **authors:** Paul Borrill
  - **institution:** DÆDÆLUS
  - **link:** https://arxiv.org/pdf/2602.21730
  - **Simple LLM Summary:** The paper critiques Lamport's logical clocks, arguing they embed a "forward-in-time-only" assumption that conflates logical ordering with physical causality. It traces this conflation through impossibility theorems and contrasts it with relativistic and quantum models that allow indefinite causal order. The authors propose mutual information conservation as a more fundamental primitive for distributed consistency than temporal precedence.

- **[arXiv260226] JSAM: Privacy Straggler-Resilient Joint Client Selection and Incentive Mechanism Design in Differentially Private Federated Learning**
  - **tags:** [mlsys], [others], [differential privacy, federated learning, incentive mechanism design, client selection, Bayesian optimization, privacy stragglers]
  - **authors:** Ruichen Xu, Ying-Jun Angela Zhang, Jianwei Huang
  - **institution:** The Chinese University of Hong Kong, Shenzhen Institute of Artificial Intelligence and Robotics for Society
  - **link:** https://arxiv.org/pdf/2602.21844
  - **Simple LLM Summary:** The paper proposes JSAM, a Bayesian-optimal framework that jointly optimizes client selection probabilities and privacy compensation to maximize training effectiveness in differentially private federated learning under budget constraints. It finds that servers should preferentially select privacy-tolerant clients and reveals that clients with minimal privacy sensitivity may incur the highest cumulative costs due to frequent participation. Evaluations show JSAM achieves up to 15% improvement in test accuracy compared to existing unbiased selection mechanisms.

- **[arXiv260226] PiPNN: Ultra-Scalable Graph-Based Nearest Neighbor Indexing**
  - **tags:** [mlsys], [others], [graph-based indexing, approximate nearest neighbor search, beam search, dense matrix multiplication, online pruning, HashPrune]
  - **authors:** Tobias Rubel, Richard Wen, Laxman Dhulipala, Lars Gottesbüren, Rajesh Jayaram, Jakub Łącki
  - **institution:** University of Maryland, Google Research
  - **link:** https://arxiv.org/pdf/2602.21247
  - **Simple LLM Summary:** The paper introduces PiPNN, a new graph construction algorithm for approximate nearest neighbor search that uses a core component called HashPrune for online pruning to avoid the slow beam search bottleneck of existing methods. It partitions data and uses dense matrix multiplication for efficient bulk comparisons, achieving significantly faster index construction than state-of-the-art methods like HNSW and Vamana. The main conclusion is that PiPNN enables building high-quality billion-scale indexes in under 20 minutes on a single machine, greatly improving scalability.

- **[arXiv260226] DHP: Efficient Scaling of MLLM Training with Dynamic Hybrid Parallelism**
  - **tags:** [mlsys], [multi-modal training], [dynamic hybrid parallelism, non-power-of-two parallelism, polynomial-time algorithm, data parallelism, tensor parallelism, pipeline parallelism, sequence parallelism]
  - **authors:** Yifan Niu, Han Xiao, Dongyi Liu, Wei Zhou, Jia Li
  - **institution:** The Hong Kong University of Science and Technology (Guangzhou), Huawei Technologies Co., Ltd., The Hong Kong University of Science and Technology
  - **link:** https://arxiv.org/pdf/2602.21788
  - **Simple LLM Summary:** This paper proposes Dynamic Hybrid Parallelism (DHP), a method that adaptively reconfigures communication groups and parallelism degrees during training to handle heterogeneous multimodal data efficiently. It introduces a polynomial-time algorithm to generate near-optimal strategies with minimal overhead. The results show DHP significantly outperforms static frameworks like Megatron-LM and DeepSpeed, achieving up to 1.36x speedup in training throughput.

- **[arXiv260226] Multi-Layer Scheduling for MoE-Based LLM Reasoning**
  - **tags:** [mlsys], [llm inference], [multi-layer scheduling, Mixture-of-Experts (MoE), Shortest-Job-First (SJF), priority-aware aging, load-aware dispatching, expert hotspots, KV cache]
  - **authors:** Yifan Sun, Gholamreza Haffar, Minxian Xu, Rajkumar Buyya, Adel N. Toosi
  - **institution:** The University of Melbourne, Monash University, Shenzhen Institute of Advanced Technology, Chinese Academy of Sciences
  - **link:** https://arxiv.org/pdf/2602.21626
  - **Simple LLM Summary:** This paper proposes a multi-layer scheduling framework for efficient inference of Mixture-of-Experts (MoE) based Large Language Models, operating at the request, engine, and expert levels. The method employs strategies like Shortest-Job-First and load-aware dispatching to optimize resource utilization and reduce latency. Experimental results show the framework outperforms vLLM, achieving significant reductions in Time To First Token and Time-Per-Output-Token latency.

- **[arXiv260226] DualPath: Breaking the Storage Bandwidth Bottleneck in Agentic LLM Inference**
  - **tags:** [mlsys], [llm inference], [KV-Cache, disaggregated architecture, RDMA, dual-path loading, prefill-decode engines, global scheduler]
  - **authors:** Yongtong Wu, Shaoyuan Chen, Yinmin Zhong, Rilin Huang, Yixuan Tan, Wentao Zhang, Liyue Zhang, Shangyan Zhou, Yuxuan Liu, Shunfeng Zhou, Mingxing Zhang, Xin Jin, Panpan Huang
  - **institution:** Peking University, Tsinghua University, DeepSeek-AI
  - **link:** https://arxiv.org/pdf/2602.21548
  - **Simple LLM Summary:** The paper presents DualPath, an inference system that introduces a dual-path KV-Cache loading mechanism to address the storage bandwidth bottleneck in agentic LLM workloads. It adds a novel storage-to-decode path alongside the traditional storage-to-prefill path, using RDMA for efficient transfer, combined with a global scheduler. The evaluation shows DualPath significantly improves both offline and online inference throughput without violating service-level objectives.

- **[arXiv260226] Energy Efficient Federated Learning with Hyperdimensional Computing over Wireless Communication Networks**
  - **tags:** [mlsys], [others], [hyperdimensional computing, differential privacy, resource allocation, alternating optimization, energy efficiency]
  - **authors:** Yahao Ding, Yinchao Yang, Jiaxiang Wang, Zhaohui Yang, Dusit Niyato, Zhu Han, Mohammad Shikh-Bahaei
  - **institution:** King's College London, Zhejiang University, Nanyang Technological University, University of Houston, Kyung Hee University
  - **link:** https://arxiv.org/pdf/2602.21949
  - **Simple LLM Summary:** This paper proposes a federated learning framework that uses hyperdimensional computing for local training and differential privacy for security, aiming to reduce energy consumption in wireless edge networks. It jointly optimizes HDC dimension, transmission time, bandwidth, power, and CPU frequency to minimize total energy under latency and privacy constraints. The proposed method significantly reduces energy usage and communication rounds compared to a neural network baseline while maintaining high accuracy.

- **[arXiv260226] LLMTailor: A Layer-wise Tailoring Tool for Efficient Checkpointing of Large Language Models**
  - **tags:** [mlsys], [fault-tolerance], [checkpointing, layer-wise tailoring, selective checkpointing, I/O optimization]
  - **authors:** Minqiu Sun, Xin Huang, Luanzheng Guo, Nathan R. Tallent, Kento Sato, Dong Dai
  - **institution:** University of Delaware, RIKEN Center for Computational Science, Pacific Northwest National Laboratory
  - **link:** https://arxiv.org/pdf/2602.22158
  - **Simple LLM Summary:** The paper proposes LLMTailor, a checkpoint-merging framework that selectively saves only the layers of a large language model that have undergone significant updates, rather than the entire model state. This approach significantly reduces checkpoint storage size and I/O time while maintaining model quality, as demonstrated in evaluations with models like Llama3.1-8B and Qwen2.5-7B.

- **[arXiv260226] Hybrid Consensus with Quantum Sybil Resistance**
  - **tags:** [sys], [consensus protocols], [quantum sybil resistance, hybrid consensus, quantum position verification, proof-of-work, proof-of-stake]
  - **authors:** Dar Gilboa, Siddhartha Jain, Or Sattath
  - **institution:** Google Quantum AI, University of Texas at Austin, Ben-Gurion University
  - **link:** https://arxiv.org/pdf/2602.22195
  - **Simple LLM Summary:** This paper proposes a new decentralized consensus protocol that uses quantum position verification as a Sybil resistance mechanism, integrated with classical hybrid consensus. The method improves energy efficiency compared to Proof-of-Work-based hybrids and avoids issues like wealth compounding in Proof-of-Stake. The protocol achieves security in the standard model and includes a spam prevention mechanism.

- **[arXiv260226] PASTA: A Modular Program Analysis Tool Framework for Accelerators**
  - **tags:** [mlsys], [GPU kernels], [performance analysis, profiling, GPU-accelerated backend, modular framework, deep learning workloads, NVIDIA GPU, AMD GPU]
  - **authors:** Mao Lin, Hyeran Jeon, Keren Zhou
  - **institution:** University of California, Merced, George Mason University, OpenAI
  - **link:** https://arxiv.org/pdf/2602.22103
  - **Simple LLM Summary:** The paper presents PASTA, a modular and low-overhead program analysis tool framework for hardware accelerators. It abstracts low-level profiling APIs and deep learning frameworks to provide a unified interface for performance analysis. The evaluation shows PASTA offers detailed insights with significantly lower overhead than conventional tools, making it suitable for modern accelerator environments.

- **[arXiv260226] IOAgent: Democratizing Trustworthy HPC I/O Performance Diagnosis Capability via LLMs**
  - **tags:** [mlsys], [llm inference], [RAG, Darshan trace, tree-based merger, module-based pre-processor, TraceBench]
  - **authors:** Chris Egersdoerfer, Arnav Sareen, Jean Luca Bez, Suren Byna, Dongkuan, Dong Dai
  - **institution:** University of Delaware, University of North Carolina at Charlotte, Lawrence Berkeley National Laboratory, The Ohio State University, North Carolina State University
  - **link:** https://arxiv.org/pdf/2602.22017
  - **Simple LLM Summary:** The paper proposes IOAgent, a tool that uses LLMs to diagnose HPC I/O performance issues from Darshan trace files. It integrates a pre-processor, a RAG-based knowledge integrator, and a tree-based merger to provide accurate, justified diagnoses. Evaluations on the TraceBench test suite show it matches or outperforms existing tools and works with various LLMs.

- **[arXiv260226] A task-based data-flow methodology for programming heterogeneous systems with multiple accelerator APIs**
  - **tags:** [mlsys], [cluster infrastructure], [task-based data-flow, directed acyclic graph (DAG), OpenMP/OmpSs-2, task-aware APIs (TA-libs), nOS-V, runtime interoperability, CUDA, SYCL]
  - **authors:** Aleix Boné, Alejandro Aguirre, David Álvarez, Pedro J. Martinez-Ferrer, Vicenç Beltran
  - **institution:** Barcelona Supercomputing Center (BSC), Universitat Politècnica de Catalunya - BarcelonaTech (UPC)
  - **link:** https://arxiv.org/pdf/2602.21897
  - **Simple LLM Summary:** The paper proposes a task-based data-flow methodology using task-aware APIs (like TACUDA and TASYCL) and the nOS-V threading library to seamlessly integrate multiple accelerator programming models (e.g., CUDA, SYCL) within a single application. It demonstrates that this approach enables efficient and transparent use of heterogeneous hardware, mitigating runtime interference and maintaining performance comparable to using a single runtime in isolation.


**cs.AI/cs.LG contains "reinforcement learning" total: 17**
- [arXiv260226] Hierarchical Lead Critic based Multi-Agent Reinforcement Learning [link](https://arxiv.org/pdf/2602.21680)
- [arXiv260226] Tool-R0: Self-Evolving LLM Agents for Tool-Learning from Zero Data [link](https://arxiv.org/pdf/2602.21320)
- [arXiv260226] Alignment-Weighted DPO: A principled reasoning approach to improve safety alignment [link](https://arxiv.org/pdf/2602.21346)
- [arXiv260226] ARLArena: A Unified Framework for Stable Agentic Reinforcement Learning [link](https://arxiv.org/pdf/2602.21534)
- [arXiv260226] GradAlign: Gradient-Aligned Data Selection for LLM Reinforcement Learning [link](https://arxiv.org/pdf/2602.21492)
- [arXiv260226] Training Generalizable Collaborative Agents via Strategic Risk Aversion [link](https://arxiv.org/pdf/2602.21515)
- [arXiv260226] CCCaption: Dual-Reward Reinforcement Learning for Complete and Correct Image Captioning [link](https://arxiv.org/pdf/2602.21655)
- [arXiv260226] Self-Correcting VLA: Online Action Refinement via Sparse World Imagination [link](https://arxiv.org/pdf/2602.21633)
- [arXiv260226] Overconfident Errors Need Stronger Correction: Asymmetric Confidence Penalties for Reinforcement Learning [link](https://arxiv.org/pdf/2602.21420)
- [arXiv260226] Two-Stage Active Distribution Network Voltage Control via LLM-RL Collaboration: A Hybrid Knowledge-Data-Driven Approach [link](https://arxiv.org/pdf/2602.21715)
- [arXiv260226] On the Structural Non-Preservation of Epistemic Behaviour under Policy Transformation [link](https://arxiv.org/pdf/2602.21424)
- [arXiv260226] Evaluating the relationship between regularity and learnability in recursive numeral systems using Reinforcement Learning [link](https://arxiv.org/pdf/2602.21720)
- [arXiv260226] ImpRIF: Stronger Implicit Reasoning Leads to Better Complex Instruction Following [link](https://arxiv.org/pdf/2602.21228)
- [arXiv260226] Generalisation of RLHF under Reward Shift and Clipped KL Regularisation [link](https://arxiv.org/pdf/2602.21765)
- [arXiv260226] Distill and Align Decomposition for Enhanced Claim Verification [link](https://arxiv.org/pdf/2602.21857)
- [arXiv260226] SWE-Protégé: Learning to Selectively Collaborate With an Expert Unlocks Small Language Models as Software Engineering Agents [link](https://arxiv.org/pdf/2602.22124)
- [arXiv260226] Provable Last-Iterate Convergence for Multi-Objective Safe LLM Alignment via Optimistic Primal-Dual [link](https://arxiv.org/pdf/2602.22146)

**cs.AI/cs.LG contains "accelerate" total: 8**
- [arXiv260226] SymTorch: A Framework for Symbolic Distillation of Deep Neural Networks [link](https://arxiv.org/pdf/2602.21307)
- [arXiv260226] Excitation: Momentum For Experts [link](https://arxiv.org/pdf/2602.21798)
- [arXiv260226] Asymptotically Fast Clebsch-Gordan Tensor Products with Vector Spherical Harmonics [link](https://arxiv.org/pdf/2602.21466)
- [arXiv260226] AngelSlim: A more accessible, comprehensive, and efficient toolkit for large model compression [link](https://arxiv.org/pdf/2602.21233)
- [arXiv260226] Error-awareness Accelerates Active Automata Learning [link](https://arxiv.org/pdf/2602.21674)
- [arXiv260226] The Error of Deep Operator Networks Is the Sum of Its Parts: Branch-Trunk and Mode Error Decompositions [link](https://arxiv.org/pdf/2602.21910)
- [arXiv260226] Counterdiabatic Hamiltonian Monte Carlo [link](https://arxiv.org/pdf/2602.21272)
- [arXiv260226] Towards single-shot coherent imaging via overlap-free ptychography [link](https://arxiv.org/pdf/2602.21361)
